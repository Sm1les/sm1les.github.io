<!doctype html>
<html lang="en">
    <head>
		
        <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta http-equiv="Content-Type" content="text/html" charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <meta name="description" content="">
        <link rel="shortcut icon" href="/styles/images/logo.jpg"/>
        <link rel="alternate" type="application/rss+xml" title="Sm1les" href="/atom.xml">

        <title>L1正则化和L2正则化 | Sm1les&#39;s blog</title>
        <meta name="description" content="{{meta_description}}">

        <link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">
        <link rel="stylesheet" type="text/css" href="/styles/crisp.css">
        <meta name="HandheldFriendly" content="True" />
        <meta name="MobileOptimized" content="320" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
        <![endif]--><!-- hexo-inject:begin --><!-- hexo-inject:end -->

    </head>
    
		<body class="post-template">
	

        <!-- hexo-inject:begin --><!-- hexo-inject:end --><header id="header">
            <a id="logo" href="/"><img src="/styles/images/logo.jpg" alt="Sm1les's blog" /></a>
            <h1><a href="/">Sm1les</a></h1>
            <p></p>
            <div id="follow-icons">
	<a href="#"><i class="fa fa-instagram fa-2x"></i></a>
	<a href="#"><i class="fa fa-pinterest-square fa-2x"></i></a>
	<a href="http://github.com/Sm1les"><i class="fa fa-github-square fa-2x"></i></a>
	<a href="#"><i class="fa fa-facebook-square fa-2x"></i></a>
	<a href="#"><i class="fa fa-twitter-square fa-2x"></i></a>
	<a href="#"><i class="fa fa-linkedin-square fa-2x"></i></a>
	<a href="/atom.xml"><i class="fa fa-rss-square fa-2x"></i></a>
</div>
<div id="tag-cloud">

        <a href="/tags/KKT条件/" style="font-size: 10px;">KKT条件</a> <a href="/tags/Logistic回归/" style="font-size: 20px;">Logistic回归</a> <a href="/tags/Slater条件/" style="font-size: 10px;">Slater条件</a> <a href="/tags/对偶问题/" style="font-size: 10px;">对偶问题</a> <a href="/tags/正则化/" style="font-size: 10px;">正则化</a> <a href="/tags/线性回归/" style="font-size: 10px;">线性回归</a>
    
</div>
<h6><a href="/about">About</a></h6>

        </header>

        <main id="content">
        

<article class="post">
  
  一月 7, 2019
  
    <span class="taglist">  &middot; 
    
    
      <a href='/tags/正则化/'>正则化</a> 
    
    </span>
  

  <h1 class="post-title">L1正则化和L2正则化</h1>
  <section class="post-content article-entry">
    <p>正则化是结构风险最小化策略的实现，是在经验风险上加一个正则化项或罚项，正则化项一般是模型复杂度的单调递增函数，模型越复杂，正则化值就越大。例如模型参数向量的范数，正则化的一般形式如下：</p>
<script type="math/tex; mode=display">\min \limits_{f\in\mathcal{F}} \left( \cfrac{1}{N} \sum_{N}^{i=1} L(y_i,f(x_i))+\lambda J(f) \right) \qquad (A.1)</script><p>其中，第1项是经验风险，第2项是正则化项，$\lambda$为调整两者之间关系的系数。常用的正则化项是模型参数向量的$L_1$范数和$L_2$范数，分别称作L1正则化和L2正则化。以线性回归为例，其L1正则化的损失函数为：</p>
<script type="math/tex; mode=display">J(\boldsymbol w)=\cfrac{1}{N} \sum_{N}^{i=1} (f(\boldsymbol x_i;\boldsymbol w)-y_i)^2+\lambda \Vert\boldsymbol w \Vert_1</script><p>其中$\Vert\boldsymbol w \Vert_1$为$\boldsymbol w$的$L_1$范数，同理可得L2正则化的损失函数为：</p>
<script type="math/tex; mode=display">J(\boldsymbol w)=\cfrac{1}{N} \sum_{N}^{i=1} (f(\boldsymbol x_i;\boldsymbol w)-y_i)^2+\lambda \Vert\boldsymbol w \Vert_2^2</script><p>其中$\Vert\boldsymbol w \Vert_2$为$\boldsymbol w$的$L_2$范数。<br>L1正则化和L2正则化最主要的不同之处在于前者更易得稀疏解，解释如下：</p>
<h5 id="从优化问题的角度："><a href="#从优化问题的角度：" class="headerlink" title="从优化问题的角度："></a>从优化问题的角度：</h5><p>式(A.1)可以看作如下优化问题：</p>
<script type="math/tex; mode=display">\begin{aligned}
& \min\limits_{\boldsymbol w} \quad E_{emp}(\boldsymbol w) \\
& s.t.  \quad \lambda E_{reg}(\boldsymbol w) \leq \eta
\end{aligned}</script><p>其中$E_{emp}(\boldsymbol w)$是经验风险，$E_{reg}(\boldsymbol w)$是正则化项，$\eta$是自行设定的容忍度，此优化问题可以描述为：<strong>把$\boldsymbol w$的解限制一定范围内，同时使得经验风险尽可能小</strong>。L1正则化和L2正则化画图表示如下：</p>
<p><center>
<img src="./l1vsl2.png">
</center><br>其中，左图为L1正则化，右图为L2正则化，$\boldsymbol w^*$是$\boldsymbol w$的解，蓝色等高线为经验风险$E_{emp}(\boldsymbol w)$的取值，红色等高线为正则化项$E_{reg}(\boldsymbol w)$的取值，黄色区域是红色等高线的变化范围，也即$\boldsymbol w^*$的取值范围，默认内环等高线的值更小。从图中可以看出，红色等高线和蓝色等高线的<strong>切点</strong>即为优化问题的解$\boldsymbol w^*$，而且L1正则化相比于L2正则化更容易使得切点落在$\boldsymbol w$某个维度$w_i$的坐标轴上，从而导致另一个维度$w_j$的取值为0，从而更容易得到具有稀疏性的$\boldsymbol w^*$。</p>
<h5 id="从梯度的角度："><a href="#从梯度的角度：" class="headerlink" title="从梯度的角度："></a>从梯度的角度：</h5><p>L1正则化的损失函数一般形式为：</p>
<script type="math/tex; mode=display">J(\boldsymbol w)=L(\boldsymbol w)+\lambda \sum \vert w_i \vert \qquad (B.1)</script><p>L2正则化的损失函数一般形式为：</p>
<script type="math/tex; mode=display">J(\boldsymbol w)=L(\boldsymbol w)+\lambda \sum (w_i)^2 \qquad (B.2)</script><p>对式(B.1)关于$\boldsymbol w$某个维度$w_i$求偏导可得：</p>
<script type="math/tex; mode=display">\cfrac{\partial J(\boldsymbol w)}{\partial w_i}=\cfrac{\partial L(\boldsymbol w)}{\partial w_i}+\lambda sign (w_i)</script><p>对式(B.2)关于$\boldsymbol w$某个维度$w_i$求偏导可得：</p>
<script type="math/tex; mode=display">\cfrac{\partial J(\boldsymbol w)}{\partial w_i}=\cfrac{\partial L(\boldsymbol w)}{\partial w_i}+2\lambda w_i</script><p>当使用梯度下降法等此类根据$\boldsymbol w$的梯度来调整$\boldsymbol w$的算法时，若用L1正则化，$\boldsymbol w$的某个维度$w_i$的更新公式为：</p>
<script type="math/tex; mode=display">w_i:=w_i-\eta\cfrac{\partial J(\boldsymbol w)}{\partial w_i}=w_i-\eta\cfrac{\partial L(\boldsymbol w)}{\partial w_i}-\eta\lambda sign (w_i)</script><p>其中$\eta$为自行设定的学习率，从上式可以看出，$\eta\lambda sign (w_i)$的取值恒为$\pm\eta\lambda$，与$w_i$的大小无关，所以这就会导致即使$w_i$已经很小了但仍然以较高的梯度在变化，从而容易使得$w_i$取到0；若用L2正则化，则更新公式为：</p>
<script type="math/tex; mode=display">w_i:=w_i-\eta\cfrac{\partial J(\boldsymbol w)}{\partial w_i}=w_i-\eta\cfrac{\partial L(\boldsymbol w)}{\partial w_i}-2\eta\lambda w_i</script><p>显然此式中的$2\eta\lambda w_i$的大小与$w_i$相关，所以当$w_i$很小时变化的梯度也很小，不容易取到0，也就不容易得到稀疏解。<br><br>L1正则化和L2正则化还有如下不同之处：</p>
<ul>
<li>L1正则化自带特征选择的功能，这是由于L1正则化易得稀疏解导致的，因为稀疏解$\boldsymbol w^*$的某些维度$w_i=0$，从而达到了特征选择的功能；</li>
<li>L1正则化的解不稳定，也即可能会有多个解，这是因为L1正则化的红色等高线容易与经验风险的蓝色等高线产生多个切点，例如上图中的蓝色等高线若不为圆形曲线，而是直线时，此时极有可能与L1正则化的红色等高线重合，从而产生多个解；</li>
<li>L1正则化不易求解，这是因为绝对值函数通常都不好求解；</li>
<li>L1正则化相对于L2正则化对异常值敏感度低，这是因为当$\vert w_i \vert&gt;1$时，$\sum\vert w_i \vert &lt; \sum(w_i)^2$，从而对异常值敏感度低。</li>
</ul>

  </section>
  <footer class="post-footer">
    <!--
    <section class="author">
      <h4>Sm1les</h4>
      <p></p>
    </section>
    -->
  </footer>
</article>

<nav class="pagination" role="pagination">
    
    <span class="page-number">•</span>
    
    <a class="older-posts" href="/2019/01/02/logistic-regression-log-loss-and-quadratic-loss/">
        <!--Logistic回归——为什么用对数损失函数而不用平方损失函数？--> next →
    </a>
    
</nav>

<!-- Begin Comments Code -->

  <div id="comments">
    <!-- 多说评论框 start -->
    <div class="ds-thread" data-thread-key="post-l1-and-l2-regularization" data-title="L1正则化和L2正则化" data-url="http://www.sm1les.com/2019/01/07/l1-and-l2-regularization/"></div>
    <!-- 多说评论框 end -->
    <!-- 多说公共JS代码 start (一个网页只需插入一次) -->
    <script type="text/javascript">
    var duoshuoQuery = {short_name:'sm1les'};
      (function() {
        var ds = document.createElement('script');
        ds.type = 'text/javascript';ds.async = true;
        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
        ds.charset = 'UTF-8';
        (document.getElementsByTagName('head')[0] 
         || document.getElementsByTagName('body')[0]).appendChild(ds);
      })();
      </script>
    <!-- 多说公共JS代码 end -->
  </div>

<!-- End Comments Code -->


        </main>
        <footer id="footer">
            <section id="footer-message">&copy; 2019 Sm1les. All rights reserved. Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>. <a href="https://github.com/guolin/crisp-hexo-theme" target="_blank">crisp</a> theme by <a href="http://guolin.github.io" target="_blank">Guo Lin</a>.</section>
        </footer>
        <script>
            (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
            })(window,document,'script','/js/ga.js','ga');
            ga('create', 'UA-131477813-1', 'auto');
            ga('send', 'pageview');
        </script>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>



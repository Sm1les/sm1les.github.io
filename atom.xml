<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Sm1les&#39;s blog</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://sm1les.com/"/>
  <updated>2019-05-22T01:07:26.217Z</updated>
  <id>http://sm1les.com/</id>
  
  <author>
    <name>Sm1les</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>概率图模型——隐马尔可夫模型</title>
    <link href="http://sm1les.com/2019/04/10/hidden-markov-model/"/>
    <id>http://sm1les.com/2019/04/10/hidden-markov-model/</id>
    <published>2019-04-10T12:03:50.000Z</published>
    <updated>2019-05-22T01:07:26.217Z</updated>
    
    <content type="html"><![CDATA[<h3 id="隐马尔可夫模型的定义-1"><a href="#隐马尔可夫模型的定义-1" class="headerlink" title="隐马尔可夫模型的定义[1]"></a>隐马尔可夫模型的定义<sup><a href="#ref1">[1]</a></sup></h3><p>隐马尔可夫模型（Hidden Markov Model，HMM）是关于时序的概率模型，描述由一个隐藏的马尔可夫链随机生成不可观测的状态随机序列，再由各个状态生成一个观测而产生观测随机序列的过程。隐藏的马尔可夫链随机生成的状态的序列，称为<strong>状态序列</strong>；每个状态生成一个观测，而由此产生的观测的随机序列，称为<strong>观测序列</strong>，序列的每一个位置又可以看作是一个时刻。其形式定义如下：</p>
<p><center>
<img src="./hmm.png">
</center><br>$Q$是所有可能的状态的集合，$V$是所有可能的观测的集合：</p>
<script type="math/tex; mode=display">Q=\{q_1,q_2,...,q_N\},V=\{v_1,v_2,...,v_M\}</script><p>其中，$N$是可能的状态数，$M$是可能的观测数。<br>$I$是长度为$T$的状态序列，$O$是对应的观测序列：</p>
<script type="math/tex; mode=display">I=(i_1,i_2,...,i_T),O=(o_1,o_2,...,o_T)</script><p>$A$是<strong>状态转移概率矩阵</strong>：</p>
<script type="math/tex; mode=display">A=[a_{ij}]_{N\times N}</script><p>其中，$a_{ij}=P(i_{t+1}=q_j\vert i_t=q_i),\quad i=1,2,…,N;j=1,2,…,N$，表示在时刻$t$处于状态$q_i$的条件下在时刻$t+1$转移到状态$q_j$的概率。<br>$B$是<strong>观测概率矩阵</strong>：</p>
<script type="math/tex; mode=display">B=[b_{jk}]_{N\times M}</script><p>其中，$b_{jk}=P(o_t=v_k\vert i_t=q_j),\quad j=1,2,…N;k=1,2,…,M$，表示在时刻$t$处于状态$q_j$的条件下生成观测$v_k$的概率。<br>$\pi$是<strong>初始状态概率向量</strong>：</p>
<script type="math/tex; mode=display">\pi=(\pi_1,\pi_2,...,\pi_N)</script><p>其中，$\pi_i=P(i_1=q_i),\quad i=1,2,…,N$，表示时刻$t=1$时处于状态$q_i$的概率。<br>隐马尔可夫模型由初始状态概率向量$\pi$、状态转移概率矩阵$A$和观测概率矩阵$B$决定。$\pi$和$A$决定状态序列，$B$决定观测序列。因此，隐马尔可夫模型$\lambda$可以用三元符号表示，即：</p>
<script type="math/tex; mode=display">\lambda=(A,B,\pi)</script><p>$A,B,\pi$称为隐马尔可夫模型的<strong>三要素</strong>。<br>从定义可知，隐马尔可夫模型作了<strong>两个基本假设</strong>：</p>
<ol>
<li>齐次马尔可夫性假设，即假设隐藏的马尔可夫链在任意时刻$t$的状态只依赖于其前一时刻的状态，与其他时刻的状态及观测无关，也与时刻$t$无关：<script type="math/tex; mode=display">P(i_t\vert i_{t-1},o_{t-1},...,i_1,o_1)=P(i_t\vert i_{t-1})</script></li>
<li>观测独立性假设，即假设任意时刻的观测只依赖于该时刻的马尔可夫链的状态，与其他观测及状态无关：<script type="math/tex; mode=display">P(o_t\vert i_T,o_T,i_{T-1},o_{T-1},...,i_t,i_{t-1},o_{t-1},...,i_1,o_1)=P(o_t\vert i_t)</script></li>
</ol>
<h3 id="隐马尔可夫模型的3个基本问题"><a href="#隐马尔可夫模型的3个基本问题" class="headerlink" title="隐马尔可夫模型的3个基本问题"></a>隐马尔可夫模型的3个基本问题</h3><ol>
<li>概率计算问题：给定模型$\lambda=(A,B,\pi)$和观测序列$O=(o_1,o_2,…,o_T)$，计算在模型$\lambda$下观测序列$O$出现的概率$P(O\vert \lambda)$；</li>
<li>学习问题：已知观测序列$O=(o_1,o_2,…,o_T)$，估计模型$\lambda=(A,B,\pi)$参数，使得在该模型下观测序列概率$P(O\vert \lambda)$最大，即用极大似然估计的方法估计参数；</li>
<li>预测问题：也称为解码问题，已知模型$\lambda=(A,B,\pi)$和观测序列$O=(o_1,o_2,…,o_T)$，求对给定观测序列条件概率$P(I\vert O)$最大的状态序列$I=(i_1,i_2,…,i_T)$，即给定观测序列，求最有可能的对应的状态序列。</li>
</ol>
<h3 id="概率计算问题"><a href="#概率计算问题" class="headerlink" title="概率计算问题"></a>概率计算问题</h3><h5 id="直接计算法"><a href="#直接计算法" class="headerlink" title="直接计算法"></a>直接计算法</h5><p>对于求$P(O\vert \lambda)$最直接的方法就是按照概率公式直接计算，即：</p>
<script type="math/tex; mode=display">\begin{aligned}
P(O\vert\lambda)&=\sum_{I}P(O,I\vert\lambda) \\
&=\sum_{I}P(O\vert I,\lambda)P(I\vert\lambda) 
\end{aligned}</script><p>其中，$P(I\vert \lambda)$表示给定模型参数时，产生状态序列$I=(i_1,i_2,…,i_T)$的概率：</p>
<script type="math/tex; mode=display">P(I\vert \lambda)=\pi_{i_1}a_{i_1i_2}a_{i_2i_3}\cdots a_{i_{T-1}i_T}</script><p>$P(O\vert I,\lambda)$表示给定模型参数且状态序列为$I=(i_1,i_2,…,i_T)$时，产生观测序列$O=(o_1,o_2,…,o_T)$的概率：</p>
<script type="math/tex; mode=display">P(O\vert I,\lambda)=b_{i_1o_1}b_{i_2o_2}...b_{i_To_T}</script><p>所以</p>
<script type="math/tex; mode=display">\begin{aligned}
P(O\vert\lambda)&=\sum_{I}P(O\vert I,\lambda)P(I\vert\lambda) \\
&=\sum_{i_1,i_2,...,i_T}\pi_{i_1}b_{i_1o_1}a_{i_1i_2}b_{i_2o_2}\cdots a_{i_{T-1}i_T}b_{i_To_T}
\end{aligned}</script><p>其中，$\sum_{i_1,i_2,…,i_T}$共有$N^T$种可能，计算$\pi_{i_1}b_{i_1o_1}a_{i_1i_2}b_{i_2o_2}\cdots a_{i_{T-1}i_T}b_{i_To_T}$的时间复杂度为$O(T)$，所以上式整体的时间复杂度为$O(TN^T)$，显然这种算法是不可行的。</p>
<h5 id="前向算法"><a href="#前向算法" class="headerlink" title="前向算法"></a>前向算法</h5><p>首先定义<strong>前向概率</strong>：给定隐马尔可夫模型$\lambda$，定义到时刻$t$部分观测序列为$o_1,o_2,…,o_t$且状态为$q_i$的概率为前向概率，记作：</p>
<script type="math/tex; mode=display">\alpha_t(i)=P(o_1,o_2,...,o_t,i_t=q_i\vert \lambda)</script><p><center>
<img src="./hmm-forward.png">
</center><br>根据前向概率的定义可推得：</p>
<script type="math/tex; mode=display">P(O\vert \lambda)=\sum_{i=1}^{N}P(o_1,o_2,...,o_T,i_T=q_i\vert \lambda)=\sum_{i=1}^{N}\alpha_T(i)</script><p>于是求解$P(O\vert \lambda)$的问题被转化为了求解前向概率$\alpha_T(i)$的问题。由前向概率的定义可知：</p>
<script type="math/tex; mode=display">\begin{aligned}
\alpha_1(i)&=\pi_ib_{io_1}  \\
\alpha_2(i)&=[\sum_{j=1}^{N}\alpha_1(j)a_{ji}]\times b_{io_2} \\
\alpha_3(i)&=[\sum_{j=1}^{N}\alpha_2(j)a_{ji}]\times b_{io_3} \\
\end{aligned}</script><p>依次此类推可得如下递推公式：</p>
<script type="math/tex; mode=display">\alpha_{t+1}(i)=[\sum_{j=1}^{N}\alpha_t(j)a_{ji}]\times b_{io_{t+1}}</script><p>因此可以递推求得：</p>
<script type="math/tex; mode=display">\alpha_{T}(i)=[\sum_{j=1}^{N}\alpha_{T-1}(j)a_{ji}]\times b_{io_{T}}</script><h5 id="后向算法"><a href="#后向算法" class="headerlink" title="后向算法"></a>后向算法</h5><p>同前向算法一样，首先定义<strong>后向概率</strong>：给定隐马尔可夫模型$\lambda$，定义在时刻$t$状态为$q_i$的条件下，从$t+1$到$T$的部分观测序列为$o_{t+1},o_{t+2},…,o_T$的概率为后向概率，记作：</p>
<script type="math/tex; mode=display">\beta_t(i)=P(o_{t+1},o_{t+2},...,o_T\vert i_t=q_i,\lambda)</script><p><center>
<img src="./hmm-backward.png">
</center><br>由后向概率的定义可知：</p>
<script type="math/tex; mode=display">\begin{aligned}
\beta_T(i)&=1  \\
\beta_{T-1}(i)&=\sum_{j=1}^{N}a_{ij}b_{jo_T}\beta_T(j) \\
\beta_{T-2}(i)&=\sum_{j=1}^{N}a_{ij}b_{jo_{T-1}}\beta_{T-1}(j) \\
\end{aligned}</script><p>依次类推可得递推公式：</p>
<script type="math/tex; mode=display">\beta_t(i)=\sum_{j=1}^{N}a_{ij}b_{jo_{t+1}}\beta_{t+1}(j)</script><p>根据递推公式可求得$\beta_1(i)$，又</p>
<script type="math/tex; mode=display">P(O\vert \lambda)=\sum_{i=1}^{N}\pi_ib_{io_1}\beta_1(i)</script><p>所以也可求得$P(O\vert \lambda)$。<br></p>
<p>综上可以看出前向算法和后向算法都是先计算局部概率，然后递推到全局，每一时刻的概率计算都会用上前一时刻计算出的结果，整体的时间复杂度大约为$O(TN^2)$，明显小于直接计算法的$O(TN^T)$。<br></p>
<p><strong>利用前向概率和后向概率，可以得到关于单个状态和两个状态概率的一些计算公式</strong>：</p>
<ol>
<li>给定模型参数$\lambda$和观测$O$，在时刻$t$处于状态$q_i$的概率，记<script type="math/tex; mode=display">\gamma_t(i)=P(i_t=q_i\vert O,\lambda)</script>可以通过前向概率和后向概率进行计算，推导如下：<script type="math/tex; mode=display">\gamma_t(i)=P(i_t=q_i\vert O,\lambda)=\cfrac{P(i_t=q_i,O\vert \lambda)}{P(O\vert\lambda)}</script>又由前向概率和后向概率的定义可知：<script type="math/tex; mode=display">\alpha_t(i)\beta_t(i)=P(i_t=q_i,O\vert\lambda)</script>所以<script type="math/tex; mode=display">\gamma_t(i)=\cfrac{P(i_t=q_i,O\vert \lambda)}{P(O\vert\lambda)}=\cfrac{P(i_t=q_i,O\vert \lambda)}{\sum_{j=1}^NP(i_t=q_j,O\vert \lambda)}=\cfrac{\alpha_t(i)\beta_t(i)}{\sum_{j=1}^N\alpha_t(j)\beta_t(j)} \tag{A.1}</script></li>
<li>给定模型参数$\lambda$和观测$O$，在时刻$t$处于状态$q_i$且在时刻$t+1$处于状态$q_j$的概率，记<script type="math/tex; mode=display">\xi_t(i,j)=P(i_t=q_i,i_{t+1}=q_j\vert O,\lambda)</script>可以通过前向后向概率进行计算，推导如下：<script type="math/tex; mode=display">\xi_t(i,j)=\cfrac{P(i_t=q_i,i_{t+1}=q_j,O\vert\lambda)}{P(O\vert\lambda)}=\cfrac{P(i_t=q_i,i_{t+1}=q_j,O\vert\lambda)}{\sum_{i=1}^N\sum_{j=1}^NP(i_t=q_i,i_{t+1}=q_j,O\vert\lambda)}</script>而<script type="math/tex; mode=display">P(i_t=q_i,i_{t+1}=q_j,O\vert\lambda)=\alpha_t(i)a_{ij}b_{jo_{t+1}}\beta_{t+1}(j)</script>所以<script type="math/tex; mode=display">\xi_t(i,j)=\cfrac{\alpha_t(i)a_{ij}b_{jo_{t+1}}\beta_{t+1}(j)}{\sum_{i=1}^N\sum_{j=1}^N\alpha_t(i)a_{ij}b_{jo_{t+1}}\beta_{t+1}(j)}\tag{A.2}</script></li>
</ol>
<h3 id="学习问题"><a href="#学习问题" class="headerlink" title="学习问题"></a>学习问题</h3><h5 id="监督学习方法"><a href="#监督学习方法" class="headerlink" title="监督学习方法"></a>监督学习方法</h5><p>假设已给出训练数据包含$S$个长度相同的观测序列和对应的状态序列$\{(O_1,I_1),(O_2,I_2),…,(O_S,I_S)\}$，那么可以利用极大似然估计法来估计隐马尔可夫模型的参数，具体方法如下：</p>
<ul>
<li>转移概率$a_{ij}$的估计：<script type="math/tex; mode=display">a_{ij}=\cfrac{A_{ij}}{\sum_{j=1}^NA_{ij}}</script>其中，$A_{ij}$为样本中时刻$t$处于状态$q_i$而到时刻$t+1$转移到状态$q_j$的频数；</li>
<li>观测概率$b_{jk}$的估计：<script type="math/tex; mode=display">b_{jk}=\cfrac{B_{jk}}{\sum_{k=1}^MB_{jk}}</script>其中，$B_{jk}$为样本中状态为$q_j$，其对应观测为$v_k$的频数；</li>
<li>初始状态概率$\pi_i$的估计为$S$个样本中初始状态为$q_i$的<strong>频率</strong>。</li>
</ul>
<p>显然此训练数据中的状态序列数据通常是需要人工标注出来的，因此代价较高，所以非监督学习的方法更为实用，例如Baum-Welch算法。</p>
<h5 id="Baum-Welch算法"><a href="#Baum-Welch算法" class="headerlink" title="Baum-Welch算法"></a>Baum-Welch算法</h5><p>如果只有观测序列数据$O=(o_1,o_2,…,o_T)$，而没有状态序列数据$I=(i_1,i_2,…,i_T)$，那么隐马尔可夫模型就是一个含有隐变量的概率模型：</p>
<script type="math/tex; mode=display">P(O|\lambda)=\sum_I P(O\vert I,\lambda)P(I\vert \lambda)</script><p>如果要对它进行参数估计，则可以采用<strong>EM算法</strong>来实现，具体步骤如下：</p>
<h6 id="1-确定完全数据的对数似然函数"><a href="#1-确定完全数据的对数似然函数" class="headerlink" title="1.确定完全数据的对数似然函数"></a>1.确定完全数据的对数似然函数</h6><p>此时观测数据为$O=(o_1,o_2,…,o_T)$，未观测数据为$I=(i_1,i_2,…,i_T)$，则完全数据为$(O,I)=(o_1,o_2,…,o_T,i_1,i_2,…,i_T)$，完全数据的对数似然函数为：</p>
<script type="math/tex; mode=display">\ln P(O,I\vert \lambda)</script><p>其中，$P(O,I\vert \lambda)=\pi_{i_1}b_{i_1o_1}a_{i_1i_2}b_{i_2o_2}\cdots a_{i_{T-1}i_T}b_{i_To_T}$，所以可以进一步推得：</p>
<script type="math/tex; mode=display">\begin{aligned}
\ln P(O,I\vert \lambda)&=\ln (\pi_{i_1}b_{i_1o_1}a_{i_1i_2}b_{i_2o_2}\cdots a_{i_{T-1}i_T}b_{i_To_T}) \\
&=\ln \pi_{i_1} + \sum_{t=1}^{T-1}\ln a_{i_t i_{t+1}} + \sum_{t=1}^{T}\ln b_{i_t o_t} \\
\end{aligned}</script><h6 id="2-EM算法E步：求-Q-函数-Q-lambda-bar-lambda"><a href="#2-EM算法E步：求-Q-函数-Q-lambda-bar-lambda" class="headerlink" title="2.EM算法E步：求$Q$函数$Q(\lambda,\bar{\lambda})$"></a>2.EM算法E步：求$Q$函数$Q(\lambda,\bar{\lambda})$</h6><script type="math/tex; mode=display">Q(\lambda,\bar{\lambda})=\sum_I P(I\vert O,\bar{\lambda})\ln P(O,I\vert \lambda)</script><p>其中，$\bar{\lambda}$是隐马尔可夫模型参数的当前估计值，$\lambda$是要极大化的隐马尔可夫模型参数。为了便于后续计算，$Q$函数还可以作如下恒等变形：</p>
<script type="math/tex; mode=display">\begin{aligned}
Q(\lambda,\bar{\lambda})&=\sum_I P(I\vert O,\bar{\lambda})\ln P(O,I\vert \lambda) \\
&=\sum_I \cfrac{P(I\vert O,\bar{\lambda})P(O\vert\bar{\lambda})}{P(O\vert\bar{\lambda})}\ln P(O,I\vert \lambda) \\
&=\sum_I \cfrac{P(O,I\vert\bar{\lambda})}{P(O\vert\bar{\lambda})}\ln P(O,I\vert \lambda)
\end{aligned}</script><p>由于接下来仅极大化$\lambda$，所以$P(O\vert\bar{\lambda})$可以看做常数项进行略去，所以$Q$函数可以进一步化简为：</p>
<script type="math/tex; mode=display">\begin{aligned}
Q(\lambda,\bar{\lambda})&=\sum_I P(O,I\vert\bar{\lambda})\ln P(O,I\vert \lambda) \\
&=\sum_I P(O,I\vert\bar{\lambda})\left(\ln \pi_{i_1} + \sum_{t=1}^{T-1}\ln a_{i_t i_{t+1}} + \sum_{t=1}^{T}\ln b_{i_t o_t}\right) \\
&=\sum_I P(O,I\vert\bar{\lambda})\ln \pi_{i_1} + \sum_I P(O,I\vert\bar{\lambda})\left(\sum_{t=1}^{T-1}\ln a_{i_t i_{t+1}}\right)+ \sum_I P(O,I\vert\bar{\lambda})\left(\sum_{t=1}^{T}\ln b_{i_t o_t}\right)
\end{aligned}</script><h6 id="3-EM算法M步：极大化-Q-函数"><a href="#3-EM算法M步：极大化-Q-函数" class="headerlink" title="3.EM算法M步：极大化$Q$函数"></a>3.EM算法M步：极大化$Q$函数</h6><p>由于要极大化的参数在上式中单独地出现在3个项中，所以只需对各项分别极大化。</p>
<ol>
<li>上述$Q$函数中的第1项可以写成：<script type="math/tex; mode=display">\begin{aligned}
\sum_I P(O,I\vert\bar{\lambda})\ln \pi_{i_1} &=\sum_{i=1}^N \left\{\ln\pi_{i}\cdot\left(\sum_{i_2,i_3,...,i_T} P(O,i_1=q_i,i_2,i_3,...,i_T\vert\bar{\lambda})\right)\right\} \\
&=\sum_{i=1}^N \left\{\ln\pi_{i}\cdot P(O,i_1=q_i\vert\bar{\lambda})\right\} \\
&=\sum_{i=1}^N\ln\pi_{i}P(O,i_1=q_i\vert\bar{\lambda})
\end{aligned}</script>由于$\pi_i$需要满足约束$\sum_{i=1}^N\pi_i=1$，利用拉格朗日乘子法，写出拉格朗日函数：<script type="math/tex; mode=display">\sum_{i=1}^N\ln\pi_{i}P(O,i_1=q_i\vert\bar{\lambda})+\eta\left(\sum_{i=1}^N\pi_i-1\right)</script>对其关于$\pi_i$求偏导并令结果为0：<script type="math/tex; mode=display">\cfrac{\partial}{\partial\pi_i}\left[\sum_{i=1}^N\ln\pi_{i}P(O,i_1=q_i\vert\bar{\lambda})+\eta\left(\sum_{i=1}^N\pi_i-1\right)\right]=0</script>得<script type="math/tex; mode=display">P(O,i_1=q_i\vert\bar{\lambda})+\eta\pi_i=0\tag{B.1}</script>对上式关于$i$求和可得：<script type="math/tex; mode=display">\begin{aligned}
\sum_{i=1}^N\left[P(O,i_1=q_i\vert\bar{\lambda})+\eta\pi_i\right]&=0 \\
\sum_{i=1}^NP(O,i_1=q_i\vert\bar{\lambda})+\sum_{i=1}^N\eta\pi_i&=0 \\
P(O\vert\bar{\lambda})+\eta\cdot 1&=0 \\
\end{aligned}</script>解得<script type="math/tex; mode=display">\eta=-P(O\vert\bar{\lambda})</script>将其代回式（B.1）可得：<script type="math/tex; mode=display">P(O,i_1=q_i\vert\bar{\lambda})-P(O\vert\bar{\lambda})\cdot\pi_i=0</script><script type="math/tex; mode=display">\pi_i = \cfrac{P(O,i_1=q_i\vert\bar{\lambda})}{P(O\vert\bar{\lambda})}</script><script type="math/tex; mode=display">\pi_i=\gamma_1(i)</script>其中，$\gamma_1(i)$由式（A.1）给出。</li>
<li>上述$Q$函数中的第2项可以写成：<script type="math/tex; mode=display">\begin{aligned} 
\sum_I P(O,I\vert\bar{\lambda})\left(\sum_{t=1}^{T-1}\ln a_{i_t i_{t+1}}\right)&=\sum_{t=1}^{T-1}\left\{\sum_{i=1}^N\sum_{j=1}^N\left[\ln a_{ij}\cdot\left(\sum_{i_1,i_2,...,i_{t-1},i_{t+2},...,i_T}P(O,i_1,i_2,...,i_t=q_i,i_{t+1}=q_j,...,i_T\vert\bar{\lambda})\right)\right]\right\} \\
&=\sum_{t=1}^{T-1}\left\{\sum_{i=1}^N\sum_{j=1}^N\left[\ln a_{ij}\cdot P(O,i_t=q_i,i_{t+1}=q_j\vert\bar{\lambda})\right]\right\} \\
&=\sum_{t=1}^{T-1}\sum_{i=1}^N\sum_{j=1}^N\ln a_{ij}P(O,i_t=q_i,i_{t+1}=q_j\vert\bar{\lambda})
\end{aligned}</script>由于$a_{ij}$满足约束$\sum_{j=1}^Na_{ij}=1$，同样利用拉格朗日乘子法，写出拉格朗日函数：<script type="math/tex; mode=display">\sum_{t=1}^{T-1}\sum_{i=1}^N\sum_{j=1}^N\ln a_{ij}P(O,i_t=q_i,i_{t+1}=q_j\vert\bar{\lambda})+\eta\left(\sum_{j=1}^Na_{ij}-1\right)</script>对其关于$a_{ij}$求偏导并令结果为0：<script type="math/tex; mode=display">\cfrac{\partial}{\partial a_{ij}}\left[\sum_{t=1}^{T-1}\sum_{i=1}^N\sum_{j=1}^N\ln a_{ij}P(O,i_t=q_i,i_{t+1}=q_j\vert\bar{\lambda})+\eta\left(\sum_{j=1}^Na_{ij}-1\right)\right]=0</script>得<script type="math/tex; mode=display">\sum_{t=1}^{T-1}P(O,i_t=q_i,i_{t+1}=q_j\vert\bar{\lambda})+\eta a_{ij}=0\tag{B.2}</script>对上式关于$j$求和可得：<script type="math/tex; mode=display">\begin{aligned} 
\sum_{j=1}^N\sum_{t=1}^{T-1}P(O,i_t=q_i,i_{t+1}=q_j\vert\bar{\lambda})+\sum_{j=1}^N\eta a_{ij}&=0 \\
\sum_{t=1}^{T-1}P(O,i_t=q_i\vert\bar{\lambda})+\eta\cdot 1&=0 \\
\end{aligned}</script>解得：<script type="math/tex; mode=display">\eta=-\sum_{t=1}^{T-1}P(O,i_t=q_i\vert\bar{\lambda})</script>将其代回式（B.2）可得：<script type="math/tex; mode=display">\sum_{t=1}^{T-1}P(O,i_t=q_i,i_{t+1}=q_j\vert\bar{\lambda})-\sum_{t=1}^{T-1}P(O,i_t=q_i\vert\bar{\lambda}) \cdot a_{ij}=0</script><script type="math/tex; mode=display">a_{ij}=\cfrac{\sum_{t=1}^{T-1}P(O,i_t=q_i,i_{t+1}=q_j\vert\bar{\lambda})}{\sum_{t=1}^{T-1}P(O,i_t=q_i\vert\bar{\lambda})}</script>分子分母同时除以$P(O|\bar{\lambda})$，所以<script type="math/tex; mode=display">a_{ij}=\cfrac{\cfrac{\sum_{t=1}^{T-1}P(O,i_t=q_i,i_{t+1}=q_j\vert\bar{\lambda})}{P(O|\bar{\lambda})}}{\cfrac{\sum_{t=1}^{T-1}P(O,i_t=q_i\vert\bar{\lambda})}{P(O|\bar{\lambda})}}=\cfrac{\sum_{t=1}^{T-1}P(i_t=q_i,i_{t+1}=q_j\vert O,\bar{\lambda})}{\sum_{t=1}^{T-1}P(i_t=q_i\vert O,\bar{\lambda})}=\cfrac{\sum_{t=1}^{T-1}\xi_t(i,j)}{\sum_{t=1}^{T-1}\gamma_t(i)}</script>其中，$\xi_t(i,j)$由式（A.2）给出，$\gamma_t(i)$由式（A.1）给出。</li>
<li>上述$Q$函数中的第3项可以写成：<script type="math/tex; mode=display">\begin{aligned}
\sum_I P(O,I\vert\bar{\lambda})\left(\sum_{t=1}^{T}\ln b_{i_t o_t}\right)&=\sum_{t=1}^{T}\left\{\sum_{j=1}^N\left[\ln b_{jo_t}\cdot\left(\sum_{i_1,i_2,...,i_{t-1},i_{t+1},...,i_T}P(O,i_1,i_2,...,i_t=q_j,...,i_T\vert\bar{\lambda})\right)\right]\right\} \\
&=\sum_{t=1}^{T}\left\{\sum_{j=1}^N\left[\ln b_{jo_t}\cdot P(O,i_t=q_j\vert\bar{\lambda})\right]\right\} \\
&=\sum_{t=1}^{T}\sum_{j=1}^N\ln b_{jo_t}P(O,i_t=q_j\vert\bar{\lambda}) \\
\end{aligned}</script>由于$b_{jk}$满足约束$\sum_{k=1}^M b_{jk}=1$，同样利用拉格朗日乘子法，写出拉格朗日函数：<script type="math/tex; mode=display">\sum_{t=1}^{T}\sum_{j=1}^N\ln b_{jo_t}P(O,i_t=q_j\vert\bar{\lambda})+\eta\left(\sum_{k=1}^M b_{jk}-1\right)</script>对其关于$b_{jk}$求偏导并令结果为0：<script type="math/tex; mode=display">\cfrac{\partial}{\partial b_{jk}}\left[\sum_{t=1}^{T}\sum_{j=1}^N\ln b_{jo_t}P(O,i_t=q_j\vert\bar{\lambda})+\eta\left(\sum_{k=1}^M b_{jk}-1\right)\right]=0</script>得<script type="math/tex; mode=display">\sum_{t=1}^{T}P(O,i_t=q_j\vert\bar{\lambda})\mathbb{I}(o_t=v_k)+\eta b_{jk}=0 \tag{B.3}</script>其中，$\mathbb{I}(o_t=v_k)$为指示函数。对上式关于$k$求和可得：<script type="math/tex; mode=display">\begin{aligned}
\sum_{k=1}^M\sum_{t=1}^{T}P(O,i_t=q_j\vert\bar{\lambda})\mathbb{I}(o_t=v_k)+\sum_{k=1}^M\eta b_{jk}&=0 \\
\sum_{t=1}^{T}P(O,i_t=q_j\vert\bar{\lambda})+\eta\cdot 1&=0 
\end{aligned}</script>解得：<script type="math/tex; mode=display">\eta=-\sum_{t=1}^{T}P(O,i_t=q_j\vert\bar{\lambda})</script>将其代回式（B.3）可得：<script type="math/tex; mode=display">\sum_{t=1}^{T}P(O,i_t=q_j\vert\bar{\lambda})\mathbb{I}(o_t=v_k)-\sum_{t=1}^{T}P(O,i_t=q_j\vert\bar{\lambda})\cdot b_{jk}=0</script><script type="math/tex; mode=display">b_{jk}=\cfrac{\sum_{t=1}^{T}P(O,i_t=q_j\vert\bar{\lambda})\mathbb{I}(o_t=v_k)}{\sum_{t=1}^{T}P(O,i_t=q_j\vert\bar{\lambda})}</script>分子分母同时除以$P(O|\bar{\lambda})$，所以<script type="math/tex; mode=display">b_{jk}=\cfrac{\cfrac{\sum_{t=1}^{T}P(O,i_t=q_j\vert\bar{\lambda})\mathbb{I}(o_t=v_k)}{P(O|\bar{\lambda})}}{\cfrac{\sum_{t=1}^{T}P(O,i_t=q_j\vert\bar{\lambda})}{P(O|\bar{\lambda})}}=\cfrac{\sum_{t=1}^{T}P(i_t=q_j\vert O,\bar{\lambda})\mathbb{I}(o_t=v_k)}{\sum_{t=1}^{T}P(i_t=q_j\vert O,\bar{\lambda})}=\cfrac{\sum_{t=1,o_t=v_k}^T\gamma_t(j)}{\sum_{t=1}^{T}\gamma_t(j)}</script>其中，$\gamma_t(j)$由式（A.1）给出。</li>
</ol>
<h3 id="预测问题"><a href="#预测问题" class="headerlink" title="预测问题"></a>预测问题</h3><h5 id="近似算法"><a href="#近似算法" class="headerlink" title="近似算法"></a>近似算法</h5><p>近似算法思想：在每个时刻$t$选择在该时刻最有可能出现的状态$i_t^*$，从而得到一个状态序列$I^*=(i_1^*,i_2^*,…,i_T^*)$，将它作为预测的结果。具体算法如下：<br><br>给定隐马尔可夫模型$\lambda$和观测序列$O$，在时刻$t$处于状态$q_i$的概率$\gamma_t(i)$是</p>
<script type="math/tex; mode=display">\gamma_t(i)=\cfrac{\alpha_t(i)\beta_t(i)}{\sum_{j=1}^N\alpha_t(j)\beta_t(j)}</script><p>在每一时刻$t$最有可能的状态$i_t^*$是</p>
<script type="math/tex; mode=display">i_t^*=\arg\max\limits_{1\leq i \leq N}[\gamma_t(i)],\quad t=1,2,...,T</script><p>从而得到状态序列$I^*=(i_1^*,i_2^*,…,i_T^*)$。<br><br>近似算法的优点是计算简单，其缺点是不能保证预测的状态序列整体是最有可能的状态序列，因为预测的序列可能有实际不发生的部分，也即可能存在状态转移概率$a_{i^*j^*}=0$的相邻状态$i^*$和$j^*$出现。<strong>尽管如此，近似算法仍然是有用的。</strong></p>
<h5 id="维特比算法"><a href="#维特比算法" class="headerlink" title="维特比算法"></a>维特比算法</h5><p>维特比算法实际是用<strong>动态规划</strong>解隐马尔可夫模型预测问题，即用动态规划求概率最大路径，这时一条路径对应着一个状态序列。具体算法如下：<br><br>定义在时刻$t$状态为$q_i$的所有单个路径$(i_1,i_2,…,i_t)$中概率最大值为</p>
<script type="math/tex; mode=display">\delta_t(i)=\max\limits_{i_1,i_2,..,i_{t-1}}P(o_1,...,o_t,i_1,...,i_{t-1},i_t=q_i),\quad i=1,2,...,N</script><p>由上述定义可知：</p>
<script type="math/tex; mode=display">\begin{aligned}
\delta_1(i)&=\pi_ib_{io_1} \\
\delta_2(i)&=\max\limits_{1\leq j\leq N}[\delta_1(j)a_{ji}]b_{io_2} \\
\delta_3(i)&=\max\limits_{1\leq j\leq N}[\delta_2(j)a_{ji}]b_{io_3} \\
\end{aligned}</script><p>依次此类推可得如下递推公式：</p>
<script type="math/tex; mode=display">\delta_{t}(i)=\max\limits_{1\leq j\leq N}[\delta_{t-1}(j)a_{ji}]b_{io_t}</script><p>同时再定义在时刻$t$状态为$q_i$的所有单个路径$(i_1,i_2,…,i_{t-1},i_t)$中概率最大的路径的第$t-1$个结点为</p>
<script type="math/tex; mode=display">\psi_t(i)=\arg\max\limits_{1\leq j\leq N}[\delta_{t-1}(j)a_{ji}]</script><p>因此，取$i_T^*=\arg\max\limits_{i}[\delta_T(i)]$，则$i_{T-1}^*=\psi_T(i_T^*),i_{T-2}^*=\psi_{T-1}(i_{T-1}^*),…,i_1^*=\psi_2(i_2^*)$，具体例子参见<a href="#ref1">[1]</a>第10章例10.3。</p>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p><span id="ref1">[1] 李航.《统计学习方法》</span></p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;隐马尔可夫模型的定义-1&quot;&gt;&lt;a href=&quot;#隐马尔可夫模型的定义-1&quot; class=&quot;headerlink&quot; title=&quot;隐马尔可夫模型的定义[1]&quot;&gt;&lt;/a&gt;隐马尔可夫模型的定义&lt;sup&gt;&lt;a href=&quot;#ref1&quot;&gt;[1]&lt;/a&gt;&lt;/sup&gt;&lt;/h3&gt;
    
    </summary>
    
      <category term="机器学习" scheme="http://sm1les.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="概率图模型" scheme="http://sm1les.com/tags/%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B/"/>
    
      <category term="隐马尔可夫模型" scheme="http://sm1les.com/tags/%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B/"/>
    
      <category term="HMM" scheme="http://sm1les.com/tags/HMM/"/>
    
  </entry>
  
  <entry>
    <title>EM算法的两种推导方式</title>
    <link href="http://sm1les.com/2019/03/13/expectation-maximization/"/>
    <id>http://sm1les.com/2019/03/13/expectation-maximization/</id>
    <published>2019-03-13T07:51:10.000Z</published>
    <updated>2019-07-22T01:59:19.471Z</updated>
    
    <content type="html"><![CDATA[<p>EM算法有两种常见的推导方式，一种是李航老师在《统计学习方法》里面给出的，另一种是吴恩达老师在CS229课上讲到的，两种推导方式各有千秋，但都殊途同归，下面对这两种推导方式进行一个总结。由于两种推导方式里都用到了一个经典的不等式——Jensen不等式<sup><a href="#ref1">[1]</a></sup>，所以下面先铺垫一下Jensen不等式。Jensen不等式的定义如下：<br>若$f$是<strong>凸函数</strong>，则</p>
<script type="math/tex; mode=display">f\left(t x_1 + (1-t)x_2\right)\leq tf(x_1)+(1-t)f(x_2)</script><p>其中$t\in [0,1]$，若将$x$推广到$n$个时同样成立，即</p>
<script type="math/tex; mode=display">f(t_1 x_1 + t_2x_2+...+t_nx_n)\leq t_1f(x_1)+t_2f(x_2)+...+t_nf(t_n)</script><p>其中$t_1,t_2,…,t_n\in[0,1],t_1+t_2+…+t_n=1$。此不等式在概率论中通常以如下形式出现</p>
<script type="math/tex; mode=display">\varphi(E[X])\leq E[\varphi(X)]</script><p>其中$X$是一个随机变量，$\varphi$为凸函数，$E[X]$为随机变量$X$的期望。同理，若$f$和$\varphi$是<strong>凹函数</strong>，则只需将不等式中的$\leq$换成$\geq$即可。</p>
<h3 id="EM算法的由来"><a href="#EM算法的由来" class="headerlink" title="EM算法的由来"></a>EM算法的由来</h3><p>假设现有一批独立同分布的样本数据$\{x_1,x_2,…,x_m\}$，它们是由某个含有隐变量的模型$p(x,z;\theta)$生成，现尝试用极大似然估计法估计此模型的参数。由对数似然函数的定义可知此时的对数似然函数为（假设$z$为离散型）</p>
<script type="math/tex; mode=display">\begin{aligned} 
LL(\theta) &=\sum_{i=1}^{m} \ln p(x_i; \theta) \\ 
&=\sum_{i=1}^{m} \ln \sum_{z_i} p(x_i, z_i; \theta) 
\end{aligned}</script><p>显然，此时$LL(\theta)$里含有未知的隐变量$z$以及和（$z$为离散型时）或者积分（$z$为连续型时）的对数，因此无法按照传统方法直接求出使得$LL(\theta)$达到最大值的模型参数$\theta$，而EM算法则给出了一种迭代的方法来完成对$LL(\theta)$的极大化。下面给出EM算法的两种推导方式：</p>
<h3 id="《统计学习方法》版-2"><a href="#《统计学习方法》版-2" class="headerlink" title="《统计学习方法》版[2]"></a>《统计学习方法》版<sup><a href="#ref2">[2]</a></sup></h3><p>设$X=\{x_1,x_2,…,x_m\},Z=\{z_1,z_2,…,z_m\}$，则对数似然函数可以改写为</p>
<script type="math/tex; mode=display">\begin{aligned} 
LL(\theta)&=\ln P(X\vert \theta)\\
&=\ln \sum_Z P(X,Z\vert\theta)\\
&=\ln \left(\sum_Z P(X\vert Z,\theta)P(Z\vert \theta)\right)
\end{aligned}</script><p>EM算法采用的是通过迭代逐步近似极大化$L(\theta)$：假设第$t$次迭代时$\theta$的估计值是$\theta^{(t)}$，我们希望第$t+1$次迭代时的$\theta$能使$LL(\theta)$增大，也即$LL(\theta)&gt;LL(\theta^{(t)})$。为此，考虑两者的差</p>
<script type="math/tex; mode=display">\begin{aligned}
LL(\theta)-LL(\theta^{(t)})&=\ln \left(\sum_Z P(X\vert Z,\theta)P(Z\vert \theta)\right)-\ln P(X\vert\theta^{(t)}) \\
&=\ln \left(\sum_Z P(Z\vert X,\theta^{(t)}) \cfrac{P(X\vert Z,\theta)P(Z\vert \theta)}{P(Z\vert X,\theta^{(t)})}\right)-\ln P(X\vert\theta^{(t)})
\end{aligned}</script><p>由上述Jensen不等式可得</p>
<script type="math/tex; mode=display">\begin{aligned}
LL(\theta)-LL(\theta^{(t)})
&\geq \sum_Z P(Z\vert X,\theta^{(t)})\ln \cfrac{P(X\vert Z,\theta)P(Z\vert \theta)}{P(Z\vert X,\theta^{(t)})}-\ln P(X\vert\theta^{(t)}) \\
&= \sum_Z P(Z\vert X,\theta^{(t)})\ln \cfrac{P(X\vert Z,\theta)P(Z\vert \theta)}{P(Z\vert X,\theta^{(t)})}-1\cdot \ln P(X\vert\theta^{(t)}) \\
&= \sum_Z P(Z\vert X,\theta^{(t)})\ln \cfrac{P(X\vert Z,\theta)P(Z\vert \theta)}{P(Z\vert X,\theta^{(t)})}-\sum_Z P(Z\vert X,\theta^{(t)})\cdot \ln P(X\vert\theta^{(t)}) \\
&=\sum_Z P(Z\vert X,\theta^{(t)}) \left( \ln \cfrac{P(X\vert Z,\theta)P(Z\vert \theta)}{P(Z\vert X,\theta^{(t)})} - \ln P(X\vert\theta^{(t)}) \right)\\
&= \sum_Z P(Z\vert X,\theta^{(t)})\ln \cfrac{P(X\vert Z,\theta)P(Z\vert \theta)}{P(Z\vert X,\theta^{(t)})P(X\vert\theta^{(t)})}
\end{aligned}</script><p>令</p>
<script type="math/tex; mode=display">B(\theta,\theta^{(t)})=LL(\theta^{(t)})+\sum_Z P(Z\vert X,\theta^{(t)})\ln \cfrac{P(X\vert Z,\theta)P(Z\vert \theta)}{P(Z\vert X,\theta^{(t)})P(X\vert\theta^{(t)})}</script><p>则</p>
<script type="math/tex; mode=display">LL(\theta)\geq B(\theta,\theta^{(t)})</script><p>即$B(\theta,\theta^{(t)})$是$LL(\theta)$的下界，此时若设$\theta^{(t+1)}$能使得$B(\theta,\theta^{(t)})$达到极大，也即</p>
<script type="math/tex; mode=display">B(\theta^{(t+1)},\theta^{(t)}) \geq B(\theta,\theta^{(t)})</script><p>由于$LL(\theta^{(t)})=B(\theta^{(t)},\theta^{(t)})$，那么可以进一步推得</p>
<script type="math/tex; mode=display">LL(\theta^{(t+1)})\geq B(\theta^{(t+1)},\theta^{(t)})\geq B(\theta^{(t)},\theta^{(t)})=LL(\theta^{(t)})</script><script type="math/tex; mode=display">LL(\theta^{(t+1)})\geq LL(\theta^{(t)})</script><p>因此，任何能使得$B(\theta,\theta^{(t)})$增大的$\theta$，也可以使得$LL(\theta)$增大，于是问题就转化为了求解能使得$B(\theta,\theta^{(t)})$达到极大的$\theta^{(t+1)}$，即</p>
<script type="math/tex; mode=display">\begin{aligned}
\theta^{(t+1)}&=\mathop{\arg\max}_{\theta}B(\theta,\theta^{(t)}) \\
&=\mathop{\arg\max}_{\theta}\left( LL(\theta^{(t)})+\sum_Z P(Z\vert X,\theta^{(t)})\ln \cfrac{P(X\vert Z,\theta)P(Z\vert \theta)}{P(Z\vert X,\theta^{(t)})P(X\vert\theta^{(t)})}\right)
\end{aligned}</script><p>略去对$\theta$极大化而言是常数的项：</p>
<script type="math/tex; mode=display">\begin{aligned}
\theta^{(t+1)}&=\mathop{\arg\max}_{\theta}\left(\sum_Z P(Z\vert X,\theta^{(t)})\ln\left( P(X\vert Z,\theta)P(Z\vert \theta)\right)\right) \\
&=\mathop{\arg\max}_{\theta}\left(\sum_Z P(Z\vert X,\theta^{(t)})\ln P(X,Z\vert \theta)\right) \\
&=\mathop{\arg\max}_{\theta}Q(\theta,\theta^{(t)})
\end{aligned}</script><p>到此即完成了EM算法的一次迭代，求出的$\theta^{(t+1)}$作为下一次迭代的初始$\theta^{(t)}$。综上所述即可总结出EM算法的“E步”和“M步”分别为：</p>
<p><strong>E步：</strong>计算完全数据的对数似然函数$\ln P(X,Z\vert \theta)$关于在给定观测数据$X$和当前参数$\theta^{(t)}$下对未观测数据$Z$的条件概率分布$ P(Z\vert X,\theta^{(t)})$的期望，也即$Q(\theta,\theta^{(t)})$：</p>
<script type="math/tex; mode=display">Q(\theta,\theta^{(t)})=E_Z[\ln P(X,Z\vert \theta)\vert X,\theta^{(t)}]=\sum_Z P(Z\vert X,\theta^{(t)})\ln P(X,Z\vert \theta)</script><p><strong>M步：</strong>求使得$Q(\theta,\theta^{(t)})$达到极大的$\theta^{(t+1)}$。</p>
<h3 id="CS229版-3"><a href="#CS229版-3" class="headerlink" title="CS229版[3]"></a>CS229版<sup><a href="#ref3">[3]</a></sup></h3><p>设$z_i$的概率质量函数为$Q_i(z_i)$，则$LL(\theta)$可以作如下恒等变形</p>
<script type="math/tex; mode=display">\begin{aligned} 
LL(\theta) &=\sum_{i=1}^{m} \ln p(x_i; \theta) \\ 
&=\sum_{i=1}^{m} \ln \sum_{z_i} p(x_i, z_i; \theta) \\
&=\sum_{i=1}^{m} \ln \sum_{z_i} Q_i(z_i)\cfrac{p(x_i, z_i; \theta)}{Q_i(z_i)} \\
\end{aligned}</script><p>其中$\sum_{z_i} Q_i(z_i)\cfrac{p(x_i, z_i; \theta)}{Q_i(z_i)}$可以看做是对$\cfrac{p(x_i, z_i; \theta)}{Q_i(z_i)}$关于$z_i$求期望，也即</p>
<script type="math/tex; mode=display">\sum_{z_i} Q_i(z_i)\cfrac{p(x_i, z_i; \theta)}{Q_i(z_i)}=E_{z_i}\left[\cfrac{p(x_i, z_i; \theta)}{Q_i(z_i)}\right]</script><p>那么由Jensen不等式可得</p>
<script type="math/tex; mode=display">\ln\left(E_{z_i}\left[\cfrac{p(x_i, z_i; \theta)}{Q_i(z_i)}\right]\right)\geq E_{z_i}\left[\ln\left(\cfrac{p(x_i, z_i; \theta)}{Q_i(z_i)}\right)\right]</script><script type="math/tex; mode=display">\ln\sum_{z_i} Q_i(z_i)\cfrac{p(x_i, z_i; \theta)}{Q_i(z_i)}\geq \sum_{z_i} Q_i(z_i)\ln\cfrac{p(x_i, z_i; \theta)}{Q_i(z_i)}</script><p>将此式代入$LL(\theta)$可得</p>
<script type="math/tex; mode=display">\begin{aligned} 
LL(\theta) &=\sum_{i=1}^{m} \ln \sum_{z_i} Q_i(z_i)\cfrac{p(x_i, z_i; \theta)}{Q_i(z_i)} \\
&\geq \sum_{i=1}^{m}\sum_{z_i} Q_i(z_i)\ln\cfrac{p(x_i, z_i; \theta)}{Q_i(z_i)}
\end{aligned}</script><p>若令$B(\theta)=\sum\limits_{i=1}^{m}\sum\limits_{z_i} Q_i(z_i)\ln\cfrac{p(x_i, z_i; \theta)}{Q_i(z_i)}$，则此时$B(\theta)$为$LL(\theta)$的下界函数，因此想要极大化$LL(\theta)$可以通过极大化$B(\theta)$来间接极大化$LL(\theta)$，然而对于$B(\theta)$而言，$LL(\theta)$就是其上界，所以极大化$B(\theta)$最理想的状态就是使其等于$LL(\theta)$。根据Jensen不等式的性质可知，当且仅当$\cfrac{p(x_i, z_i; \theta)}{Q_i(z_i)}$恒等于某个<strong>常量</strong>$c$时，不等式才能取到等号，也即</p>
<script type="math/tex; mode=display">\begin{aligned} 
LL(\theta)&=\sum_{i=1}^{m} \ln \sum_{z_i} Q_i(z_i)\cfrac{p(x_i, z_i; \theta)}{Q_i(z_i)}\qquad(A.1)\\
&=\sum_{i=1}^{m}\sum_{z_i} Q_i(z_i)\ln\cfrac{p(x_i, z_i; \theta)}{Q_i(z_i)}\\
&=B(\theta) \\
&s.t.\quad\cfrac{p(x_i, z_i; \theta)}{Q_i(z_i)}=c
\end{aligned}</script><p>因此，任意选取满足$\cfrac{p(x_i, z_i; \theta)}{Q_i(z_i)}=c$的$Q_i(z_i)$都能使得$B(\theta)$达到最大值，由于$Q_i(z_i)$是$z_i$的概率质量函数，所以$Q_i(z_i)$同时也满足约束$0\leq Q_i(z_i)\leq 1,\sum\limits_{z_i} Q_i(z_i)=1$，那么可以推得</p>
<script type="math/tex; mode=display">\cfrac{p(x_i, z_i; \theta)}{Q_i(z_i)}=c</script><script type="math/tex; mode=display">p(x_i, z_i; \theta)=c\cdot Q_i(z_i)</script><script type="math/tex; mode=display">\sum_{z_i}p(x_i, z_i; \theta)=c\cdot \sum_{z_i}Q_i(z_i)</script><script type="math/tex; mode=display">\sum_{z_i}p(x_i, z_i; \theta)=c</script><script type="math/tex; mode=display">\cfrac{p(x_i, z_i; \theta)}{Q_i(z_i)}=\sum_{z_i}p(x_i, z_i; \theta)</script><script type="math/tex; mode=display">Q_i(z_i)=\cfrac{p(x_i, z_i; \theta)}{\sum\limits_{z_i}p(x_i, z_i; \theta)}=\cfrac{p(x_i, z_i; \theta)}{p(x_i; \theta)}=p(z_i|x_i; \theta)</script><p>所以，当且仅当$Q_i(z_i)=p(z_i|x_i; \theta)$时$B(\theta)$取到最大值。若将$Q_i(z_i)=p(z_i|x_i; \theta)$代回$LL(\theta)$可以推得如下结论</p>
<script type="math/tex; mode=display">\begin{aligned} 
LL(\theta) &=\sum_{i=1}^{m} \ln \sum_{z_i} Q_i(z_i)\cfrac{p(x_i, z_i; \theta)}{Q_i(z_i)} &\qquad(A.2.1)\\
&=\sum_{i=1}^{m} \ln \sum_{z_i}p(z_i|x_i; \theta)\cfrac{p(x_i, z_i; \theta)}{p(z_i|x_i; \theta)} &\qquad(A.2.2)\\
&=\sum_{i=1}^{m}\sum_{z_i} p(z_i|x_i; \theta)\ln\cfrac{p(x_i, z_i; \theta)}{p(z_i|x_i; \theta)}&\qquad(A.2.3)\\
&=\max\{B(\theta)\} &\qquad(A.2.4)\\
&\geq B(\theta)&\qquad(A.2.5)\\
&=\sum\limits_{i=1}^{m}\sum\limits_{z_i} Q_i(z_i)\ln\cfrac{p(x_i, z_i; \theta)}{Q_i(z_i)}&\qquad(A.2.6)
\end{aligned}</script><p>其中，（A.2.3）由（A.1）推得。假设<strong>已知</strong>第$t$次迭代的参数为$\theta^{(t)}$，而第$t+1$次迭代的参数$\theta^{(t+1)}$通过如下方式求得</p>
<script type="math/tex; mode=display">\begin{aligned} 
\theta^{(t+1)}&=\arg\max_{\theta}\sum_{i=1}^{m}\sum_{z_i} p(z_i|x_i;\theta^{(t)})\ln\cfrac{p(x_i, z_i; \theta)}{p(z_i|x_i; \theta^{(t)})} \qquad(A.3) \\
&=\arg\max_{\theta}\sum_{i=1}^{m}\sum_{z_i} p(z_i|x_i;\theta^{(t)})\ln p(x_i, z_i; \theta)
\end{aligned}</script><p>那么可以推得</p>
<script type="math/tex; mode=display">\begin{aligned} 
LL(\theta^{(t+1)}) &=\sum_{i=1}^{m}\sum_{z_i} p(z_i|x_i; \theta^{(t+1)})\ln\cfrac{p(x_i, z_i; \theta^{(t+1)})}{p(z_i|x_i; \theta^{(t+1)})} &\qquad(A.4.1)\\
&\geq \sum_{i=1}^{m}\sum_{z_i} p(z_i|x_i; \theta^{(t)})\ln\cfrac{p(x_i, z_i; \theta^{(t+1)})}{p(z_i|x_i; \theta^{(t)})} &\qquad(A.4.2)\\
&\geq \sum_{i=1}^{m}\sum_{z_i} p(z_i|x_i; \theta^{(t)})\ln\cfrac{p(x_i, z_i; \theta^{(t)})}{p(z_i|x_i; \theta^{(t)})} &\qquad(A.4.3)\\
&=LL(\theta^{(t)})&\qquad(A.4.4)
\end{aligned}</script><p>其中，（A.4.1）由（A.2）推得；（A.4.2）由（A.2）推得；（A.4.3）由（A.3）推得；（A.4.4）由（A.2）推得。所以，若令</p>
<script type="math/tex; mode=display">Q(\theta,\theta^{(t)})=\sum_{i=1}^{m}\sum_{z_i} p(z_i|x_i; \theta^{(t)})\ln p(x_i, z_i; \theta)</script><p>那么由（A.4）可知，凡是能使得$Q(\theta,\theta^{(t)})$达到极大的$\theta^{(t+1)}$一定能使得$LL(\theta^{(t+1)})\geq LL(\theta^{(t)})$。综上所述即可总结出EM算法的“E步”和“M步”分别为：</p>
<p><strong>E步：</strong>令$Q_i(z_i)=p(z_i|x_i; \theta)$并写出$Q(\theta,\theta^{(t)})$；</p>
<p><strong>M步：</strong>求使得$Q(\theta,\theta^{(t)})$到达极大的$\theta^{(t+1)}$。</p>
<h3 id="证明两种推导方式中的Q函数相等"><a href="#证明两种推导方式中的Q函数相等" class="headerlink" title="证明两种推导方式中的Q函数相等"></a>证明两种推导方式中的Q函数相等</h3><script type="math/tex; mode=display">
\begin{aligned} Q(\theta|\theta^{(t)})&=\sum_Z P(Z|X,\theta^{(t)})\ln P(X,Z|\theta) \\
&=\sum_{z_1,z_2,...,z_m}\left\{\prod_{i=1}^mP(z_i|x_i,\theta^{(t)})\ln\left[ \prod_{i=1}^m P(x_i,z_i|\theta) \right] \right\} \\
&=\sum_{z_1,z_2,...,z_m}\left\{\prod_{i=1}^mP(z_i|x_i,\theta^{(t)})\left[ \sum_{i=1}^m\ln P(x_i,z_i|\theta) \right] \right\} \\
&=\sum_{z_1,z_2,...,z_m}\left\{\prod_{i=1}^mP(z_i|x_i,\theta^{(t)})\left[\ln P(x_1,z_1|\theta) + \ln P(x_2,z_2|\theta) +...+ \ln P(x_m,z_m|\theta)\right] \right\} \\
&=\sum_{z_1,z_2,...,z_m}\left[\prod_{i=1}^mP(z_i|x_i,\theta^{(t)})\cdot\ln P(x_1,z_1|\theta) \right]+...+\sum_{z_1,z_2,...,z_m}\left[\prod_{i=1}^mP(z_i|x_i,\theta^{(t)})\cdot\ln P(x_m,z_m|\theta) \right]  \\
\end{aligned}</script><p>其中$\sum\limits_{z_1,z_2,…,z_m}\left[\prod\limits_{i=1}^mP(z_i|x_i,\theta^{(t)})\cdot\ln P(x_1,z_1|\theta) \right] $可作如下恒等变形：</p>
<script type="math/tex; mode=display">\begin{aligned} 
&=\sum\limits_{z_1,z_2,...,z_m}\left[\prod_{i=2}^mP(z_i|x_i,\theta^{(t)})\cdot P(z_1|x_1,\theta^{(t)})\cdot\ln P(x_1,z_1|\theta) \right] \\
&=\sum_{z_1}\sum\limits_{z_2,...,z_m}\left[\prod_{i=2}^mP(z_i|x_i,\theta^{(t)})\cdot P(z_1|x_1,\theta^{(t)})\cdot\ln P(x_1,z_1|\theta) \right] \\
&=\sum_{z_1}P(z_1|x_1,\theta^{(t)})\ln P(x_1,z_1|\theta) \sum\limits_{z_2,...,z_m}\left[\prod_{i=2}^mP(z_i|x_i,\theta^{(t)}) \right] \\
&=\sum_{z_1}P(z_1|x_1,\theta^{(t)})\ln P(x_1,z_1|\theta)\sum\limits_{z_2,...,z_m}\left[\prod_{i=3}^mP(z_i|x_i,\theta^{(t)})\cdot P(z_2|x_2,\theta^{(t)}) \right] \\
&=\sum_{z_1}P(z_1|x_1,\theta^{(t)})\ln P(x_1,z_1|\theta) \left\{\sum\limits_{z_2}\sum\limits_{z_3,...,z_m}\left[\prod_{i=3}^mP(z_i|x_i,\theta^{(t)})\cdot P(z_2|x_2,\theta^{(t)}) \right]\right\} \\
&=\sum_{z_1}P(z_1|x_1,\theta^{(t)})\ln P(x_1,z_1|\theta) \left\{\sum_{z_2}P(z_2|x_2,\theta^{(t)}) \sum\limits_{z_3,...,z_m}\left[\prod_{i=3}^mP(z_i|x_i,\theta^{(t)})\right]\right\} \\
&=\sum_{z_1}P(z_1|x_1,\theta^{(t)})\ln P(x_1,z_1|\theta) \left\{\sum_{z_2}P(z_2|x_2,\theta^{(t)})\times\sum_{z_3}P(z_3|x_3,\theta^{(t)})\times...\times\sum_{z_m}P(z_m|x_m,\theta^{(t)})\right\} \\
&=\sum_{z_1}P(z_1|x_1,\theta^{(t)})\ln P(x_1,z_1|\theta)\times \left\{1\times1\times...\times1\right\} \\
&=\sum_{z_1}P(z_1|x_1,\theta^{(t)})\ln P(x_1,z_1|\theta)  \\
\end{aligned}</script><p>所以</p>
<script type="math/tex; mode=display">\sum\limits_{z_1,z_2,...,z_m}\left[\prod_{i=1}^mP(z_i|x_i,\theta^{(t)})\cdot\ln P(x_1,z_1|\theta) \right]=\sum_{z_1}P(z_1|x_1,\theta^{(t)})\ln P(x_1,z_1|\theta)</script><p>同理可得</p>
<script type="math/tex; mode=display">\begin{aligned} 
\sum\limits_{z_1,z_2,...,z_m}\left[\prod_{i=1}^mP(z_i|x_i,\theta^{(t)})\cdot\ln P(x_2,z_2|\theta) \right] &=\sum_{z_2}P(z_2|x_2,\theta^{(t)})\ln P(x_2,z_2|\theta) \\
&\vdots\\
\sum\limits_{z_1,z_2,...,z_m}\left[\prod_{i=1}^mP(z_i|x_i,\theta^{(t)})\cdot\ln P(x_m,z_m|\theta) \right] &=\sum_{z_m}P(z_m|x_m,\theta^{(t)})\ln P(x_m,z_m|\theta)
\end{aligned}</script><p>将上式代入$Q(\theta|\theta^{(t)})$可得</p>
<script type="math/tex; mode=display">\begin{aligned} 
Q(\theta|\theta^{(t)})&=\sum_{z_1,z_2,...,z_m}\left[\prod_{i=1}^mP(z_i|x_i,\theta^{(t)})\cdot\ln P(x_1,z_1|\theta) \right]+...+\sum_{z_1,z_2,...,z_m}\left[\prod_{i=1}^mP(z_i|x_i,\theta^{(t)})\cdot\ln P(x_m,z_m|\theta) \right]  \\
&=\sum_{z_1}P(z_1|x_1,\theta^{(t)})\ln P(x_1,z_1|\theta) +...+\sum_{z_m}P(z_m|x_m,\theta^{(t)})\ln P(x_m,z_m|\theta) \\
&=\sum_{i=1}^m\sum_{z_i}P(z_i|x_i,\theta^{(t)})\ln P(x_i,z_i|\theta)\\
\end{aligned}</script><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p><span id="ref1">[1] <a href="https://en.wikipedia.org/wiki/Jensen%27s_inequality" target="_blank" rel="noopener">Jensen’s inequality</a></span><br><span id="ref2">[2] 李航.《统计学习方法》第9章</span><br><span id="ref3">[3] Andrew Ng.CS229-notes8&lt;/a&gt;</span></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;EM算法有两种常见的推导方式，一种是李航老师在《统计学习方法》里面给出的，另一种是吴恩达老师在CS229课上讲到的，两种推导方式各有千秋，但都殊途同归，下面对这两种推导方式进行一个总结。由于两种推导方式里都用到了一个经典的不等式——Jensen不等式&lt;sup&gt;&lt;a href
    
    </summary>
    
      <category term="机器学习" scheme="http://sm1les.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="EM算法" scheme="http://sm1les.com/tags/EM%E7%AE%97%E6%B3%95/"/>
    
      <category term="Jensen不等式" scheme="http://sm1les.com/tags/Jensen%E4%B8%8D%E7%AD%89%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>梯度下降法与牛顿法</title>
    <link href="http://sm1les.com/2019/03/01/gradient-descent-and-newton-method/"/>
    <id>http://sm1les.com/2019/03/01/gradient-descent-and-newton-method/</id>
    <published>2019-03-01T03:21:35.000Z</published>
    <updated>2019-04-07T05:35:53.332Z</updated>
    
    <content type="html"><![CDATA[<h3 id="梯度下降法的泰勒公式推导-1-："><a href="#梯度下降法的泰勒公式推导-1-：" class="headerlink" title="梯度下降法的泰勒公式推导[1]："></a>梯度下降法的泰勒公式推导<sup><a href="#ref1">[1]</a></sup>：</h3><p>梯度下降法的目标是使得$f(x_t+\Delta x )&lt;f(x_t)$，由泰勒公式可知，$f(x)$在$x_t$点的一阶泰勒展开为：</p>
<script type="math/tex; mode=display">f(x) = f(x_t)+f’(x_t)(x-x_t)</script><p>则</p>
<script type="math/tex; mode=display">f(x_{t+1}) = f(x_t)+f’(x_t)(x_{t+1}-x_t)</script><p>又$x_{t+1}$可等价写作$x_t + \Delta x$，则上式可化为：</p>
<script type="math/tex; mode=display">f(x_t + \Delta x) = f(x_t)+f’(x_t) \cdot \Delta x</script><p>所以要想使得$f(x_t+\Delta x)$&lt;$f(x_t)$，$f’(x_t)\cdot\Delta x$必须小于0，此时$f’(x_t)$为定值，$\Delta x$为可变部分，于是可以令$\Delta x = -\eta \cdot f’(x_t)$，其中$\eta&gt;0$，则</p>
<script type="math/tex; mode=display">f’(x_t) \cdot \Delta x= -\eta(f’(x_t))^2<0</script><p>由此可以推得当$\Delta x = -\eta \cdot f’(x_t)$时，$f(x_t+\Delta x )&lt;f(x_t)$恒成立。</p>
<h3 id="牛顿法的泰勒公式推导-2-："><a href="#牛顿法的泰勒公式推导-2-：" class="headerlink" title="牛顿法的泰勒公式推导[2]："></a>牛顿法的泰勒公式推导<sup><a href="#ref2">[2]</a></sup>：</h3><p>对于无约束的<strong>凸优化</strong>问题</p>
<script type="math/tex; mode=display">\min\limits_{\boldsymbol{x} \in \mathbb{R}^n}f(\boldsymbol{x})</script><p>其中$\boldsymbol{x}^*$为目标函数的最小值点，也是极小值点，牛顿法利用极小值点的必要条件</p>
<script type="math/tex; mode=display">\nabla f(\boldsymbol{x}^*)=\boldsymbol{0}</script><p>从点$\boldsymbol{x}^t$开始，求$ f(\boldsymbol{x})$在$\boldsymbol{x}^t$点的二阶泰勒展开式的极小值点（仅当$\boldsymbol{x}^{t}$点的海赛矩阵（Hessian matrix）为正定矩阵时），作为下一次（第$t+1$次）的迭代值$\boldsymbol{x}^{t+1}$，直到某次迭代值$\boldsymbol{x}^{t+1}$使得$\parallel\nabla f(\boldsymbol{x}^{t+1})\parallel&lt;\epsilon$时停止迭代，其中$\epsilon$为自定义的精度要求，具体迭代步骤如下，由多元函数的泰勒展开式<sup><a href="#ref3">[3]</a></sup>可得$f(\boldsymbol{x})$在$\boldsymbol{x}^{t}$点的二阶泰勒展开式为：</p>
<script type="math/tex; mode=display">f(\boldsymbol{x})=f(\boldsymbol{x}^t)+g_t^T \cdot (\boldsymbol{x}-\boldsymbol{x}^t)+\cfrac{1}{2}(\boldsymbol{x}-\boldsymbol{x}^t)^T \cdot H_t \cdot (\boldsymbol{x}-\boldsymbol{x}^t)</script><p>其中$g_t$为$f(\boldsymbol{x})$在$\boldsymbol{x}^{t}$点的梯度值，$H_t$为$f(\boldsymbol{x})$在$\boldsymbol{x}^{t}$点的海赛矩阵值。对上式求导并令其等于$\boldsymbol{0}$可得：</p>
<script type="math/tex; mode=display">g_t + H_t \cdot (\boldsymbol{x}-\boldsymbol{x}^t)=\boldsymbol{0}</script><p>解得$\boldsymbol{x}=\boldsymbol{x}^t-H_t^{-1}g_t$，令其为下一次的迭代值，即$\boldsymbol{x}^{t+1}=\boldsymbol{x}^t-H_t^{-1}g_t$。<br>【注】：</p>
<ul>
<li>牛顿法是经典的求根方法，在最优化问题里，通常最值点也是极值点，所以目标函数$f(x)$的一阶导函数$f’(x)$在最值点处一定等于0，此时求目标函数$f(x)$最小值的问题转化为了求目标函数的一阶导函数$f’(x)$的根的问题<sup><a href="#ref4">[4]</a></sup>；</li>
<li>关于牛顿法和梯度下降法的效率对比：从本质上去看，牛顿法是二阶收敛，梯度下降是一阶收敛，所以牛顿法就更快。如果更通俗地说的话，比如你想找一条最短的路径走到一个盆地的最底部，梯度下降法每次只从你当前所处位置选一个坡度最大的方向走一步，牛顿法在选择方向时，不仅会考虑坡度是否够大，还会考虑你走了一步之后，坡度是否会变得更大。所以，可以说牛顿法比梯度下降法看得更远一点，能更快地走到最底部。（牛顿法目光更加长远，所以少走弯路；相对而言，梯度下降法只考虑了局部的最优，没有全局思想。）根据wiki上的解释，从几何上说，牛顿法就是用一个二次曲面去拟合你当前所处位置的局部曲面，而梯度下降法是用一个平面去拟合当前的局部曲面，通常情况下，二次曲面的拟合会比平面更好，所以牛顿法选择的下降路径会更符合真实的最优下降路径<sup><a href="#ref5">[5]</a></sup>。<center>
<img src="./gdandnewton.jpg"><br>
红色为牛顿法的迭代路径，绿色为梯度下降法的迭代路径
</center>

</li>
</ul>
<h3 id="参考文献："><a href="#参考文献：" class="headerlink" title="参考文献："></a>参考文献：</h3><p><span id="ref1">[1] <a href="https://zhuanlan.zhihu.com/p/36564434" target="_blank" rel="noopener">梯度下降法 —— 经典的优化方法</a></span><br><span id="ref2">[2]  李航.《统计学习方法》</span><br><span id="ref3">[3] <a href="https://blog.csdn.net/red_stone1/article/details/70260070" target="_blank" rel="noopener">多元函数的泰勒(Taylor)展开式</a></span><br><span id="ref4">[4] <a href="http://sofasofa.io/forum_main_post.php?postid=1000966" target="_blank" rel="noopener">牛顿法到底是一阶优化算法还是二阶优化算法？</a></span><br><span id="ref5">[5] <a href="http://www.cnblogs.com/maybe2030/p/4751804.html" target="_blank" rel="noopener">常见的几种最优化方法</a></span></p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;梯度下降法的泰勒公式推导-1-：&quot;&gt;&lt;a href=&quot;#梯度下降法的泰勒公式推导-1-：&quot; class=&quot;headerlink&quot; title=&quot;梯度下降法的泰勒公式推导[1]：&quot;&gt;&lt;/a&gt;梯度下降法的泰勒公式推导&lt;sup&gt;&lt;a href=&quot;#ref1&quot;&gt;[1]&lt;/
    
    </summary>
    
      <category term="最优化" scheme="http://sm1les.com/categories/%E6%9C%80%E4%BC%98%E5%8C%96/"/>
    
    
      <category term="梯度下降法" scheme="http://sm1les.com/tags/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/"/>
    
      <category term="牛顿法" scheme="http://sm1les.com/tags/%E7%89%9B%E9%A1%BF%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>Logistic回归与最大熵</title>
    <link href="http://sm1les.com/2019/01/17/logistic-regression-and-maximum-entropy/"/>
    <id>http://sm1les.com/2019/01/17/logistic-regression-and-maximum-entropy/</id>
    <published>2019-01-17T14:22:03.000Z</published>
    <updated>2019-07-23T13:44:54.738Z</updated>
    
    <content type="html"><![CDATA[<p>根据Wikipedia上的资料显示，Logistic回归的起源主要有以下几大历程：最早由Pierre François Verhulst在对人口增长情况进行研究时提出Logistic function<sup><a href="#ref1">[1]</a></sup>，后来Joseph Berkson在其基础上提出Logit function<sup><a href="#ref2">[2]</a></sup>，再后来David Cox用Logit function来做二分类的回归分析，进而提出了Logistic regression<sup><a href="#ref3">[3]</a></sup>，详细的起源历程参见<a href="#ref4">[4]</a>和<a href="#ref5">[5]</a>。Logistic回归除了按照它的起源从对数几率的角度解释以外，还有业界比较认同的从最大熵的角度来解释，下面给出Logistic回归从最大熵角度的解释。</p>
<p>对于数据集$\{(\boldsymbol x_1,y_1),(\boldsymbol x_2,y_2)…(\boldsymbol x_m,y_m)\}$，其中$\boldsymbol x_i\in \mathbb{R}^n,i=1,2…m$，Logistic回归在对随机变量$y\vert\boldsymbol x$建模的时候是假设其取值仅为0或1，即$y_i\in\{0,1\}$，且$y\vert\boldsymbol x$有固定但未知的期望$\mu$，所以根据<strong>最大熵原理</strong>，此时可以假设$y\vert\boldsymbol x$服从伯努利分布（原因参见<a href="/2019/01/13/exponential-family-and-maximum-entropy">《指数族分布与最大熵》</a>），接着我们想用线性模型来对$y\vert\boldsymbol x$的概率$p(y\vert\boldsymbol x)$进行建模，于是可以通过广义线性模型（Generalized Linear Models）<sup><a href="#ref6">[6]</a></sup>的建模方法得到我们想要的模型。广义线性模型的建模步骤如下<sup><a href="#ref7">[7]</a></sup>：</p>
<ul>
<li>在给定$\boldsymbol x$的条件下，假设随机变量$y\vert\boldsymbol x$服从某个指数族分布（Exponential family）<sup><a href="#ref8">[8]</a></sup>；</li>
<li>假设该指数族分布中的自然参数$\eta(\boldsymbol\theta)$和$\boldsymbol x$呈线性关系，即$\eta(\boldsymbol\theta) = \boldsymbol w^T \boldsymbol x$；</li>
<li>建模出的模型为$T(y\vert\boldsymbol x)$的期望$E[T(y\vert\boldsymbol x)]$的表达式。</li>
</ul>
<p>在使用上述步骤对$y$进行建模前，先证明一下伯努利分布属于指数族分布：<br>伯努利分布的分布律如下：</p>
<script type="math/tex; mode=display">p(x)=\mu^x (1-\mu)^{1-x}</script><p>其中$x\in\{0,1\}$，$\mu$为$x=1$的概率也为$x$的期望，即$p(1)=E[x]=\mu$。对其进行恒等变形可得：</p>
<script type="math/tex; mode=display">
\begin{aligned}    
p(x) &= \mu^x (1-\mu)^{1-x} \\
&= \exp(x \ln \mu+(1−x) \ln(1−\mu)) \\
&= \exp \left((\ln(\cfrac{\mu}{1-\mu}))x+\ln(1-\mu) \right)
\end{aligned}</script><p>对照<a href="/2019/01/13/exponential-family-and-maximum-entropy">《指数族分布与最大熵》</a>中指数族分布的一般形式可知，伯努利分布属于指数族分布，且对应的指数族分布参数为：</p>
<script type="math/tex; mode=display">
\begin{aligned}    
\boldsymbol\theta &=\mu &(A.1)\\
\eta(\boldsymbol\theta)&= \ln(\cfrac{\mu}{1-\mu}) &(A.2)\\
T(x) &= x &(A.3)\\
A(\boldsymbol\theta) &= -\ln(1-\mu) &(A.4)\\
h(x) &= 1 &(A.5)
\end{aligned}</script><p>现在便可以根据上述广义线性模型的建模步骤对$y$进行建模：首先$y$服从伯努利分布，属于指数族分布，接着假设伯努利分布中的自然参数$\eta(\boldsymbol\theta)=\boldsymbol w^T \boldsymbol x$，再接着计算充分统计量$T(y\vert\boldsymbol x)$的期望表达式：</p>
<script type="math/tex; mode=display">
\begin{aligned}    
E[T(y\vert\boldsymbol x)]&= E[y\vert\boldsymbol x] \\
&= \mu \\
&= \cfrac{1}{1+e^{(-\eta(\boldsymbol\theta))}} \\
&= \cfrac{1}{1+e^{(-\boldsymbol w^T \boldsymbol x)}}
\end{aligned}</script><p>其中，第1个等式由式（A.3）导出；第2个等式是因为$y\vert\boldsymbol x$服从伯努利分布，所以$E(y\vert\boldsymbol x)=1*p(1\vert\boldsymbol x)+0*(1-p(1\vert\boldsymbol x))=p(1\vert\boldsymbol x)=\mu$；第3个等式是由式(A.2)导出，所以现在建模出的模型为：</p>
<script type="math/tex; mode=display">E(y\vert\boldsymbol x)=p(1\vert\boldsymbol x)=\cfrac{1}{1+e^{(-\boldsymbol w^T \boldsymbol x)}}</script><p>显然此即为Logistic回归模型。<br>【注】：</p>
<ul>
<li>上述广义线性模型的建模步骤是一种固定的建模方法，也就是说在构建广义线性模型时，我们唯一要做的就是假设$y\vert\boldsymbol x$服从何种<strong>指数族分布</strong>，通常是以最大熵原理为准则来假设$y\vert\boldsymbol x$的分布，例如在做二分类问题时通常假设$y\vert\boldsymbol x$服从伯努利分布，在做回归问题时通常假设$y\vert\boldsymbol x$服从高斯分布，在做网站访问量预测时通常假设$y\vert\boldsymbol x$服从泊松分布。在确定$y\vert\boldsymbol x$的分布后，只需按照上述步骤即可构建出一个广义线性模型；</li>
<li>除了从伯努利分布属于最大熵分布来解释以外，还有学者直接通过最大熵原理推导出Logistic回归，详细推导过程参见<a href="#ref9">[9]</a>，文中推导思路如下：首先说明Logistic回归是多分类模型类别总数k=2时的特例，所以只要用最大熵原理推导出多分类模型也就推导出了Logistic回归。于是先证明了多分类模型的Softmax函数在取得最优参数时类似一个指示函数，接着便以此为约束条件用最大熵原理推导出Softmax函数，也即推导出多分类模型，进而也就推导出了Logistic回归。类似的直接从最大熵原理出发的推导还有<a href="#ref10">[10]</a>；</li>
<li>Logistic回归也可以从贝叶斯的角度解释，参见<a href="#ref11">[11]</a></li>
<li>本文启发自知乎上的讨论：<a href="https://www.zhihu.com/question/35322351" target="_blank" rel="noopener">为什么 LR 模型要使用 sigmoid 函数，背后的数学原理是什么？</a></li>
</ul>
<h3 id="参考文献："><a href="#参考文献：" class="headerlink" title="参考文献："></a>参考文献：</h3><p><span id="ref1">[1] <a href="https://en.wikipedia.org/wiki/Logistic_function" target="_blank" rel="noopener">Logistic function</a></span><br><span id="ref2">[2] <a href="https://en.wikipedia.org/wiki/Logit" target="_blank" rel="noopener">Logit</a></span><br><span id="ref3">[3] <a href="https://en.wikipedia.org/wiki/Logistic_regression" target="_blank" rel="noopener">Logistic regression</a></span><br><span id="ref4">[4] <a href="https://chenrudan.github.io/blog/2016/01/09/logisticregression.html" target="_blank" rel="noopener">【机器学习算法系列之二】浅析Logistic Regression</a></span><br><span id="ref5">[5] Cramer J S . The Origins of Logistic Regression</span><br><span id="ref6">[6] <a href="https://en.wikipedia.org/wiki/Generalized_linear_model" target="_blank" rel="noopener">Generalized linear model</a></span><br><span id="ref7">[7] Andrew Ng. cs229-notes1</span><br><span id="ref8">[8] <a href="https://en.wikipedia.org/wiki/Exponential_family" target="_blank" rel="noopener">Exponential family</a></span><br><span id="ref9">[9] <a href="http://www. win-vector. com/dfiles/LogisticRegressionMaxEnt. pdf" target="_blank" rel="noopener">Mount, J.The equivalence of logistic regression and maximum entropy models</a></span><br><span id="ref10">[10] <a href="https://www.zhihu.com/question/24094554/answer/108271031" target="_blank" rel="noopener">如何理解最大熵模型里面的特征？ - Semiring的回答 - 知乎</a></span><br><span id="ref11">[11] <a href="http://charleshm.github.io/2016/03/LR-and-NB/" target="_blank" rel="noopener">Logistic Regression and Naive Bayes</a></span></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;根据Wikipedia上的资料显示，Logistic回归的起源主要有以下几大历程：最早由Pierre François Verhulst在对人口增长情况进行研究时提出Logistic function&lt;sup&gt;&lt;a href=&quot;#ref1&quot;&gt;[1]&lt;/a&gt;&lt;/sup&gt;，后来
    
    </summary>
    
      <category term="机器学习" scheme="http://sm1les.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="最大熵" scheme="http://sm1les.com/tags/%E6%9C%80%E5%A4%A7%E7%86%B5/"/>
    
      <category term="Logistic回归" scheme="http://sm1les.com/tags/Logistic%E5%9B%9E%E5%BD%92/"/>
    
      <category term="广义线性模型" scheme="http://sm1les.com/tags/%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>指数族分布与最大熵</title>
    <link href="http://sm1les.com/2019/01/13/exponential-family-and-maximum-entropy/"/>
    <id>http://sm1les.com/2019/01/13/exponential-family-and-maximum-entropy/</id>
    <published>2019-01-13T07:55:30.000Z</published>
    <updated>2019-06-28T14:38:45.279Z</updated>
    
    <content type="html"><![CDATA[<h3 id="最大熵原理"><a href="#最大熵原理" class="headerlink" title="最大熵原理"></a>最大熵原理</h3><p>最大熵原理是概率模型学习的一个准则，最大熵原理认为：学习概率模型时，在所有可能的概率模型（分布）中，熵最大的模型是最好的模型。通常用约束条件来确定概率模型的集合，所以，最大熵原理也可以表述为在满足约束条件的模型集合中选取熵最大的模型<sup><a href="#ref1">[1]</a></sup>。此处所说的“熵”为信息论中的信息熵，信息熵定义如下：</p>
<ul>
<li>信息量：<script type="math/tex; mode=display">I(X) = -log_bp(X)</script>其中，$b=2$时单位为bit，$b=e$时单位为nat，$b=10$时单位为ban.</li>
<li>信息熵是信息量的期望，即：<script type="math/tex; mode=display">H(X)=E[I(X)]=E[-log_bp(X)]</script>当$X$为离散型时：<script type="math/tex; mode=display">H(X)=-\sum_x p(x)log_bp(x)</script>当$X$为连续型时：<script type="math/tex; mode=display">H(X)=-\int_{-\infty}^{+\infty}p(x)log_bp(x)dx</script>其中$p(x)=p(X=x)$，当$X$为连续型时信息熵也称为微分熵，熵只依赖于$X$的分布，而与$X$的取值无关。</li>
</ul>
<h3 id="指数族分布"><a href="#指数族分布" class="headerlink" title="指数族分布"></a>指数族分布</h3><p>指数族（Exponential family）分布<sup><a href="#ref2">[2]</a></sup>是一类分布的总称，该类分布的分布律（概率密度函数）的一般形式如下：</p>
<script type="math/tex; mode=display">\begin{aligned}    
p(x;\boldsymbol\theta) &= \cfrac{1}{Z(\boldsymbol\theta)} h(x) \exp\left(\eta(\boldsymbol\theta)^T T(x) \right) \\
&= h(x) \exp\left(\eta(\boldsymbol\theta)^T T(x) − A(\boldsymbol\theta)\right)
\end{aligned}</script><p>其中，$\boldsymbol\theta$为指数族分布的参数，视具体的分布而定，既可以是向量也可以是标量，此处暂用向量的形式表示，$\eta(\boldsymbol\theta)$是关于$\boldsymbol\theta$的函数，称作自然参数 (natural parameter，也称canonical parameter)，$T(x)$为充分统计量（sufficient statistic），$Z(\boldsymbol\theta)=\exp(A(\boldsymbol\theta))$为配分函数（partition function），是用来保证分布律的累加和$\sum\limits_x p(x|\boldsymbol\theta)=1$或者概率密度的积分值$\int_{-\infty}^{+\infty}p(x|\boldsymbol\theta)=1$，$h(x)$为一个关于$x$的函数，常见的伯努利分布和正态分布均属于指数族分布，所有指数族分布以及每个分布的各项参数值参见<a href="#ref2">[2]</a>里的表格。指数族分布有个很重要的性质：在给定的约束条件下，指数族分布是信息熵（微分熵）最大的分布。例如：在已知$X\in\{0,1\}$且期望$E[X]=\mu$时，伯努利分布是熵最大的分布；在已知$X$的均值为$\mu$，方差为$\sigma^2$时，正态分布是熵最大的分布，其他最大熵分布参见<a href="#ref3">[3]</a>里的表格。</p>
<h5 id="指数族分布的最大熵推导："><a href="#指数族分布的最大熵推导：" class="headerlink" title="指数族分布的最大熵推导："></a>指数族分布的最大熵推导：</h5><p><strong>当$X$为离散型时</strong><sup><a href="#ref4">[4]</a></sup>：<br>若已知$X$满足如下约束条件：</p>
<script type="math/tex; mode=display">\sum_{k=1}^{n}\sum_{i=1}^{\vert X \vert} f_k(x_i)p(x_i) = F_k \qquad (A.1)</script><p>其中，$\vert X \vert$为$X$的可能取值个数，$n$为约束个数，$f_k(x_i)$为任意函数，$F_k$为已知常数，此时求$X$的最大熵分布等价于求解如下优化问题：</p>
<script type="math/tex; mode=display">\begin{aligned}    
\max\limits_{p}\quad&-\sum_{i=1}^{\vert X \vert} p(x_i)\ln p(x_i) \\
s.t.\quad &p(x_i)  \geq0 \\
&\sum_{i=1}^{\vert X \vert} p(x_i) = 1 \\
&\sum_{k=1}^{n}\sum_{i=1}^{\vert X \vert}  f_k(x_i)p(x_i) = F_k
\end{aligned}</script><p>其中信息熵的单位为nat，也即取$b=e$，对该优化问题用拉格朗日乘子法可得：</p>
<script type="math/tex; mode=display">\begin{aligned}    
L(p,\boldsymbol\lambda) &=-\sum_{i=1}^{\vert X \vert}p(x_i)\ln p(x_i)+\lambda_0(1-\sum_{i=1}^{\vert X \vert}p(x_i))+\sum_{k=1}^{n}\lambda_k\left(F_k-\sum_{i=1}^{\vert X \vert} f_k(x_i)p(x_i) \right) \\
&=\sum_{i=1}^{\vert X \vert} -p(x_i)\ln p(x_i)-\sum_{i=1}^{\vert X \vert} \lambda_0 p(x_i)-\sum_{i=1}^{\vert X \vert}\sum_{k=1}^{n}\lambda_kf_k(x_i)p(x_i)+\lambda_0+\sum_{k=1}^{n}\lambda_kF_k \\
&=\sum_{i=1}^{\vert X \vert}\left(-p(x_i)\ln p(x_i)-\lambda_0 p(x_i)-\sum_{k=1}^{n}\lambda_kf_k(x_i)p(x_i)\right)+\lambda_0+\sum_{k=1}^{n}\lambda_kF_k
\end{aligned}</script><p>其中，$p$可以看作一个分布律向量，也即$p=[p(x_1),p(x_2),…,p(x_{\vert X \vert})]$，$\boldsymbol\lambda=[\lambda_0,\lambda_1,…,\lambda_n]^T$为拉格朗日乘子向量，对$L(p,\boldsymbol\lambda)$关于$p$求偏导等价于分别对所有的$p(x_i)$求偏导：</p>
<script type="math/tex; mode=display">\begin{aligned}
\cfrac{\partial L(p,\boldsymbol\lambda)}{\partial p(x_1)}&=-\ln p(x_1)-1-\lambda_0-\sum_{k=1}^{n}\lambda_kf_k(x_1) \\
\cfrac{\partial L(p,\boldsymbol\lambda)}{\partial p(x_2)}&=-\ln p(x_2)-1-\lambda_0-\sum_{k=1}^{n}\lambda_kf_k(x_2) \\
\vdots \\
\cfrac{\partial L(p,\boldsymbol\lambda)}{\partial p(x_{\vert X \vert})}&=-\ln p(x_{\vert X \vert})-1-\lambda_0-\sum_{k=1}^{n}\lambda_kf_k(x_{\vert X \vert}) 
\end{aligned}</script><p>则</p>
<script type="math/tex; mode=display">\cfrac{\partial L(p,\boldsymbol\lambda)}{\partial p(x_i)}=-\ln p(x_i)-1-\lambda_0-\sum_{k=1}^{n}\lambda_kf_k(x_i)</script><p>令上式等于0解得：</p>
<script type="math/tex; mode=display">p(x_i) =\exp(-1-\lambda_0-\sum\limits_{k=1}^{n}\lambda_kf_k(x_i))</script><p>又由约束条件$\sum\limits_{i=1}^{\vert X \vert} p(x_i) = 1$可得：</p>
<script type="math/tex; mode=display">\begin{aligned}    
\sum_{i=1}^{\vert X \vert} \exp(-1-\lambda_0-\sum\limits_{k=1}^{n}\lambda_kf_k(x_i))= 1 \\
\sum_{i=1}^{\vert X \vert} \cfrac{\exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(x_i))}{e^{(1+\lambda_0)}}= 1 \\
e^{(1+\lambda_0)}=\sum_{i=1}^{\vert X \vert} \exp(-\sum_{k=1}^{n}\lambda_kf_k(x_i))
\end{aligned}</script><p>将其代入$p(x_i)$可得：</p>
<script type="math/tex; mode=display">p(x_i) =\cfrac{\exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(x_i))}{\sum\limits_{i=1}^{\vert X \vert} \exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(x_i))}</script><p>此式为$X$取到各个值$x_i$的概率，可以从中抽象出$X$的分布律为：</p>
<script type="math/tex; mode=display">\begin{aligned}    
p(x) &=\cfrac{\exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(x))}{\sum\limits_x\exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(x))} \qquad (A.2) \\
&=\cfrac{1}{Z}\exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(x))
\end{aligned}</script><p>其中$Z=\sum\limits_x\exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(x))$，此时$p(x)$的表达式显然符合指数族分布的一般形式。（注：上述推导过程是结合<a href="#ref1">[1]</a>中例6.2和<a href="#ref4">[4]</a>中9.2.6所述内容而成）<br><strong>当$X$为连续型时</strong>：<br>若已知$X$满足如下约束条件：</p>
<script type="math/tex; mode=display">\sum_{k=1}^{n}\int_{-\infty}^{+\infty}f_k(x)p(x)dx = F_k \qquad (B.1)</script><p>其中，$n$为约束个数，$f_k(x)$为任意函数，$F_k$为已知常数，此时求$X$的最大熵分布等价于求解如下优化问题：</p>
<script type="math/tex; mode=display">\begin{aligned}    
\max\limits_{p}\quad&-\int_{-\infty}^{+\infty}p(x)\ln p(x)dx \\
s.t.\quad &p(x)  \geq0 \\
&\int_{-\infty}^{+\infty}p(x)dx = 1 \\
&\int_{-\infty}^{+\infty}f_k(x)p(x)dx = F_k
\end{aligned}</script><p>其中信息熵的单位为nat，也即取$b=e$，对该优化问题用拉格朗日乘子法可得：</p>
<script type="math/tex; mode=display">\begin{aligned}    
L(p,\boldsymbol\lambda) &=-\int_{-\infty}^{+\infty}p(x)\ln p(x)dx+\lambda_0(1-\int_{-\infty}^{+\infty}p(x)dx)+\sum_{k=1}^{n}\lambda_k\left(F_k-\int_{-\infty}^{+\infty}f_k(x)p(x)dx \right) \\
&=\int_{-\infty}^{+\infty}-p(x)\ln p(x)dx-\int_{-\infty}^{+\infty}\lambda_0 p(x)dx-\int_{-\infty}^{+\infty}\sum_{k=1}^{n}\lambda_kf_k(x)p(x)dx+\lambda_0+\sum_{k=1}^{n}\lambda_kF_k \\
&=\int_{-\infty}^{+\infty}\left(-p(x)\ln p(x)-\lambda_0 p(x)-\sum_{k=1}^{n}\lambda_kf_k(x)p(x)\right)dx+\lambda_0+\sum_{k=1}^{n}\lambda_kF_k
\end{aligned}</script><p>其中，$\int_{-\infty}^{+\infty}$可以看作$\sum\limits_x$，因此可以按照$X$为离散型时的推导方法推得$X$的分布律为：</p>
<script type="math/tex; mode=display">\begin{aligned}    
p(x) &=\cfrac{\exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(x))}{\int_{-\infty}^{+\infty}\exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(x))dx} \qquad (B.2)\\
&=\cfrac{1}{Z}\exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(x))
\end{aligned}</script><p>其中$Z=\int_{-\infty}^{+\infty}\exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(x))dx$。</p>
<h5 id="伯努利分布的最大熵推导："><a href="#伯努利分布的最大熵推导：" class="headerlink" title="伯努利分布的最大熵推导："></a>伯努利分布的最大熵推导：</h5><p><strong>“已知$X\in\{0,1\}$且期望$E[X]=\mu$时，伯努利分布是熵最大的分布”</strong>，证明如下：<br>已知$X\in\{0,1\}$，所以$X$属于离散型，则根据式（A.2）知$X$的分布律的一般形式为：</p>
<script type="math/tex; mode=display">p(x) =\cfrac{\exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(x))}{\exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(0))+\exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(1))}</script><p>又已知$E[X]=\mu$，其等价于如下约束条件：</p>
<script type="math/tex; mode=display">\sum_{i=1}^{\vert X \vert} x_ip(x_i) =\mu</script><p>所以对比式（A.2）可知，此时$n=1,f_1(x_i)=x_i,F_1=\mu$，代入$p(x)$可得：</p>
<script type="math/tex; mode=display">p(x) =\cfrac{e^{-\lambda_1 x}}{1+e^{-\lambda_1}}</script><p>再由$E[X]=\mu$可得：</p>
<script type="math/tex; mode=display">E[X]=0*p(0)+1*p(1)=p(1)=\cfrac{e^{-\lambda_1}}{1+e^{-\lambda_1}}=\mu</script><p>所以$X$的分布律为：</p>
<script type="math/tex; mode=display">\begin{aligned}    
p(0)&=1-\mu \\
p(1)&=\mu
\end{aligned}</script><p>显然此即为伯努利分布，证毕。</p>
<h5 id="正态分布的最大熵推导："><a href="#正态分布的最大熵推导：" class="headerlink" title="正态分布的最大熵推导："></a>正态分布的最大熵推导：</h5><p><strong>“已知$X$的均值为$\mu$，方差为$\sigma^2$时，正态分布是熵最大的分布”</strong>，证明如下<sup><a href="#ref5">[5]</a></sup>：<br>此时没有限定$X$的取值范围，则默认为$X\in(-\infty,+\infty)$的连续型，已知$X$的均值为$\mu$，方差为$\sigma^2$，其等价于如下约束条件：</p>
<script type="math/tex; mode=display">\int_{-\infty}^{+\infty}(x-\mu)^2p(x)dx = \sigma^2</script><p>所以对比式（B.1）可知，此时$n=1,f_1(x)=(x-\mu)^2,F_1=\sigma^2$，代入式（B.1）可得此时$X$的分布律：</p>
<script type="math/tex; mode=display">p(x) =\cfrac{\exp(-\lambda_1 (x-\mu)^2)}{\int_{-\infty}^{+\infty}\exp(-\lambda_1 (x-\mu)^2)dx}</script><p>再由$\int_{-\infty}^{+\infty}(x-\mu)^2p(x)dx = \sigma^2$解得：</p>
<script type="math/tex; mode=display">\lambda_1=\cfrac{1}{2\sigma^2}</script><p>代入$p(x)$中得：</p>
<script type="math/tex; mode=display">p(x) =\cfrac{1}{\sqrt{2\pi}\sigma}\exp\left(-\cfrac{(x-\mu)^2}{2\sigma^2}\right)</script><p>显然此即为正态分布，证毕。</p>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p><span id="ref1">[1] 李航.《统计学习方法》</span><br><span id="ref2">[2] <a href="https://en.wikipedia.org/wiki/Exponential_family" target="_blank" rel="noopener">Exponential family</a></span><br><span id="ref3">[3] <a href="https://en.wikipedia.org/wiki/Maximum_entropy_probability_distribution" target="_blank" rel="noopener">Maximum entropy probability distribution</a></span><br><span id="ref4">[4] Murphy K P. 《Machine Learning: A Probabilistic Perspective》</span><br><span id="ref5">[5] 周晓飞. 《统计机器学习》课程的课件</span></p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;最大熵原理&quot;&gt;&lt;a href=&quot;#最大熵原理&quot; class=&quot;headerlink&quot; title=&quot;最大熵原理&quot;&gt;&lt;/a&gt;最大熵原理&lt;/h3&gt;&lt;p&gt;最大熵原理是概率模型学习的一个准则，最大熵原理认为：学习概率模型时，在所有可能的概率模型（分布）中，熵最大的模型是最
    
    </summary>
    
      <category term="机器学习" scheme="http://sm1les.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="指数族分布" scheme="http://sm1les.com/tags/%E6%8C%87%E6%95%B0%E6%97%8F%E5%88%86%E5%B8%83/"/>
    
      <category term="最大熵" scheme="http://sm1les.com/tags/%E6%9C%80%E5%A4%A7%E7%86%B5/"/>
    
  </entry>
  
  <entry>
    <title>L1正则化和L2正则化</title>
    <link href="http://sm1les.com/2019/01/07/l1-and-l2-regularization/"/>
    <id>http://sm1les.com/2019/01/07/l1-and-l2-regularization/</id>
    <published>2019-01-07T09:35:09.000Z</published>
    <updated>2019-03-10T10:04:29.768Z</updated>
    
    <content type="html"><![CDATA[<p>正则化是结构风险最小化策略的实现，是在经验风险上加一个正则化项或罚项，正则化项一般是模型复杂度的单调递增函数，模型越复杂，正则化值就越大。例如模型参数向量的范数，正则化的一般形式如下<sup><a href="#ref1">[1]</a></sup>：</p>
<script type="math/tex; mode=display">\min \limits_{f\in\mathcal{F}} \left( \cfrac{1}{N} \sum_{N}^{i=1} L(y_i,f(x_i))+\lambda J(f) \right) \qquad (A.1)</script><p>其中，第1项是经验风险，第2项是正则化项，$\lambda$为调整两者之间关系的系数。常用的正则化项是模型参数向量的$L_1$范数和$L_2$范数，分别称作L1正则化和L2正则化。以线性回归为例，其L1正则化的损失函数为：</p>
<script type="math/tex; mode=display">J(\boldsymbol w)=\cfrac{1}{N} \sum_{N}^{i=1} (f(\boldsymbol x_i;\boldsymbol w)-y_i)^2+\lambda \Vert\boldsymbol w \Vert_1</script><p>其中$\Vert\boldsymbol w \Vert_1$为$\boldsymbol w$的$L_1$范数，同理可得L2正则化的损失函数为：</p>
<script type="math/tex; mode=display">J(\boldsymbol w)=\cfrac{1}{N} \sum_{N}^{i=1} (f(\boldsymbol x_i;\boldsymbol w)-y_i)^2+\lambda \Vert\boldsymbol w \Vert_2^2</script><p>其中$\Vert\boldsymbol w \Vert_2$为$\boldsymbol w$的$L_2$范数，使用L1正则化或L2正则化的线性回归也称作<strong>LASSO回归</strong><sup><a href="#ref2">[2]</a></sup>或<strong>岭回归</strong><sup><a href="#ref3">[3]</a></sup>。<br>L1正则化和L2正则化最主要的不同之处在于前者更易得稀疏解，解释如下<sup><a href="#ref2">[2]</a></sup>：</p>
<h5 id="从优化问题的角度："><a href="#从优化问题的角度：" class="headerlink" title="从优化问题的角度："></a>从优化问题的角度：</h5><p>式(A.1)可以看作如下优化问题：</p>
<script type="math/tex; mode=display">\begin{aligned}
& \min\limits_{\boldsymbol w} \quad E_{emp}(\boldsymbol w) \\
& s.t.  \quad \lambda E_{reg}(\boldsymbol w) \leq \eta
\end{aligned}</script><p>其中$E_{emp}(\boldsymbol w)$是经验风险，$E_{reg}(\boldsymbol w)$是正则化项，$\eta$是自行设定的容忍度，此优化问题可以描述为：<strong>把$\boldsymbol w$的解限制一定范围内，同时使得经验风险尽可能小</strong>。L1正则化和L2正则化画图表示如下：</p>
<p><center>
<img src="./l1vsl2.png">
</center><br>其中，左图为L1正则化，右图为L2正则化，$\boldsymbol w^*$是$\boldsymbol w$的解，蓝色等高线为经验风险$E_{emp}(\boldsymbol w)$的取值，红色等高线为正则化项$E_{reg}(\boldsymbol w)$的取值，黄色区域是红色等高线的变化范围，也即$\boldsymbol w^*$的取值范围，默认内环等高线的值更小。从图中可以看出，红色等高线和蓝色等高线的<strong>切点</strong>即为优化问题的解$\boldsymbol w^*$，而且L1正则化相比于L2正则化更容易使得切点落在$\boldsymbol w$某个维度$w_i$的坐标轴上，从而导致另一个维度$w_j$的取值为0，从而更容易得到具有稀疏性的$\boldsymbol w^*$。</p>
<h5 id="从梯度的角度："><a href="#从梯度的角度：" class="headerlink" title="从梯度的角度："></a>从梯度的角度：</h5><p>L1正则化的损失函数一般形式为：</p>
<script type="math/tex; mode=display">J(\boldsymbol w)=L(\boldsymbol w)+\lambda \sum \vert w_i \vert \qquad (B.1)</script><p>L2正则化的损失函数一般形式为：</p>
<script type="math/tex; mode=display">J(\boldsymbol w)=L(\boldsymbol w)+\lambda \sum (w_i)^2 \qquad (B.2)</script><p>对式(B.1)关于$\boldsymbol w$某个维度$w_i$求偏导可得：</p>
<script type="math/tex; mode=display">\cfrac{\partial J(\boldsymbol w)}{\partial w_i}=\cfrac{\partial L(\boldsymbol w)}{\partial w_i}+\lambda sign (w_i)</script><p>对式(B.2)关于$\boldsymbol w$某个维度$w_i$求偏导可得：</p>
<script type="math/tex; mode=display">\cfrac{\partial J(\boldsymbol w)}{\partial w_i}=\cfrac{\partial L(\boldsymbol w)}{\partial w_i}+2\lambda w_i</script><p>当使用梯度下降法等此类根据$\boldsymbol w$的梯度来调整$\boldsymbol w$的算法时，若用L1正则化，$\boldsymbol w$的某个维度$w_i$的更新公式为：</p>
<script type="math/tex; mode=display">w_i:=w_i-\eta\cfrac{\partial J(\boldsymbol w)}{\partial w_i}=w_i-\eta\cfrac{\partial L(\boldsymbol w)}{\partial w_i}-\eta\lambda sign (w_i)</script><p>其中$\eta$为自行设定的学习率，从上式可以看出，$\eta\lambda sign (w_i)$的取值恒为$\pm\eta\lambda$，与$w_i$的大小无关，所以这就会导致即使$w_i$已经很小了但仍然以较高的梯度在变化，从而容易使得$w_i$取到0；若用L2正则化，则更新公式为：</p>
<script type="math/tex; mode=display">w_i:=w_i-\eta\cfrac{\partial J(\boldsymbol w)}{\partial w_i}=w_i-\eta\cfrac{\partial L(\boldsymbol w)}{\partial w_i}-2\eta\lambda w_i</script><p>显然此式中的$2\eta\lambda w_i$的大小与$w_i$相关，所以当$w_i$很小时变化的梯度也很小，不容易取到0，也就不容易得到稀疏解。</p>
<h5 id="从贝叶斯的角度："><a href="#从贝叶斯的角度：" class="headerlink" title="从贝叶斯的角度："></a>从贝叶斯的角度：</h5><p>贝叶斯学派常用的参数估计方法为最大后验估计（Maximum A Posteriori，MAP），最大后验估计法估计参数的公式为<sup><a href="#ref5">[5]</a></sup>：</p>
<script type="math/tex; mode=display">\begin{aligned}
\hat{\boldsymbol{w}} &= \mathop{\arg\max}_{\boldsymbol{w}}P(\boldsymbol{w} \vert \boldsymbol{y})\\
&= \mathop{\arg\max}_{\boldsymbol{w}}\log P(\boldsymbol{w} \vert \boldsymbol{y}) \\
&= \mathop{\arg\min}_{\boldsymbol{w}}-\log P(\boldsymbol{w} \vert \boldsymbol{y})
\end{aligned}</script><p>由贝叶斯公式可知$P(\boldsymbol{w} \vert \boldsymbol{y})=\cfrac{P(\boldsymbol{y} \vert \boldsymbol{w})\times P( \boldsymbol{w})}{P(\boldsymbol{y})}$，代入上式可得：</p>
<script type="math/tex; mode=display">\hat{\boldsymbol{w}} =\mathop{\arg\min}_{\boldsymbol{w}}-\log P(\boldsymbol{y} \vert \boldsymbol{w})-\log P(\boldsymbol{w})+\log P(\boldsymbol{y})</script><p>由于我们要求的是最优参数$\hat{\boldsymbol{w}}$，与$P(\boldsymbol{y})$无关，所以上式最后一项可以略去，进而得到损失函数为：</p>
<script type="math/tex; mode=display">J(\boldsymbol{w}) =-\log P(\boldsymbol{y} \vert \boldsymbol{w})-\log P(\boldsymbol{w})</script><p>其中$\log P(\boldsymbol{y} \vert \boldsymbol{w})$为对数似然函数，$P(\boldsymbol{w})$为我们对参数$\boldsymbol{w}$的先验估计，当我们先验估计参数$\boldsymbol{w}$服从均值为0方差为$\sigma^2$高斯分布时，即：</p>
<script type="math/tex; mode=display">\begin{aligned}
P(\boldsymbol{w}) &= \prod_{i=1}^{d}P(w_i)=\prod_{i=1}^{d}\cfrac{1}{\sqrt{2\pi}\sigma} \mathrm{exp}\left(-\cfrac{w_i^2}{2\sigma^2}\right) \\ 
\log P(\boldsymbol{w}) &= \sum_{i=1}^{d}\log\cfrac{1}{\sqrt{2\pi}\sigma} \mathrm{exp}\left(-\cfrac{w_i^2}{2\sigma^2}\right) \\
&= d \cdot \log\cfrac{1}{\sqrt{2\pi}\sigma} -\cfrac{1}{2\sigma^2} \cdot  \sum_{i=1}^{d}w_i^2 \\
&= d \cdot \log\cfrac{1}{\sqrt{2\pi}\sigma} -\cfrac{1}{2\sigma^2} \cdot  \Vert\boldsymbol{w}\Vert_2^2
\end{aligned}</script><p>代入损失函数$J(\boldsymbol{w})$可得：</p>
<script type="math/tex; mode=display">J(\boldsymbol{w}) = -\log P(\boldsymbol{y} \vert \boldsymbol{w})-d \cdot \log\cfrac{1}{\sqrt{2\pi}\sigma} +\cfrac{1}{2\sigma^2} \cdot  \Vert\boldsymbol{w}\Vert_2^2</script><p>同理$d \cdot \log\cfrac{1}{\sqrt{2\pi}\sigma}$与$\boldsymbol{w}$无关，可以略去，所以：</p>
<script type="math/tex; mode=display">J(\boldsymbol{w})=  -\log P(\boldsymbol{y} \vert \boldsymbol{w})+\cfrac{1}{2\sigma^2} \cdot  \Vert\boldsymbol{w}\Vert_2^2</script><p>此时可以看出<strong>采用高斯分布先验的最大后验估计=最大似然估计+L2正则项</strong>，同理可得<strong>采用拉普拉斯分布先验的最大后验估计=最大似然估计+L1正则项</strong>，观察高斯分布和拉普拉斯分布的概率密度函数图像可知，拉普拉斯分布更为稀疏，也即取到0的概率更大。</p>
<p><center>
<img src="./normalandlaplace.png" width="60%" height="60%"><br>
图中高斯分布和拉普拉斯分布的均值和方差均相同
</center><br>L1正则化和L2正则化还有如下不同之处：</p>
<ul>
<li>L1正则化自带特征选择的功能，这是由于L1正则化易得稀疏解导致的，因为稀疏解$\boldsymbol w^*$的某些维度$w_i=0$，从而达到了特征选择的功能；</li>
<li>L1正则化的解不稳定，也即可能会有多个解，这是因为L1正则化的红色等高线容易与经验风险的蓝色等高线产生多个切点，例如上图中的蓝色等高线若不为圆形曲线，而是直线时，此时极有可能与L1正则化的红色等高线重合，从而产生多个解；</li>
<li>L1正则化不易求解，这是因为绝对值函数通常都不好求解；</li>
<li>L1正则化相对于L2正则化对异常值敏感度低，这是因为当$\vert w_i \vert&gt;1$时，$\sum\vert w_i \vert &lt; \sum(w_i)^2$，从而对异常值敏感度低。</li>
</ul>
<h3 id="参考文献："><a href="#参考文献：" class="headerlink" title="参考文献："></a>参考文献：</h3><p><span id="ref1">[1] 李航.《统计学习方法》</span><br><span id="ref2">[2] <a href="https://en.wikipedia.org/wiki/Lasso_(statistics)" target="_blank" rel="noopener">Lasso (statistics)</a></span><br><span id="ref3">[3] <a href="https://en.wikipedia.org/wiki/Tikhonov_regularization" target="_blank" rel="noopener"> Ridge regression</a></span><br><span id="ref4">[4] <a href="https://www.zhihu.com/question/37096933" target="_blank" rel="noopener">l1 相比于 l2 为什么容易获得稀疏解？</a></span><br><span id="ref5">[5] <a href="https://zhuanlan.zhihu.com/p/32480810" target="_blank" rel="noopener">聊一聊机器学习的MLE和MAP：最大似然估计和最大后验估计</a></span></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;正则化是结构风险最小化策略的实现，是在经验风险上加一个正则化项或罚项，正则化项一般是模型复杂度的单调递增函数，模型越复杂，正则化值就越大。例如模型参数向量的范数，正则化的一般形式如下&lt;sup&gt;&lt;a href=&quot;#ref1&quot;&gt;[1]&lt;/a&gt;&lt;/sup&gt;：&lt;/p&gt;
&lt;scrip
    
    </summary>
    
      <category term="机器学习" scheme="http://sm1les.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="正则化" scheme="http://sm1les.com/tags/%E6%AD%A3%E5%88%99%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>拉格朗日对偶函数及对偶问题</title>
    <link href="http://sm1les.com/2018/12/11/lagrange-duality/"/>
    <id>http://sm1les.com/2018/12/11/lagrange-duality/</id>
    <published>2018-12-11T07:36:48.000Z</published>
    <updated>2019-07-22T12:21:44.635Z</updated>
    
    <content type="html"><![CDATA[<p>对于一般地约束优化问题：</p>
<script type="math/tex; mode=display">\begin{array}{ll}
{\min } & {f(\boldsymbol x)} \qquad\qquad\qquad\qquad\qquad\qquad (A.1)\\ 
{\text {s.t.}} & {g_{i}(\boldsymbol x) \leq 0 \quad(i=1, \ldots, m)} \\ 
{} & {h_{j}(\boldsymbol x)=0 \quad(j=1, \ldots, n)}
\end{array}</script><p>其中，自变量$\boldsymbol x\in \mathbb{R}^n$。设优化问题（A.1）的定义域为$D=\boldsymbol{dom}  f \cap \bigcap\limits_{i=1}^{m}\boldsymbol{dom}  g_i \cap \bigcap\limits_{j=1}^{n}\boldsymbol{dom}  h_j $，可行集为$\tilde{D}=\{\boldsymbol x|\boldsymbol x\in D,g_i(\boldsymbol x) \leq 0,h_j(\boldsymbol x) = 0\}$，最优值为$p^*=\min\{f(\tilde{\boldsymbol x})\}$。由拉格朗日函数的定义可知优化问题（A.1）的拉格朗日函数为</p>
<script type="math/tex; mode=display">L(\boldsymbol x,\boldsymbol \mu,\boldsymbol \lambda)=f(\boldsymbol x)+\sum_{i=1}^{m}\mu_i g_i(\boldsymbol x)+\sum_{j=1}^{n}\lambda_j h_j(\boldsymbol x)</script><p>其中$\boldsymbol \mu=(\mu_1,\mu_2,…,\mu_m)^T,\boldsymbol \lambda=(\lambda_1,\lambda_2,…,\lambda_n)^T$为拉格朗日乘子向量。</p>
<h3 id="拉格朗日对偶函数"><a href="#拉格朗日对偶函数" class="headerlink" title="拉格朗日对偶函数"></a>拉格朗日对偶函数</h3><p>定义优化问题（A.1）的拉格朗日对偶函数$\Gamma (\boldsymbol \mu,\boldsymbol \lambda)$为$L(\boldsymbol x,\boldsymbol \mu,\boldsymbol \lambda)$关于$\boldsymbol x$的下确界，也即</p>
<script type="math/tex; mode=display">\Gamma (\boldsymbol \mu,\boldsymbol \lambda)=\mathop{\inf}_{\boldsymbol x∈D}L(\boldsymbol x,\boldsymbol \mu,\boldsymbol \lambda)=\mathop{\inf}_{\boldsymbol x∈D} \left( f(\boldsymbol x)+\sum_{i=1}^{m}\mu_i g_i(\boldsymbol x)+\sum_{j=1}^{n}\lambda_j h_j(\boldsymbol x) \right)</script><p>对偶函数$\Gamma (\boldsymbol \mu,\boldsymbol \lambda)$有如下重要性质：</p>
<ul>
<li>对偶函数$\Gamma (\boldsymbol \mu,\boldsymbol \lambda)$是一族关于$(\boldsymbol \mu,\boldsymbol \lambda)$的仿射函数的逐点下确界，所以无论优化问题（A.1）是否是凸优化问题，其对偶函数$\Gamma (\boldsymbol \mu,\boldsymbol \lambda)$恒为<strong>凹函数</strong>（证明参见<a href="#ref1">[1]</a> § 3.2.3）；</li>
<li>当$\boldsymbol \mu \succeq 0$时，$\Gamma (\boldsymbol \mu,\boldsymbol \lambda)$构成了优化问题（A.1）最优值$p^*$的下界，也即<script type="math/tex; mode=display">\Gamma (\boldsymbol \mu,\boldsymbol \lambda)\leq p^*</script>【证明】：设$\tilde{\boldsymbol x}\in\tilde{D}$是优化问题（A.1）的可行点，那么当$\boldsymbol \mu \succeq 0$时<script type="math/tex; mode=display">\sum_{i=1}^{n}\mu_i g_i(\tilde{\boldsymbol x})+\sum_{j=1}^{m}\lambda_j h_j(\tilde{\boldsymbol x}) \leq 0</script>这是因为左边第一项非正而第二项恒为0。根据此不等式可以进一步推得<script type="math/tex; mode=display">\Gamma (\boldsymbol \mu,\boldsymbol \lambda)=\mathop{\inf}_{\boldsymbol x∈D}L(\boldsymbol x,\boldsymbol \mu,\boldsymbol \lambda) \leq L(\tilde{\boldsymbol x},\boldsymbol \mu,\boldsymbol \lambda) \leq f(\tilde{\boldsymbol x})\leq \min\{f(\tilde{\boldsymbol x})\}=p^*</script><script type="math/tex; mode=display">\Gamma (\boldsymbol \mu,\boldsymbol \lambda) \leq P^*</script>所以，当$\boldsymbol \mu \succeq 0$时，$\Gamma (\boldsymbol \mu,\boldsymbol \lambda) \leq p^*$恒成立，证毕。那么$\Gamma (\boldsymbol \mu,\boldsymbol \lambda)$构成的最好下界是什么呢？</li>
</ul>
<h3 id="拉格朗日对偶问题"><a href="#拉格朗日对偶问题" class="headerlink" title="拉格朗日对偶问题"></a>拉格朗日对偶问题</h3><p>定义求对偶函数最大值的优化问题为拉格朗日对偶问题，也即</p>
<script type="math/tex; mode=display">\begin{array}{ll}
{\max } & {\Gamma (\boldsymbol \mu,\boldsymbol \lambda)} \qquad\qquad\qquad\qquad\qquad\qquad (B.1)\\ 
{\text {s.t.}} & {\boldsymbol \mu \succeq 0} 
\end{array}</script><p>设优化问题（B.1）的最优值为$d^*$，显然$d^* \leq p^*$，此时称为“弱对偶性”成立，若$d^* = p^*$，则称为“强对偶性”成立。对偶问题有如下重要性质：</p>
<ul>
<li><p>对偶问题恒为<strong>凸优化问题</strong>，因为对偶函数$\Gamma (\boldsymbol \mu,\boldsymbol \lambda)$恒为<strong>凹函数</strong>（加个负号即可转为凸函数），约束条件$\boldsymbol \mu \succeq 0$恒为凸集。这也就是为什么不直接求解主问题转而去求解对偶问题的主要原因；</p>
</li>
<li><p>当主问题（A.1）满足某些<strong>充分条件（sufficient conditions）</strong><sup><a href="#ref2">[2]</a></sup>时，强对偶性成立。常见的充分条件有<strong>Slater条件</strong><sup><a href="#ref3">[3]</a></sup>：“可行集$\tilde{D}$中存在一点在使得等式约束成立的同时也使得<strong>所有</strong>不等式约束<strong>严格成立</strong>”（证明参见<a href="#ref1">[1]</a> § 5.3.2）。Slater条件也是KKT条件中的约束限制条件之一；</p>
</li>
<li><p>Slater条件的“弱化”形式（weak form of Slater’s condition）：“若前$k$个不等式约束为<strong>仿射函数</strong>，可行集$\tilde{D}$中存在一点在使得等式约束成立的同时也使得第$k+1$至第$m$个不等式约束严格成立”。也就是说当不等式约束中有仿射函数时，不要求可行集$\tilde{D}$中存在一点使得这些仿射不等式严格成立。</p>
</li>
<li><p>若拉格朗日函数$L(\boldsymbol x,\boldsymbol \mu,\boldsymbol \lambda)$是<strong>关于$\boldsymbol x$一阶偏导数连续的凸函数</strong>，则其对偶函数的表达式求解过程如下：先对$L(\boldsymbol x,\boldsymbol \mu,\boldsymbol \lambda)$关于$\boldsymbol x$求导并令导数等于0，得到一个$\boldsymbol x$关于$\boldsymbol \mu$和$\boldsymbol \lambda$的表达式$\boldsymbol x=\Phi (\boldsymbol \mu,\boldsymbol \lambda)$，然后将其带回到$L(\boldsymbol x,\boldsymbol \mu,\boldsymbol \lambda)$中即可得仅含$\boldsymbol \mu$和$\boldsymbol \lambda$的对偶函数$L \left ( \Phi (\boldsymbol \mu,\boldsymbol \lambda),\boldsymbol \mu,\boldsymbol \lambda \right ) =\Gamma (\boldsymbol \mu,\boldsymbol \lambda)$，例<a href="#ref1">[1]</a> § 5.2.4和SVM的对偶函数求解。</p>
</li>
<li><p>设$f(\boldsymbol x),g_i(\boldsymbol x),h_j(\boldsymbol x)$一阶偏导连续，$\boldsymbol x^*,(\boldsymbol \mu^*,\boldsymbol \lambda^*)$分别为主问题（A.1）（注：此时并不要求为凸优化问题）和对偶问题（B.1）的最优解，若强对偶性成立，则$\boldsymbol x^*,\boldsymbol \mu^*,\boldsymbol \lambda^*$一定满足KKT条件，也就是说KK条件是强对偶性成立的必要条件；<br>【证明】：因为$\boldsymbol x^*,(\boldsymbol \mu^*,\boldsymbol \lambda^*)$分别为主问题（A.1）和对偶问题（B.1）的最优解，且此时强对偶性成立，那么</p>
<script type="math/tex; mode=display">\begin{aligned}
f(\boldsymbol x^*)&=\Gamma(\boldsymbol \mu^*,\boldsymbol \lambda^*) &(B.2.1)\\
&=\mathop{\inf}_{\boldsymbol x∈D} \left( f(\boldsymbol x)+\sum_{i=1}^{m}\mu_i^* g_i(\boldsymbol x)+\sum_{j=1}^{n}\lambda_j^* h_j(\boldsymbol x) \right) &(B.2.2)\\
&\leq f(\boldsymbol x^*)+\sum_{i=1}^{m}\mu_i^* g_i(\boldsymbol x^*)+\sum_{j=1}^{n}\lambda_j^* h_j(\boldsymbol x^*) &(B.2.3)\\
&\leq f(\boldsymbol x^*)&(B.2.4)
\end{aligned}</script><p>其中，（B.2.1）是由强对偶性成立推得；（B.2.2）是由$\Gamma(\boldsymbol \mu,\boldsymbol \lambda)$的定义推得；（B.2.3）是由下确界函数的性质推得；（B.2.4）是由$\boldsymbol \mu \succeq 0\Rightarrow\mu_i^*\geq0,g_i(\boldsymbol x^*)\leq0,h_j(\boldsymbol x^*)=0$推得。由于$f(\boldsymbol x^*)=f(\boldsymbol x^*)$，所以此时上式中的两个不等号均可以替换为等号。如果将（B.2.3）中的不等号替换为等号，那么可以推得$\boldsymbol x^*$为$L(\boldsymbol x,\boldsymbol \mu^*,\boldsymbol \lambda^*)$的最小值点，所以$L(\boldsymbol x,\boldsymbol \mu^*,\boldsymbol \lambda^*)$在$\boldsymbol x^*$处的梯度一定为0，也即</p>
<script type="math/tex; mode=display">\nabla_{\boldsymbol x} L(\boldsymbol x^* ,\boldsymbol \mu^* ,\boldsymbol \lambda^* )=\nabla f(\boldsymbol  x^* )+\sum_{i=1}^{m}\mu_i^* \nabla g_i(\boldsymbol x^* )+\sum_{j=1}^{n}\lambda_j^* \nabla h_j(\boldsymbol x^*)=0 \qquad (B.3)</script><p>如果将（B.2.4）中的不等号替换为等号，那么可以推得</p>
<script type="math/tex; mode=display">\left\{ \begin{array}{lcl}
\sum_{i=1}^{m}\mu_i^* g_i(\boldsymbol x^*)=0 \\ 
\mu_i^*\geq0 \\
g_i(\boldsymbol x^*)\leq0\\
\end{array}\right.
\Rightarrow 
\left\{ \begin{array}{lcl}
\mu_i^* g_i(\boldsymbol x^*)=0 \\ 
\mu_i^*\geq0 \\
g_i(\boldsymbol x^*)\leq0\\
\end{array}\right.\qquad (B.4)</script><p>此条件称作<strong>互补松弛（complementary slackness）</strong>。将$h_j(\boldsymbol x^*)=0$和（B.3）、（B.4）整合在一起即可得KKT条件，证毕。</p>
</li>
<li><p>若主问题（A.1）为<strong>凸优化问题</strong>，且$f(\boldsymbol x),g_i(\boldsymbol x),h_j(\boldsymbol x)$一阶偏导连续，如果存在$\boldsymbol x^*,\boldsymbol \mu^*,\boldsymbol \lambda^*$满足KKT条件，那么$\boldsymbol x^*$和$(\boldsymbol \mu^*,\boldsymbol \lambda^*)$一定是主问题（A.1）和对偶问题（B.1）的最优解，且强对偶性成立，也就是说当主问题（A.1）为凸优化问题时，KKT条件也是强对偶性成立的充分条件。<br>【证明】：已知存在$\boldsymbol x^*,\boldsymbol \mu^*,\boldsymbol \lambda^*$满足KKT条件，也即</p>
<script type="math/tex; mode=display">\left\{
\begin{aligned}
& \nabla_{\boldsymbol x} L(\boldsymbol x^* ,\boldsymbol \mu^* ,\boldsymbol \lambda^* )=\nabla f(\boldsymbol  x^* )+\sum_{i=1}^{m}\mu_i^* \nabla g_i(\boldsymbol x^* )+\sum_{j=1}^{n}\lambda_j^* \nabla h_j(\boldsymbol x^*)=0 &(B.5.1) \\
& h_j(\boldsymbol x^*)=0 &(B.5.2) \\
& g_i(\boldsymbol x^*) \leq 0 &(B.5.3) \\
& \mu_i^* \geq 0 &(B.5.4)\\
& \mu_i^* g_i(\boldsymbol x^*)=0 &(B.5.5)
\end{aligned}
\right.</script><p>由（B.5.2）和（B.5.3）可知$\boldsymbol x^*$是可行集$\tilde{D}$中的点；由（B.5.4）可推得$L(\boldsymbol x,\boldsymbol \mu^*,\boldsymbol \lambda^*)$是关于$\boldsymbol x$的凸函数，因为</p>
<script type="math/tex; mode=display">L(\boldsymbol x ,\boldsymbol \mu^* ,\boldsymbol \lambda^* )= f(\boldsymbol  x)+\sum_{i=1}^{m}\mu_i^*  g_i(\boldsymbol x )+\sum_{j=1}^{n}\lambda_j^* h_j(\boldsymbol x)</script><p>由于此时主问题（A.1）为凸优化问题，所以上式中的$f(\boldsymbol x),g_i(\boldsymbol x)$为凸函数，$h_j(\boldsymbol x)$为仿射函数，显然，当$\mu_i^* \geq 0$时$L(\boldsymbol x ,\boldsymbol \mu^* ,\boldsymbol \lambda^* )$恒为关于$\boldsymbol x$的凸函数；由（B.5.1）可知，$\boldsymbol x^*$是$L(\boldsymbol x ,\boldsymbol \mu^* ,\boldsymbol \lambda^* )$的极值点，由凸函数的性质可知，此极值点必是最小值点，那么可以进一步推得</p>
<script type="math/tex; mode=display">\begin{aligned}
\Gamma(\boldsymbol \mu^*,\boldsymbol \lambda^*)&=\mathop{\inf}_{\boldsymbol x∈D} \left( f(\boldsymbol x)+\sum_{i=1}^{m}\mu_i^* g_i(\boldsymbol x)+\sum_{j=1}^{n}\lambda_j^* h_j(\boldsymbol x) \right) &(B.6.1)\\
&=L(\boldsymbol x^* ,\boldsymbol \mu^* ,\boldsymbol \lambda^* )&(B.6.2)\\
&=f(\boldsymbol x^*)+\sum_{i=1}^{m}\mu_i^* g_i(\boldsymbol x^*)+\sum_{j=1}^{n}\lambda_j^* h_j(\boldsymbol x^*) &(B.6.3)\\
&=f(\boldsymbol x^*)&(B.6.4)
\end{aligned}</script><p>其中，（B.6.1）是由$\Gamma(\boldsymbol \mu,\boldsymbol \lambda)$的定义推得；（B.6.2）是由</p>
<script type="math/tex; mode=display">\mathop{\inf}_{\boldsymbol x∈D} \left( f(\boldsymbol x)+\sum_{i=1}^{m}\mu_i^* g_i(\boldsymbol x^*)+\sum_{j=1}^{n}\lambda_j^* h_j(\boldsymbol x) \right)=\min\{L(\boldsymbol x ,\boldsymbol \mu^* ,\boldsymbol \lambda^* )\}=L(\boldsymbol x^* ,\boldsymbol \mu^* ,\boldsymbol \lambda^* )</script><p>推得；（B.6.3）是由$L(\boldsymbol x,\boldsymbol \mu,\boldsymbol \lambda)$的定义推得；（B.6.4）是由（B.5.2）和（B.5.5）推得。因此，由（B.6）可知，$\boldsymbol x^*$和$(\boldsymbol \mu^*,\boldsymbol \lambda^*)$是主问题（A.1）和对偶问题（B.1）的最优解，且强对偶性成立，证毕。</p>
</li>
</ul>
<p>【注】：</p>
<ul>
<li>综合上述两条证明可知：若主问题（A.1）为凸优化问题，且$f(\boldsymbol x),g_i(\boldsymbol x),h_j(\boldsymbol x)$一阶偏导连续，那么KKT条件即为强对偶性成立的<strong>充要条件</strong>。</li>
</ul>
<h3 id="参考文献："><a href="#参考文献：" class="headerlink" title="参考文献："></a>参考文献：</h3><p><span id="ref1">[1] 王书宁 译.《凸优化》</span><br><span id="ref2">[2] <a href="https://en.wikipedia.org/wiki/Strong_duality#Sufficient_conditions" target="_blank" rel="noopener">Strong duality</a></span><br><span id="ref3">[3] <a href="https://en.wikipedia.org/wiki/Slater%27s_condition" target="_blank" rel="noopener">Slater’s condition</a></span><br><span id="ref4">[4] <a href="https://inst.eecs.berkeley.edu/~ee227a/fa10/login/l_dual_strong.html" target="_blank" rel="noopener">Strong Duality - EECS</a></span></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;对于一般地约束优化问题：&lt;/p&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{array}{ll}
{\min } &amp; {f(\boldsymbol x)} \qquad\qquad\qquad\qquad\qquad\qqua
    
    </summary>
    
      <category term="最优化" scheme="http://sm1les.com/categories/%E6%9C%80%E4%BC%98%E5%8C%96/"/>
    
    
      <category term="拉格朗日对偶" scheme="http://sm1les.com/tags/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E5%AF%B9%E5%81%B6/"/>
    
      <category term="Slater条件" scheme="http://sm1les.com/tags/Slater%E6%9D%A1%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title>KKT条件（Karush–Kuhn–Tucker conditions）</title>
    <link href="http://sm1les.com/2018/12/08/karush-kuhn-tucker-conditions/"/>
    <id>http://sm1les.com/2018/12/08/karush-kuhn-tucker-conditions/</id>
    <published>2018-12-08T09:03:27.000Z</published>
    <updated>2019-07-22T12:19:36.935Z</updated>
    
    <content type="html"><![CDATA[<p>对于一般地约束优化问题</p>
<script type="math/tex; mode=display">\begin{array}{ll}
{\min } & {f(\boldsymbol x)} \\ 
{\text {s.t.}} & {g_{i}(\boldsymbol x) \leq 0 \quad(i=1, \ldots, m)} \\ 
{} & {h_{j}(\boldsymbol x)=0 \quad(j=1, \ldots, n)}
\end{array}</script><p>其中，自变量$\boldsymbol x\in \mathbb{R}^n$。设$f(\boldsymbol x),g_i(\boldsymbol x),h_j(\boldsymbol x)$具有连续的一阶偏导数，$\boldsymbol x^*$是优化问题的局部可行解。若在$\boldsymbol x^*$处<strong>约束限制条件（constraint qualifications or regularity conditions）</strong><sup><a href="#ref1">[1]</a></sup><sup><a href="#ref2">[2]</a></sup>成立，则一定存在$\boldsymbol \mu^*=(\mu_1^*,\mu_2^*,…,\mu_m^*)^T,\boldsymbol \lambda^*=(\lambda_1^*,\lambda_2^*,…,\lambda_n^*)^T,$使得</p>
<script type="math/tex; mode=display">\left\{
\begin{aligned}
& \nabla_{\boldsymbol x} L(\boldsymbol x^* ,\boldsymbol \mu^* ,\boldsymbol \lambda^* )=\nabla f(\boldsymbol  x^* )+\sum_{i=1}^{m}\mu_i^* \nabla g_i(\boldsymbol x^* )+\sum_{j=1}^{n}\lambda_j^* \nabla h_j(\boldsymbol x^*)=0 &(1) \\
& h_j(\boldsymbol x^*)=0 &(2) \\
& g_i(\boldsymbol x^*) \leq 0 &(3) \\
& \mu_i^* \geq 0 &(4)\\
& \mu_i^* g_i(\boldsymbol x^*)=0 &(5)
\end{aligned}
\right.</script><p>其中$L(\boldsymbol x,\boldsymbol \mu,\boldsymbol \lambda)$为拉格朗日函数</p>
<script type="math/tex; mode=display">L(\boldsymbol x,\boldsymbol \mu,\boldsymbol \lambda)=f(\boldsymbol x)+\sum_{i=1}^{m}\mu_i g_i(\boldsymbol x)+\sum_{j=1}^{n}\lambda_j h_j(\boldsymbol x)</script><p>以上5条即为<strong>KKT条件</strong>，其中条件(2)和(3)为约束条件显然成立，条件(1)、(4)、(5)成立的<strong>简单证明</strong>（严格数学证明参见<a href="#ref1">[1]</a> § 4.2.1）如下：</p>
<p><center>
<img src="./Inequality_constraint_diagram.png" width="60%" height="60%">
</center><br>由约束条件：$g_i(\boldsymbol x) \leq 0$可知，$\boldsymbol x^*$一定满足$g_i(\boldsymbol x^*) \lt 0$或者$g_i(\boldsymbol x^*) = 0$，下面对这两种情形分别进行讨论：</p>
<ul>
<li><strong>当$g_i(\boldsymbol x^*) \lt 0$时：</strong><br>此时极小值点在$g_i(\boldsymbol x) \lt 0$这个区域内（如上图左部所示），所以$g_i(\boldsymbol x) \leq 0$这个约束可以忽略，那么此时的优化问题等价于<strong>仅含等式约束</strong>的优化问题，所以$\mu_i^* = 0$。</li>
<li><strong>当$g_i(\boldsymbol x^*) = 0$时：</strong><br>此时极小值点在$g_i(\boldsymbol x) = 0$这个边界上，所以约束$g_i(\boldsymbol x) \leq 0$等价于约束$g_i(\boldsymbol x) = 0$，那么此时的优化问题同样等价于<strong>仅含等式约束</strong>的最优化问题。根据拉格朗日乘子法的原理可知，此时$f(\boldsymbol  x)$和$ g_i(\boldsymbol  x)=0$在极小值点处相切（如上图右部所示），梯度（正梯度）平行，即$\nabla f(\boldsymbol  x^*)+\mu_i^* \nabla g_i(\boldsymbol  x^*)=0 \quad (\mu_i^*\in \mathbb{R})$。易知$g_i(\boldsymbol x)=0$这个边界上的梯度都是向外的，而$\nabla f(\boldsymbol x^*)$一定和$\nabla g_i(\boldsymbol x^*)$的方向相反（如果不相反的话极小值点就不会在边界上取到而是在$g_i(\boldsymbol x) \lt 0$内取），所以$\nabla f(\boldsymbol  x^*)$和$\nabla g_i(\boldsymbol  x^*)$异号，那么$\mu_i^*$一定大于0。</li>
</ul>
<p>综上，当$g_i(\boldsymbol x^*) \lt 0$时$\mu_i^* = 0$， $g_i(\boldsymbol x^*) = 0$时$\mu_i^* \gt 0$，所以条件(4)、(5)恒成立；由于对$\lambda_j$取值无要求，所以总存在$\lambda_j^*$使得条件(1)恒成立。<br>【注】：</p>
<ul>
<li>若在$\boldsymbol x^*$处约束限制条件<strong>成立</strong>，则KKT条件是局部可行解$\boldsymbol x^*$的<strong>必要条件</strong>；</li>
<li>若在$\boldsymbol x^*$处约束限制条件<strong>不成立</strong>，则局部解$\boldsymbol x^*$<strong>不一定</strong>满足KKT条件（证明参见<a href="#ref1">[1]</a> § 4.2.1）;</li>
<li>满足KKT条件的点$\boldsymbol x^*$不一定是局部可行解（证明参见<a href="#ref1">[1]</a> § 4.2.1）；</li>
<li>若上述优化问题是<strong>凸优化</strong>问题，也即目标函数$f(\boldsymbol x)$是凸函数，不等式约束$g_i(\boldsymbol x)$是凸函数，等式约束$h_j(\boldsymbol x)$是仿射函数，那么此时KKT条件为局部可行解$\boldsymbol x^*$的<strong>充分条件</strong>，同时局部可行解$\boldsymbol x^*$也为<strong>全局可行解</strong>（证明参见<a href="#ref1">[1]</a> § 4.4），特别地，此时若在$\boldsymbol x^*$处约束限制条件也成立，那么KKT条件即升级为<strong>充要条件=充分条件+必要条件</strong>；</li>
<li>由<a href="/2018/12/11/lagrange-duality">《 拉格朗日对偶函数及对偶问题》</a>可知，只要上述优化问题是凸优化问题，无论在$\boldsymbol x^*$处约束限制条件是否成立，KKT条件都是全局最优解$\boldsymbol x^*$的充要条件。</li>
</ul>
<h3 id="参考文献："><a href="#参考文献：" class="headerlink" title="参考文献："></a>参考文献：</h3><p><span id="ref1">[1] 王燕军. 《最优化基础理论与方法》</span><br><span id="ref2">[2] <a href="https://en.wikipedia.org/wiki/Karush%E2%80%93Kuhn%E2%80%93Tucker_conditions#Regularity_conditions_(or_constraint_qualifications)" target="_blank" rel="noopener">Karush–Kuhn–Tucker conditions</a></span></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;对于一般地约束优化问题&lt;/p&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{array}{ll}
{\min } &amp; {f(\boldsymbol x)} \\ 
{\text {s.t.}} &amp; {g_{i}(\boldsym
    
    </summary>
    
      <category term="最优化" scheme="http://sm1les.com/categories/%E6%9C%80%E4%BC%98%E5%8C%96/"/>
    
    
      <category term="KKT条件" scheme="http://sm1les.com/tags/KKT%E6%9D%A1%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title>线性回归参数的极大似然估计和最小二乘估计</title>
    <link href="http://sm1les.com/2018/11/27/linear-regression-maximum-likelihood/"/>
    <id>http://sm1les.com/2018/11/27/linear-regression-maximum-likelihood/</id>
    <published>2018-11-27T07:20:01.000Z</published>
    <updated>2019-07-24T01:07:05.287Z</updated>
    
    <content type="html"><![CDATA[<h3 id="极大似然估计"><a href="#极大似然估计" class="headerlink" title="极大似然估计"></a>极大似然估计</h3><p>对于线性回归模型：</p>
<script type="math/tex; mode=display">y=\boldsymbol{w}^T\boldsymbol{x}+b+\epsilon</script><p>随机误差$\epsilon$可以看成是由许多观察不到的、可加的微小误差叠加而成的<sup><a href="#ref1">[1]</a></sup>，则根据<strong>中心极限定理</strong>，随机误差$\epsilon$服从正态分布，其分布为：$\epsilon \sim N(\mu,\sigma^2)$，为了方便后续计算可以将其去均值，令$\epsilon:=\epsilon-\mu$，则此时的分布为：$\epsilon \sim N(0,\sigma^2)$，分布律为：</p>
<script type="math/tex; mode=display">p(\epsilon)=\cfrac{1}{\sqrt{2\pi}\sigma} \mathrm{exp}\left(-\cfrac{\epsilon^2}{2\sigma^2}\right)</script><p>若将其中的$\epsilon$用$\epsilon=y-\boldsymbol{w}^T\boldsymbol{x}-b$等价替换可得：</p>
<script type="math/tex; mode=display">p(y)=\cfrac{1}{\sqrt{2\pi}\sigma} \mathrm{exp}\left(-\cfrac{(y-\boldsymbol{w}^T\boldsymbol{x}-b)^2}{2\sigma^2}\right)</script><p>上式显然可以看做$y \sim N(\boldsymbol{w}^T\boldsymbol{x}+b,\sigma^2)$的分布律，接下来便可以用最（极）大似然估计法来估计$\boldsymbol{w}$和b的值。似然函数为：</p>
<script type="math/tex; mode=display">L(\boldsymbol{w},b)=\prod_{i=1}^{m}p(y_i)=\prod_{i=1}^{m}\cfrac{1}{\sqrt{2\pi}\sigma} \mathrm{exp}\left(-\cfrac{(y_i-\boldsymbol{w}^T\boldsymbol{x_i}-b)^2}{2\sigma^2}\right)</script><p>两边同时取对数得对数似然函数：</p>
<script type="math/tex; mode=display">
\begin{aligned}     
\ln L(\boldsymbol{w},b) & = \sum_{i=1}^{m}\ln \cfrac{1}{\sqrt{2\pi}\sigma} \mathrm{exp}\left(-\cfrac{(y_i-\boldsymbol{w}^T\boldsymbol{x_i}-b)^2}{2\sigma^2}\right) \\
& = \sum_{i=1}^{m}\ln \cfrac{1}{\sqrt{2\pi}\sigma}+\sum_{i=1}^{m}\ln \mathrm{exp}\left(-\cfrac{(y_i-\boldsymbol{w}^T\boldsymbol{x_i}-b)^2}{2\sigma^2}\right) \\
& = m\ln \cfrac{1}{\sqrt{2\pi}\sigma}-\cfrac{1}{2\sigma^2}\sum_{i=1}^{m}(y_i-\boldsymbol{w}^T\boldsymbol{x_i}-b)^2
\end{aligned}</script><p>其中$m$，$\sigma$均为常数，所以最大化$\ln L(\boldsymbol{w},b)$等价于最小化$\sum_{i=1}^{m}(y_i-\boldsymbol{w}^T\boldsymbol{x_i}-b)^2$，也即：</p>
<script type="math/tex; mode=display">(\boldsymbol{w}',b')=\mathop{\arg\max}_{(\boldsymbol{w},b)} \ln L(\boldsymbol{w},b)=\mathop{\arg\min}_{(\boldsymbol{w},b)} \sum_{i=1}^{m}(y_i-\boldsymbol{w}^T\boldsymbol{x_i}-b)^2</script><p>其中$\boldsymbol{w}’$和$b’$为$\boldsymbol{w}$和$b$的解.</p>
<h3 id="最小二乘估计"><a href="#最小二乘估计" class="headerlink" title="最小二乘估计"></a>最小二乘估计</h3><p>最小二乘法是基于均方误差最小化来对模型进行参数估计的，用公式表示为：</p>
<script type="math/tex; mode=display">
\begin{aligned}    
    (\boldsymbol{w}',b') & = \mathop{\arg\min}_{(\boldsymbol{w},b)} \sum_{i=1}^{m}(y_i-(\boldsymbol{w}^T\boldsymbol{x_i}+b))^2 \\
    & = \mathop{\arg\min}_{(\boldsymbol{w},b)} \sum_{i=1}^{m}(y_i-\boldsymbol{w}^T\boldsymbol{x_i}-b)^2
\end{aligned}</script><p>显然与最（极）大似然估计的推导结果一致。</p>
<h3 id="参考文献："><a href="#参考文献：" class="headerlink" title="参考文献："></a>参考文献：</h3><p><span id="ref1">[1] 盛骤.《概率论与数理统计（第四版）》</span></p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;极大似然估计&quot;&gt;&lt;a href=&quot;#极大似然估计&quot; class=&quot;headerlink&quot; title=&quot;极大似然估计&quot;&gt;&lt;/a&gt;极大似然估计&lt;/h3&gt;&lt;p&gt;对于线性回归模型：&lt;/p&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;y=
    
    </summary>
    
      <category term="机器学习" scheme="http://sm1les.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="线性回归" scheme="http://sm1les.com/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    
  </entry>
  
</feed>

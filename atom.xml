<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Sm1les&#39;s blog</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.sm1les.com/"/>
  <updated>2019-04-06T06:00:18.934Z</updated>
  <id>http://www.sm1les.com/</id>
  
  <author>
    <name>Sm1les</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>EM算法</title>
    <link href="http://www.sm1les.com/2019/03/13/expectation-maximization/"/>
    <id>http://www.sm1les.com/2019/03/13/expectation-maximization/</id>
    <published>2019-03-13T07:51:10.000Z</published>
    <updated>2019-04-06T06:00:18.934Z</updated>
    
    <content type="html"><![CDATA[<p>在推导EM算法之前先学习一下<strong>Jensen不等式<sup><a href="#ref1">[1]</a></sup></strong>，Jensen不等式的定义如下：若<br>$f$是<strong>凸函数</strong>，则</p>
<script type="math/tex; mode=display">f(t x_1 + (1-t)x_2)\leq tf(x_1)+(1-t)f(x_2)</script><p>其中$t\in [0,1]$。同理，若$f$是<strong>凹函数</strong>，则只需将上式的$\leq$换成$\geq$即可。</p>
<p>将上式中的$t$推广到$n$个同样成立，即</p>
<script type="math/tex; mode=display">f(t_1 x_1 + t_2x_2+...+t_nx_n)\leq t_1f(x_1)+t_2f(x_2)+...+t_nf(t_n)</script><p>其中$t_1,t_2,…,t_n\in[0,1],t_1+t_2+…+t_n=1$。</p>
<p>上式在概率论中通常以如下形式出现：</p>
<script type="math/tex; mode=display">\varphi(E[X])\leq E[\varphi(X)]</script><p>其中$X$是一个随机变量，$\varphi$为凸函数，$E[X]$为随机变量$X$的期望。</p>
<h3 id="EM（Expectation-Maximization）算法的导出-2"><a href="#EM（Expectation-Maximization）算法的导出-2" class="headerlink" title="EM（Expectation Maximization）算法的导出[2]"></a>EM（Expectation Maximization）算法的导出<sup><a href="#ref2">[2]</a></sup></h3><p>我们面对一个含有隐变量的概率模型，目标是极大化观测数据（不完全数据）$Y$关于参数$\theta$的对数似然函数，即极大化</p>
<script type="math/tex; mode=display">L(\theta)=\ln P(Y\vert \theta)=\ln \sum_Z P(Y,Z\vert\theta)=\ln \left(\sum_Z P(Y\vert Z,\theta)P(Z\vert \theta)\right)</script><p>注意到这一极大化的主要困难是上式中有未观测数据$Z$并有包含和（$Z$为离散型时）或者积分（$Z$为连续型时）的对数。EM算法采用的是通过迭代逐步近似极大化$L(\theta)$：假设在第$i$次迭代后$\theta$的估计值是$\theta^{(i)}$，我们希望新的估计值$\theta$能使$L(\theta)$增加，即$L(\theta)&gt;L(\theta^{(i)})$，并逐步达到极大值。为此，考虑两者的差：</p>
<script type="math/tex; mode=display">\begin{aligned}
L(\theta)-L(\theta^{(i)})&=\ln \left(\sum_Z P(Y\vert Z,\theta)P(Z\vert \theta)\right)-\ln P(Y\vert\theta^{(i)}) \\
&=\ln \left(\sum_Z P(Z\vert Y,\theta^{(i)}) \cfrac{P(Y\vert Z,\theta)P(Z\vert \theta)}{P(Z\vert Y,\theta^{(i)})}\right)-\ln P(Y\vert\theta^{(i)})
\end{aligned}</script><p>注意，上式中采用的是和参考文献<a href="#ref3">[3]</a>一样上下同时乘以$P(Z\vert Y,\theta^{(i)})$，而参考文献<a href="#ref2">[2]</a>中一开始上下同乘的是$P(Y\vert Z,\theta^{(i)})$，而后续却用的是$P(Z\vert Y,\theta^{(i)})$，不知是另有原由还是作者笔误，暂不知晓，接着由上述Jensen不等式以及$\ln$函数为<strong>凹函数</strong>可得：</p>
<script type="math/tex; mode=display">\begin{aligned}
L(\theta)-L(\theta^{(i)})&=\ln \left(\sum_Z P(Z\vert Y,\theta^{(i)}) \cfrac{P(Y\vert Z,\theta)P(Z\vert \theta)}{P(Z\vert Y,\theta^{(i)})}\right)-\ln P(Y\vert\theta^{(i)})  \\
&\geq \sum_Z P(Z\vert Y,\theta^{(i)})\ln \cfrac{P(Y\vert Z,\theta)P(Z\vert \theta)}{P(Z\vert Y,\theta^{(i)})}-\ln P(Y\vert\theta^{(i)}) \\
&= \sum_Z P(Z\vert Y,\theta^{(i)})\ln \cfrac{P(Y\vert Z,\theta)P(Z\vert \theta)}{P(Z\vert Y,\theta^{(i)})}-1\cdot \ln P(Y\vert\theta^{(i)}) \\
&= \sum_Z P(Z\vert Y,\theta^{(i)})\ln \cfrac{P(Y\vert Z,\theta)P(Z\vert \theta)}{P(Z\vert Y,\theta^{(i)})}-\sum_Z P(Z\vert Y,\theta^{(i)})\cdot \ln P(Y\vert\theta^{(i)}) \\
&=\sum_Z P(Z\vert Y,\theta^{(i)}) \left( \ln \cfrac{P(Y\vert Z,\theta)P(Z\vert \theta)}{P(Z\vert Y,\theta^{(i)})} - \ln P(Y\vert\theta^{(i)}) \right)\\
&= \sum_Z P(Z\vert Y,\theta^{(i)})\ln \cfrac{P(Y\vert Z,\theta)P(Z\vert \theta)}{P(Z\vert Y,\theta^{(i)})P(Y\vert\theta^{(i)})}
\end{aligned}</script><p>令</p>
<script type="math/tex; mode=display">B(\theta,\theta^{(i)})=L(\theta^{(i)})+\sum_Z P(Z\vert Y,\theta^{(i)})\ln \cfrac{P(Y\vert Z,\theta)P(Z\vert \theta)}{P(Z\vert Y,\theta^{(i)})P(Y\vert\theta^{(i)})}</script><p>则</p>
<script type="math/tex; mode=display">L(\theta)\geq B(\theta,\theta^{(i)})</script><p>即函数$B(\theta,\theta^{(i)})$是$L(\theta)$的一个下界，此时若设$\theta^{(i+1)}$使得$B(\theta,\theta^{(i)})$达到极大，也即</p>
<script type="math/tex; mode=display">B(\theta^{(i+1)},\theta^{(i)}) \geq B(\theta^{(i)},\theta^{(i)})</script><p>由于$L(\theta^{(i)})=B(\theta^{(i)},\theta^{(i)})$，所以可以进一步推得：</p>
<script type="math/tex; mode=display">L(\theta^{(i+1)})\geq B(\theta^{(i+1)},\theta^{(i)})\geq B(\theta^{(i)},\theta^{(i)})=L(\theta^{(i)})</script><script type="math/tex; mode=display">L(\theta^{(i+1)})\geq L(\theta^{(i)})</script><p><center>
<img src="./em.png" width="60%" height="60%"><br>
此图是对上述不等式的直观解释
</center><br>因此，任何可以使$B(\theta,\theta^{(i)})$增大的$\theta$，也可以使$L(\theta)$增大，于是问题就转化为了求解能使得$B(\theta,\theta^{(i)})$达到极大的$\theta^{(i+1)}$，即</p>
<script type="math/tex; mode=display">\begin{aligned}
\theta^{(i+1)}&=\mathop{\arg\max}_{\theta}B(\theta,\theta^{(i)}) \\
&=\mathop{\arg\max}_{\theta}\left( L(\theta^{(i)})+\sum_Z P(Z\vert Y,\theta^{(i)})\ln \cfrac{P(Y\vert Z,\theta)P(Z\vert \theta)}{P(Z\vert Y,\theta^{(i)})P(Y\vert\theta^{(i)})}\right)
\end{aligned}</script><p>略去对$\theta$的极大化而言是常数的项：</p>
<script type="math/tex; mode=display">\begin{aligned}
\theta^{(i+1)}&=\mathop{\arg\max}_{\theta}\left(\sum_Z P(Z\vert Y,\theta^{(i)})\ln\left( P(Y\vert Z,\theta)P(Z\vert \theta)\right)\right) \\
&=\mathop{\arg\max}_{\theta}\left(\sum_Z P(Z\vert Y,\theta^{(i)})\ln P(Y,Z\vert \theta)\right) \\
&=\mathop{\arg\max}_{\theta}Q(\theta,\theta^{(i)})
\end{aligned}</script><p>到此即完成了EM算法的一次迭代，求出的$\theta^{(i+1)}$作为下一次迭代的初始$\theta^{(i)}$。综上可以总结出EM算法的“E步”和“M步”分别为：<br><strong>E步：</strong>计算完全数据的对数似然函数$\ln P(Y,Z\vert \theta)$关于在给定观测数据$Y$和当前参数$\theta^{(i)}$下对未观测数据$Z$的条件概率分布$ P(Z\vert Y,\theta^{(i)})$的期望，也即$Q$函数：</p>
<script type="math/tex; mode=display">Q(\theta,\theta^{(i)})=E_Z[\ln P(Y,Z\vert \theta)\vert Y,\theta^{(i)}]=\sum_Z P(Z\vert Y,\theta^{(i)})\ln P(Y,Z\vert \theta)</script><p><strong>M步：</strong>求使得$Q$函数到达极大的$\theta^{(i+1)}$。<br>EM算法的基本思想可以总结为<sup><a href="#ref4">[4]</a></sup>：若参数$\theta$已知，则可根据观测数据$Y$推断出最优隐变量$Z$的值（E步）；反之，若$Z$的值已知，则可方便地对参数$\theta$做极大似然估计（M步）。</p>
<h3 id="EM算法在高斯混合模型中的应用-2-3-5"><a href="#EM算法在高斯混合模型中的应用-2-3-5" class="headerlink" title="EM算法在高斯混合模型中的应用[2][3][5]"></a>EM算法在高斯混合模型中的应用<sup><a href="#ref2">[2]</a></sup><sup><a href="#ref3">[3]</a></sup><sup><a href="#ref5">[5]</a></sup></h3><p>高斯混合模型（Gaussian Mixture Model，GMM）定义如下：</p>
<script type="math/tex; mode=display">P(y|\theta)=\sum_{k=1}^{K}\alpha_k\phi(y\vert \theta_k)</script><p>其中$\alpha_k$是系数，$\alpha_k\geq0,\sum_{k=1}^{K}\alpha_k=1$，$\theta_k=(\mu_k,\sigma_k^2)$，$\phi(y\vert \theta_k)$为高斯分布密度：</p>
<script type="math/tex; mode=display">\phi(y\vert \theta_k) =\cfrac{1}{\sqrt{2\pi}\sigma_k}\exp\left(-\cfrac{(y-\mu_k)^2}{2\sigma_k^2}\right)</script><p>假设观测数据$y_1,y_2,…,y_N$由上述高斯混合模型生成，现用EM算法来估计其参数$\theta=(\alpha_1,\alpha_2,…,\alpha_K;\theta_1,\theta_2,…,\theta_K)$。</p>
<h5 id="1-明确隐变量，写出完全数据的对数似然函数"><a href="#1-明确隐变量，写出完全数据的对数似然函数" class="headerlink" title="1.明确隐变量，写出完全数据的对数似然函数"></a>1.明确隐变量，写出完全数据的对数似然函数</h5><p>假设观测数据$y_j$是这样产生的：首先依概率$\alpha_k$选择第$k$个高斯分布分模型$\phi(y\vert \theta_k)$，接着由该分模型生成观测数据$y_j$，此时观测数据$y_j$（其中$j=1,2,…,N$）是已知的，反映观测数据$y_j$来自第$k$个分模型的数据是未知的，我们用隐变量$z_{jk}$来表示，其定义如下：</p>
<script type="math/tex; mode=display">
z_{jk} = \left\{ \begin{array}{rcl}
1 & 第j个观测数据y_j来自第k个分模型 \\ 
 0 & 否则 \\
\end{array}\right.</script><p>所以$z_{jk}$是一个0-1随机变量。确定了未观测数据的表示形式后便可以写出完全数据的对数似然函数：</p>
<script type="math/tex; mode=display">\begin{aligned}
\ln P(Y,Z\vert \theta)&=\ln\left( P(Y\vert Z,\theta)P(Z\vert \theta)\right) \\
&=\ln\left( \prod_{j=1}^{N}\left( \prod_{k=1}^{K} [\phi(y_j\vert\theta_k)]^{z_{jk}}\times \prod_{k=1}^{K} \alpha_{k}^{z_{jk}}\right)\right) \\
&=\ln\left( \prod_{j=1}^{N}\left( \prod_{k=1}^{K} [\phi(y_j\vert\theta_k)]^{z_{jk}} \alpha_{k}^{z_{jk}}\right)\right) \\
&=\ln\left( \prod_{j=1}^{N}\prod_{k=1}^{K}[\alpha_{k}\phi(y_j\vert\theta_k)]^{z_{jk}}\right) \\
&= \sum_{j=1}^{N}\sum_{k=1}^{K}\ln\left([\alpha_{k}\phi(y_j\vert\theta_k)]^{z_{jk}}\right) \\
&= \sum_{j=1}^{N}\sum_{k=1}^{K}{z_{jk}}\ln(\alpha_{k}\phi(y_j\vert\theta_k)) \\
&= \sum_{j=1}^{N}\sum_{k=1}^{K}{z_{jk}}(\ln\alpha_{k}+\ln\phi(y_j\vert\theta_k)) \\
\end{aligned}</script><h5 id="2-EM算法E步：确定-Q-函数"><a href="#2-EM算法E步：确定-Q-函数" class="headerlink" title="2.EM算法E步：确定$Q$函数"></a>2.EM算法E步：确定$Q$函数</h5><script type="math/tex; mode=display">\begin{aligned}
Q(\theta,\theta^{(i)})&=\sum_Z P(Z\vert Y,\theta^{(i)})\ln P(Y,Z\vert \theta) \\
&=\sum_Z P(Z\vert Y,\theta^{(i)})\left\{\sum_{j=1}^{N}\sum_{k=1}^{K}{z_{jk}}(\ln\alpha_{k}+\ln\phi(y_j\vert\theta_k))\right\}\\
&=\sum_{j=1}^{N}\sum_{k=1}^{K}\left\{\sum_{z_{jk}}P(z_{jk}\vert y_j,\theta^{(i)}){z_{jk}}(\ln\alpha_{k}+\ln\phi(y_j\vert\theta_k))\right\} \quad(此处\sum_{z_{jk}}表示遍历z_{jk}的两种取值情况：0和1)\\
&=\sum_{j=1}^{N}\sum_{k=1}^{K}\left\{P(z_{jk}=1\vert y_j,\theta^{(i)})\cdot 1 \cdot (\ln\alpha_{k}+\ln\phi(y_j\vert\theta_k))+P(z_{jk}=0\vert y_j,\theta^{(i)})\cdot 0 \cdot (\ln\alpha_{k}+\ln\phi(y_j\vert\theta_k))\right\} \\
&=\sum_{j=1}^{N}\sum_{k=1}^{K}\left\{P(z_{jk}=1\vert y_j,\theta^{(i)})(\ln\alpha_{k}+\ln\phi(y_j\vert\theta_k))\right\}\\    
\end{aligned}</script><p>其中$P(z_{jk}=1\vert y_j,\theta^{(i)})$表示在给定$\theta=\theta^{(i)}$的条件下，某个观测数据$y_j$是由第$k$个分模型生成的概率，称为分模型$k$对观测数据$y_j$的响应度。由<strong>贝叶斯定理</strong>可进一步推得<sup><a href="#ref4">[4]</a></sup>：</p>
<script type="math/tex; mode=display">\begin{aligned}
P(z_{jk}=1\vert y_j,\theta^{(i)})&=\cfrac{P(y_j\vert z_{jk}=1,\theta^{(i)})\cdot P(z_{jk}=1,\theta^{(i)})}{P(y_j,\theta^{(i)})} \\
&=\cfrac{P(y_j\vert z_{jk}=1,\theta^{(i)})\cdot P(z_{jk}=1,\theta^{(i)})}{\sum_{l=1}^{K}\alpha_l\phi(y_j\vert \theta_l^{(i)})} \\
&=\cfrac{\phi(y_j\vert \theta_k^{(i)})\cdot \alpha_k}{\sum_{l=1}^{K}\alpha_l\phi(y_j\vert \theta_l^{(i)})} \\
&=\cfrac{\alpha_k\cdot \phi(y_j\vert \theta_k^{(i)})}{\sum_{l=1}^{K}\alpha_l\phi(y_j\vert \theta_l^{(i)})}
\end{aligned}</script><p>$P(z_{jk}=1\vert y_j,\theta^{(i)})$也可以看做是<strong>某个</strong>$z_{jk}$的期望<strong>（注意不是所有的，因为$z_{jk}$一共有$N\times K$个，每个$z_{jk}$均为一个独立的随机变量，此处说的只是其中某一个，例如$z_{12}$的期望值）</strong>，证明如下：由于每个$z_{jk}$均为$0-1$随机变量，所以对于某个$z_{jk}$来说，其期望为：</p>
<script type="math/tex; mode=display">\begin{aligned}
E[z_{jk}]&=\sum_{z_{jk}}\left(P(z_{jk}\vert y_j,\theta^{(i)})\cdot z_{jk}\right) \\
&=P(z_{jk}=1\vert y_j,\theta^{(i)})\cdot 1 + P(z_{jk}=0\vert y_j,\theta^{(i)})\cdot 0\\
&=P(z_{jk}=1\vert y_j,\theta^{(i)})\\
\end{aligned}</script><p>证毕。现将$P(z_{jk}=1\vert y_j,\theta^{(i)})$简记为$\gamma_{jk}$，则：</p>
<script type="math/tex; mode=display">\begin{aligned}
Q(\theta,\theta^{(i)})&=\sum_{j=1}^{N}\sum_{k=1}^{K}\left\{\gamma_{jk}(\ln\alpha_{k}+\ln\phi(y_j\vert\theta_k))\right\} \\
&=\sum_{j=1}^{N}\sum_{k=1}^{K}\left\{\gamma_{jk}\ln\alpha_{k}+\gamma_{jk}\ln\phi(y_j\vert\theta_k)\right\} \\
&=\sum_{j=1}^{N}\sum_{k=1}^{K}\left\{\gamma_{jk}\ln\alpha_{k}+\gamma_{jk}\ln\left(\cfrac{1}{\sqrt{2\pi}\sigma_k}\exp\left(-\cfrac{(y_j-\mu_k)^2}{2\sigma_k^2}\right)\right)\right\} \\
&=\sum_{j=1}^{N}\sum_{k=1}^{K}\left\{\gamma_{jk}\ln\alpha_{k}+\gamma_{jk}\left(\ln\cfrac{1}{\sqrt{2\pi}}-\ln \sigma_k-\cfrac{(y_j-\mu_k)^2}{2\sigma_k^2}\right)\right\} \\
&=\sum_{j=1}^{N}\sum_{k=1}^{K}\left\{\gamma_{jk}\ln\alpha_{k}+\gamma_{jk}\ln\cfrac{1}{\sqrt{2\pi}}-\gamma_{jk}\ln \sigma_k-\gamma_{jk}\cfrac{(y_j-\mu_k)^2}{2\sigma_k^2}\right\}
\end{aligned}</script><h5 id="3-EM算法M步：求使得-Q-函数达到极大的-theta-i-1"><a href="#3-EM算法M步：求使得-Q-函数达到极大的-theta-i-1" class="headerlink" title="3.EM算法M步：求使得$Q$函数达到极大的$\theta^{(i+1)}$"></a>3.EM算法M步：求使得$Q$函数达到极大的$\theta^{(i+1)}$</h5><p>$Q(\theta,\theta^{(i)})$关于$\mu_k$求偏导（此时$k$是固定的）：</p>
<script type="math/tex; mode=display">\begin{aligned}
\cfrac{\partial{Q(\theta,\theta^{(i)})}}{\partial{\mu_k}}&=\sum_{j=1}^{N}\left\{0+0-0-\cfrac{\gamma_{jk}}{2\sigma_k^2}\cdot 2 \cdot(y_j-\mu_k)\right\} \\
&=\sum_{j=1}^{N}\left\{-\cfrac{\gamma_{jk}}{\sigma_k^2}\cdot(y_j-\mu_k)\right\} \\
&=\cfrac{\mu_k}{\sigma_k^2}\sum_{j=1}^{N}\gamma_{jk}-\cfrac{1}{\sigma_k^2}\sum_{j=1}^{N}\gamma_{jk}y_j \\
\end{aligned}</script><p>令上式等于0即可得：</p>
<script type="math/tex; mode=display">\mu_k^{(i+1)}=\cfrac{\sum_{j=1}^{N}\gamma_{jk}y_j}{\sum_{j=1}^{N}\gamma_{jk}}</script><p>$Q(\theta,\theta^{(i)})$关于$\sigma_k$求偏导（此时$k$是固定的）：</p>
<script type="math/tex; mode=display">\begin{aligned}
\cfrac{\partial{Q(\theta,\theta^{(i)})}}{\partial{\sigma_k}}&=\sum_{j=1}^{N}\left\{0+0-\gamma_{jk}\sigma_k^{-1}-\gamma_{jk}(y_j-\mu_k)^2\cdot\cfrac{1}{2}\cdot-2\cdot\sigma_k^{-3} \right\} \\
&=\sum_{j=1}^{N}\left\{\gamma_{jk}(y_j-\mu_k)^2\sigma_k^{-3}-\gamma_{jk}\sigma_k^{-1} \right\} \\
&=\sigma_k^{-3}\sum_{j=1}^{N}\gamma_{jk}(y_j-\mu_k)^2-\sigma_k^{-1}\sum_{j=1}^{N}\gamma_{jk} \\
\end{aligned}</script><p>令上式等于0即可得：</p>
<script type="math/tex; mode=display">[\sigma_k^{(i+1)}]^{2}=\cfrac{\sum_{j=1}^{N}\gamma_{jk}(y_j-\mu_k)^2}{\sum_{j=1}^{N}\gamma_{jk}}</script><p>求$\alpha_k^{(i+1)}$时需要注意，此时存在约束$\sum_{k=1}^{K}\alpha_k^{(i+1)}=1$，因此考虑使用拉格朗日乘子法，首先构造拉格朗日函数：</p>
<script type="math/tex; mode=display">L(\theta,\beta)=Q(\theta,\theta^{(i)})+\beta(\sum_{k=1}^{K}\alpha_k-1)</script><p>对$L(\theta,\beta)$关于$\sigma_k$求偏导（此时$k$是固定的）：</p>
<script type="math/tex; mode=display">\begin{aligned}
\cfrac{\partial{L(\theta,\beta)}}{\partial{\alpha_k}}&=\cfrac{\sum_{j=1}^{N}\gamma_{jk}}{\alpha_{k}}+\beta \\
\end{aligned}</script><p>令上式等于0即可得：</p>
<script type="math/tex; mode=display">\alpha_{k}^{(i+1)}=\cfrac{\sum_{j=1}^{N}\gamma_{jk}}{-\beta}</script><p>又由约束条件可得：</p>
<script type="math/tex; mode=display">\sum_{k=1}^{K}\alpha_k^{(i+1)}=\cfrac{\sum_{k=1}^{K}\sum_{j=1}^{N}\gamma_{jk}}{-\beta}=1</script><p>其中$\sum_{k=1}^{K}\sum_{j=1}^{N}\gamma_{jk}=\sum_{j=1}^{N}\sum_{k=1}^{K}\gamma_{jk}=\sum_{j=1}^{N}1=N$，所以</p>
<script type="math/tex; mode=display">\cfrac{N}{-\beta}=1\Rightarrow -\beta=N\Rightarrow \alpha_{k}^{(i+1)}=\cfrac{\sum_{j=1}^{N}\gamma_{jk}}{N}</script><p>【注】：</p>
<ul>
<li>上述“M步”中求极大化时直接就求偏导令其等于0进行求解，求出来的解一定是极大值点吗？不会是极小值点吗？不应该先做凹凸性判断吗？但是做凹凸性判断时$\sigma_k$的二阶偏导正负性无法判断呀。。。难道另有隐情？为何参考文献里都没提？挖坑待填。。。</li>
<li><a href="#ref2">[2]</a>中三硬币模型使用EM算法的推导过程参见<a href="#ref2">[6]</a></li>
</ul>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p><span id="ref1">[1] <a href="https://en.wikipedia.org/wiki/Jensen%27s_inequality" target="_blank" rel="noopener">Jensen’s inequality</a></span><br><span id="ref2">[2] 李航.《统计学习方法》</span><br><span id="ref3">[3] cs229-notes8</span><br><span id="ref4">[4] 周志华.《机器学习》</span><br><span id="ref5">[5] <a href="http://alexkong.net/2014/07/GMM-and-EM/" target="_blank" rel="noopener">高斯混合模型和期望最大化算法</a></span><br><span id="ref6">[6] <a href="http://www.cnblogs.com/Determined22/p/5776791.html" target="_blank" rel="noopener">NLP —— 图模型（零）：EM算法简述及简单示例（三硬币模型）</a></span></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在推导EM算法之前先学习一下&lt;strong&gt;Jensen不等式&lt;sup&gt;&lt;a href=&quot;#ref1&quot;&gt;[1]&lt;/a&gt;&lt;/sup&gt;&lt;/strong&gt;，Jensen不等式的定义如下：若&lt;br&gt;$f$是&lt;strong&gt;凸函数&lt;/strong&gt;，则&lt;/p&gt;
&lt;script typ
    
    </summary>
    
      <category term="机器学习" scheme="http://www.sm1les.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="EM算法" scheme="http://www.sm1les.com/tags/EM%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>梯度下降法与牛顿法</title>
    <link href="http://www.sm1les.com/2019/03/01/gradient-descent-and-newton-method/"/>
    <id>http://www.sm1les.com/2019/03/01/gradient-descent-and-newton-method/</id>
    <published>2019-03-01T03:21:35.000Z</published>
    <updated>2019-03-12T06:37:18.626Z</updated>
    
    <content type="html"><![CDATA[<h3 id="梯度下降法的泰勒公式推导-1-："><a href="#梯度下降法的泰勒公式推导-1-：" class="headerlink" title="梯度下降法的泰勒公式推导[1]："></a>梯度下降法的泰勒公式推导<sup><a href="#ref1">[1]</a></sup>：</h3><p>梯度下降法的目标是使得$f(x_t+\Delta x )&lt;f(x_t)$，由泰勒公式可知，$f(x)$在$x_t$点的一阶泰勒展开为：</p>
<script type="math/tex; mode=display">f(x) = f(x_t)+f’(x_t)(x-x_t)</script><p>则</p>
<script type="math/tex; mode=display">f(x_{t+1}) = f(x_t)+f’(x_t)(x_{t+1}-x_t)</script><p>又$x_{t+1}$可等价写作$x_t + \Delta x$，则上式可化为：</p>
<script type="math/tex; mode=display">f(x_t + \Delta x) = f(x_t)+f’(x_t) \cdot \Delta x</script><p>所以要想使得$f(x_t+\Delta x )<f(x_t)$，$f’(x_t) \cdot \delta x$必须小于0，此时$f’(x_t)$为定值，$\delta x$为可控部分，于是可以令$\delta x="-\eta" f’(x_t)$，其中$\eta>0$，则</f(x_t)$，$f’(x_t)></p>
<script type="math/tex; mode=display">f’(x_t) \cdot \Delta x= -\eta(f’(x_t))^2<0</script><p>由此可以推得当$\Delta x = -\eta \cdot f’(x_t)$时，$f(x_t+\Delta x )&lt;f(x_t)$恒成立。</p>
<h3 id="牛顿法的泰勒公式推导-2-："><a href="#牛顿法的泰勒公式推导-2-：" class="headerlink" title="牛顿法的泰勒公式推导[2]："></a>牛顿法的泰勒公式推导<sup><a href="#ref2">[2]</a></sup>：</h3><p>对于无约束的<strong>凸优化</strong>问题</p>
<script type="math/tex; mode=display">\min\limits_{\boldsymbol{x} \in \mathbb{R}^n}f(\boldsymbol{x})</script><p>其中$\boldsymbol{x}^*$为目标函数的最小值点，也是极小值点，牛顿法利用极小值点的必要条件</p>
<script type="math/tex; mode=display">\nabla f(\boldsymbol{x}^*)=\boldsymbol{0}</script><p>从点$\boldsymbol{x}^t$开始，求$ f(\boldsymbol{x})$在$\boldsymbol{x}^t$点的二阶泰勒展开式的极小值点（仅当$\boldsymbol{x}^{t}$点的海赛矩阵（Hessian matrix）为正定矩阵时），作为下一次（第$t+1$次）的迭代值$\boldsymbol{x}^{t+1}$，直到某次迭代值$\boldsymbol{x}^{t+1}$使得$\parallel\nabla f(\boldsymbol{x}^{t+1})\parallel&lt;\epsilon$时停止迭代，其中$\epsilon$为自定义的精度要求，具体迭代步骤如下，由多元函数的泰勒展开式<sup><a href="#ref3">[3]</a></sup>可得$f(\boldsymbol{x})$在$\boldsymbol{x}^{t}$点的二阶泰勒展开式为：</p>
<script type="math/tex; mode=display">f(\boldsymbol{x})=f(\boldsymbol{x}^t)+g_t^T \cdot (\boldsymbol{x}-\boldsymbol{x}^t)+\cfrac{1}{2}(\boldsymbol{x}-\boldsymbol{x}^t)^T \cdot H_t \cdot (\boldsymbol{x}-\boldsymbol{x}^t)</script><p>其中$g_t$为$f(\boldsymbol{x})$在$\boldsymbol{x}^{t}$点的梯度值，$H_t$为$f(\boldsymbol{x})$在$\boldsymbol{x}^{t}$点的海赛矩阵值。对上式求导并令其等于$\boldsymbol{0}$可得：</p>
<script type="math/tex; mode=display">g_t + H_t \cdot (\boldsymbol{x}-\boldsymbol{x}^t)=\boldsymbol{0}</script><p>解得$\boldsymbol{x}=\boldsymbol{x}^t-H_t^{-1}g_t$，令其为下一次的迭代值，即$\boldsymbol{x}^{t+1}=\boldsymbol{x}^t-H_t^{-1}g_t$。<br>【注】：</p>
<ul>
<li>牛顿法是经典的求根方法，在最优化问题里，通常最值点也是极值点，所以目标函数$f(x)$的一阶导函数$f’(x)$在最值点处一定等于0，此时求目标函数$f(x)$最小值的问题转化为了求目标函数的一阶导函数$f’(x)$的根的问题<sup><a href="#ref4">[4]</a></sup>；</li>
<li>关于牛顿法和梯度下降法的效率对比：从本质上去看，牛顿法是二阶收敛，梯度下降是一阶收敛，所以牛顿法就更快。如果更通俗地说的话，比如你想找一条最短的路径走到一个盆地的最底部，梯度下降法每次只从你当前所处位置选一个坡度最大的方向走一步，牛顿法在选择方向时，不仅会考虑坡度是否够大，还会考虑你走了一步之后，坡度是否会变得更大。所以，可以说牛顿法比梯度下降法看得更远一点，能更快地走到最底部。（牛顿法目光更加长远，所以少走弯路；相对而言，梯度下降法只考虑了局部的最优，没有全局思想。）根据wiki上的解释，从几何上说，牛顿法就是用一个二次曲面去拟合你当前所处位置的局部曲面，而梯度下降法是用一个平面去拟合当前的局部曲面，通常情况下，二次曲面的拟合会比平面更好，所以牛顿法选择的下降路径会更符合真实的最优下降路径<sup><a href="#ref5">[5]</a></sup>。<center>
<img src="./gdandnewton.jpg"><br>
红色为牛顿法的迭代路径，绿色为梯度下降法的迭代路径
</center>

</li>
</ul>
<h3 id="参考文献："><a href="#参考文献：" class="headerlink" title="参考文献："></a>参考文献：</h3><p><span id="ref1">[1] <a href="https://zhuanlan.zhihu.com/p/36564434" target="_blank" rel="noopener">梯度下降法 —— 经典的优化方法</a></span><br><span id="ref2">[2]  李航.《统计学习方法》</span><br><span id="ref3">[3] <a href="https://blog.csdn.net/red_stone1/article/details/70260070" target="_blank" rel="noopener">多元函数的泰勒(Taylor)展开式</a></span><br><span id="ref4">[4] <a href="http://sofasofa.io/forum_main_post.php?postid=1000966" target="_blank" rel="noopener">牛顿法到底是一阶优化算法还是二阶优化算法？</a></span><br><span id="ref5">[5] <a href="http://www.cnblogs.com/maybe2030/p/4751804.html" target="_blank" rel="noopener">常见的几种最优化方法</a></span></p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;梯度下降法的泰勒公式推导-1-：&quot;&gt;&lt;a href=&quot;#梯度下降法的泰勒公式推导-1-：&quot; class=&quot;headerlink&quot; title=&quot;梯度下降法的泰勒公式推导[1]：&quot;&gt;&lt;/a&gt;梯度下降法的泰勒公式推导&lt;sup&gt;&lt;a href=&quot;#ref1&quot;&gt;[1]&lt;/
    
    </summary>
    
      <category term="最优化" scheme="http://www.sm1les.com/categories/%E6%9C%80%E4%BC%98%E5%8C%96/"/>
    
    
      <category term="梯度下降法" scheme="http://www.sm1les.com/tags/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/"/>
    
      <category term="牛顿法" scheme="http://www.sm1les.com/tags/%E7%89%9B%E9%A1%BF%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>Logistic回归与最大熵</title>
    <link href="http://www.sm1les.com/2019/01/17/logistic-regression-and-maximum-entropy/"/>
    <id>http://www.sm1les.com/2019/01/17/logistic-regression-and-maximum-entropy/</id>
    <published>2019-01-17T14:22:03.000Z</published>
    <updated>2019-01-18T05:35:30.038Z</updated>
    
    <content type="html"><![CDATA[<p>根据Wikipedia上的资料显示，Logistic回归的起源主要有以下几大历程：最早由Pierre François Verhulst在对人口增长情况进行研究时提出Logistic function<sup><a href="#ref1">[1]</a></sup>，后来Joseph Berkson在其基础上提出Logit function<sup><a href="#ref2">[2]</a></sup>，再后来David Cox用Logit function来做二分类的回归分析，进而提出了Logistic regression<sup><a href="#ref3">[3]</a></sup>，详细的起源历程参见<a href="#ref4">[4]</a>和<a href="#ref5">[5]</a>。Logistic回归除了按照它的起源从对数几率的角度解释以外，还有业界比较认同的从最大熵的角度来解释，下面给出Logistic回归从最大熵角度的解释。</p>
<p>对于数据集$\{(\boldsymbol x_1,y_1),(\boldsymbol x_2,y_2)…(\boldsymbol x_m,y_m)\}$，其中$\boldsymbol x_i\in \mathbb{R}^n,i=1,2…m$，Logistic回归在对随机变量$y\vert\boldsymbol x$建模的时候是假设其取值仅为0或1，即$y_i\in\{0,1\}$，且$y\vert\boldsymbol x$有固定但未知的期望$\mu$，所以根据<strong>最大熵原理</strong>，此时可以假设$y\vert\boldsymbol x$服从伯努利分布（原因参见<a href="https://www.sm1les.com/2019/01/13/exponential-family-and-maximum-entropy">《指数族分布与最大熵》</a>），接着我们想用线性模型来对$y\vert\boldsymbol x$的概率$p(y\vert\boldsymbol x)$进行建模，于是可以通过广义线性模型（Generalized Linear Models）<sup><a href="#ref6">[6]</a></sup>的建模方法得到我们想要的模型。广义线性模型的建模步骤如下<sup><a href="#ref7">[7]</a></sup>：</p>
<ul>
<li>在给定$\boldsymbol x$的条件下，假设随机变量$y\vert\boldsymbol x$服从某个指数族分布（Exponential family）<sup><a href="#ref8">[8]</a></sup>；</li>
<li>假设该指数族分布中的自然参数$\eta(\boldsymbol\theta)$和$\boldsymbol x$呈线性关系，即$\eta(\boldsymbol\theta) = \boldsymbol w^T \boldsymbol x$；</li>
<li>建模出的模型为$T(y\vert\boldsymbol x)$的期望$E[T(y\vert\boldsymbol x)]$的表达式。</li>
</ul>
<p>在使用上述步骤对$y$进行建模前，先证明一下伯努利分布属于指数族分布：<br>伯努利分布的分布律如下：</p>
<script type="math/tex; mode=display">p(x)=\mu^x (1-\mu)^{1-x}</script><p>其中$x\in\{0,1\}$，$\mu$为$x=1$的概率也为$x$的期望，即$p(1)=E[x]=\mu$。对其进行恒等变形可得：</p>
<script type="math/tex; mode=display">
\begin{aligned}    
p(x) &= \mu^x (1-\mu)^{1-x} \\
&= \exp(x \ln \mu+(1−x) \ln(1−\mu)) \\
&= \exp \left((\ln(\cfrac{\mu}{1-\mu}))x+\ln(1-\mu) \right)
\end{aligned}</script><p>对照<a href="https://www.sm1les.com/2019/01/13/exponential-family-and-maximum-entropy">《指数族分布与最大熵》</a>中指数族分布的一般形式可知，伯努利分布属于指数族分布，且对应的指数族分布参数为：</p>
<script type="math/tex; mode=display">
\begin{aligned}    
\boldsymbol\theta &=\mu &(A.1)\\
\eta(\boldsymbol\theta)&= \ln(\cfrac{\mu}{1-\mu}) &(A.2)\\
T(x) &= x &(A.3)\\
A(\boldsymbol\theta) &= -\ln(1-\mu) &(A.4)\\
h(x) &= 1 &(A.5)
\end{aligned}</script><p>现在便可以根据上述广义线性模型的建模步骤对$y$进行建模：首先$y$服从伯努利分布，属于指数族分布，接着假设伯努利分布中的自然参数$\eta(\boldsymbol\theta)=\boldsymbol w^T \boldsymbol x$，再接着计算充分统计量$T(y\vert\boldsymbol x)$的期望表达式：</p>
<script type="math/tex; mode=display">
\begin{aligned}    
E[T(y\vert\boldsymbol x)]&= E[y\vert\boldsymbol x] \\
&= \mu \\
&= \cfrac{1}{1+e^{(-\eta(\boldsymbol\theta))}} \\
&= \cfrac{1}{1+e^{(-\boldsymbol w^T \boldsymbol x)}}
\end{aligned}</script><p>其中，第1个等式由式（A.3）导出；第2个等式是因为$y\vert\boldsymbol x$服从伯努利分布，所以$E(y\vert\boldsymbol x)=1*p(1\vert\boldsymbol x)+0*(1-p(1\vert\boldsymbol x))=p(1\vert\boldsymbol x)=\mu$；第3个等式是由式(A.2)导出，所以现在建模出的模型为：</p>
<script type="math/tex; mode=display">E(y\vert\boldsymbol x)=p(1\vert\boldsymbol x)=\cfrac{1}{1+e^{(-\boldsymbol w^T \boldsymbol x)}}</script><p>显然此即为Logistic回归模型。<br>【注】：</p>
<ul>
<li>上述广义线性模型的建模步骤是一种固定的建模方法，也就是说在构建广义线性模型时，我们唯一要做的就是假设$y\vert\boldsymbol x$服从何种<strong>指数族分布</strong>，通常是以最大熵原理为准则来假设$y\vert\boldsymbol x$的分布，例如在做二分类问题时通常假设$y\vert\boldsymbol x$服从伯努利分布，在做回归问题时通常假设$y\vert\boldsymbol x$服从高斯分布，在做网站访问量预测时通常假设$y\vert\boldsymbol x$服从泊松分布。在确定$y\vert\boldsymbol x$的分布后，只需按照上述步骤即可构建出一个广义线性模型；</li>
<li>除了从伯努利分布属于最大熵分布来解释以外，还有学者直接通过最大熵原理推导出Logistic回归，详细推导过程参见<a href="#ref9">[9]</a>，文中推导思路如下：首先说明Logistic回归是多分类模型类别总数k=2时的特例，所以只要用最大熵原理推导出多分类模型也就推导出了Logistic回归。于是先证明了多分类模型的Softmax函数在取得最优参数时类似一个指示函数，接着便以此为约束条件用最大熵原理推导出Softmax函数，也即推导出多分类模型，进而也就推导出了Logistic回归。类似的直接从最大熵原理出发的推导还有<a href="#ref10">[10]</a>；</li>
<li>Logistic回归也可以从贝叶斯的角度解释，参见<a href="#ref11">[11]</a></li>
<li>本文启发自知乎上的讨论：<a href="https://www.zhihu.com/question/35322351" target="_blank" rel="noopener">为什么 LR 模型要使用 sigmoid 函数，背后的数学原理是什么？</a></li>
</ul>
<h3 id="参考文献："><a href="#参考文献：" class="headerlink" title="参考文献："></a>参考文献：</h3><p><span id="ref1">[1] <a href="https://en.wikipedia.org/wiki/Logistic_function" target="_blank" rel="noopener">Logistic function</a></span><br><span id="ref2">[2] <a href="https://en.wikipedia.org/wiki/Logit" target="_blank" rel="noopener">Logit</a></span><br><span id="ref3">[3] <a href="https://en.wikipedia.org/wiki/Logistic_regression" target="_blank" rel="noopener">Logistic regression</a></span><br><span id="ref4">[4] <a href="https://chenrudan.github.io/blog/2016/01/09/logisticregression.html" target="_blank" rel="noopener">【机器学习算法系列之二】浅析Logistic Regression</a></span><br><span id="ref5">[5] Cramer J S . The Origins of Logistic Regression</span><br><span id="ref6">[6] <a href="https://en.wikipedia.org/wiki/Generalized_linear_model" target="_blank" rel="noopener">Generalized linear model</a></span><br><span id="ref7">[7] Andrew Ng. cs229-notes1</span><br><span id="ref8">[8] <a href="https://en.wikipedia.org/wiki/Exponential_family" target="_blank" rel="noopener">Exponential family</a></span><br><span id="ref9">[9] <a href="http://www. win-vector. com/dfiles/LogisticRegressionMaxEnt. pdf" target="_blank" rel="noopener">Mount, J.The equivalence of logistic regression and maximum entropy models</a></span><br><span id="ref10">[10] <a href="https://www.zhihu.com/question/24094554/answer/108271031" target="_blank" rel="noopener">如何理解最大熵模型里面的特征？ - Semiring的回答 - 知乎</a></span><br><span id="ref11">[11] <a href="http://charleshm.github.io/2016/03/LR-and-NB/" target="_blank" rel="noopener">Logistic Regression and Naive Bayes</a></span></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;根据Wikipedia上的资料显示，Logistic回归的起源主要有以下几大历程：最早由Pierre François Verhulst在对人口增长情况进行研究时提出Logistic function&lt;sup&gt;&lt;a href=&quot;#ref1&quot;&gt;[1]&lt;/a&gt;&lt;/sup&gt;，后来
    
    </summary>
    
      <category term="机器学习" scheme="http://www.sm1les.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="最大熵" scheme="http://www.sm1les.com/tags/%E6%9C%80%E5%A4%A7%E7%86%B5/"/>
    
      <category term="Logistic回归" scheme="http://www.sm1les.com/tags/Logistic%E5%9B%9E%E5%BD%92/"/>
    
      <category term="广义线性模型" scheme="http://www.sm1les.com/tags/%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>指数族分布与最大熵</title>
    <link href="http://www.sm1les.com/2019/01/13/exponential-family-and-maximum-entropy/"/>
    <id>http://www.sm1les.com/2019/01/13/exponential-family-and-maximum-entropy/</id>
    <published>2019-01-13T07:55:30.000Z</published>
    <updated>2019-01-17T10:34:22.683Z</updated>
    
    <content type="html"><![CDATA[<h3 id="最大熵原理"><a href="#最大熵原理" class="headerlink" title="最大熵原理"></a>最大熵原理</h3><p>最大熵原理是概率模型学习的一个准则，最大熵原理认为：学习概率模型时，在所有可能的概率模型（分布）中，熵最大的模型是最好的模型。通常用约束条件来确定概率模型的集合，所以，最大熵原理也可以表述为在满足约束条件的模型集合中选取熵最大的模型<sup><a href="#ref1">[1]</a></sup>。此处所说的“熵”为信息论中的信息熵，信息熵定义如下：</p>
<ul>
<li>信息量：<script type="math/tex; mode=display">I(X) = -log_bp(X)</script>其中，$b=2$时单位为bit，$b=e$时单位为nat，$b=10$时单位为ban.</li>
<li>信息熵是信息量的期望，即：<script type="math/tex; mode=display">H(X)=E[I(X)]=E[-log_bp(X)]</script>当$X$为离散型时：<script type="math/tex; mode=display">H(X)=-\sum_x p(x)log_bp(x)</script>当$X$为连续型时：<script type="math/tex; mode=display">H(X)=-\int_{-\infty}^{+\infty}p(x)log_bp(x)dx</script>其中$p(x)=p(X=x)$，当$X$为连续型时信息熵也称为微分熵，熵只依赖于$X$的分布，而与$X$的取值无关。</li>
</ul>
<h3 id="指数族分布"><a href="#指数族分布" class="headerlink" title="指数族分布"></a>指数族分布</h3><p>指数族（Exponential family）分布<sup><a href="#ref2">[2]</a></sup>是一类分布的总称，该类分布的分布律（概率密度）的一般形式如下：</p>
<script type="math/tex; mode=display">\begin{aligned}    
p(x;\boldsymbol\theta) &= \cfrac{1}{Z(\boldsymbol\theta)} h(x) \exp\left(\eta(\boldsymbol\theta)^T T(x) \right) \\
&= h(x) \exp\left(\eta(\boldsymbol\theta)^T T(x) − A(\boldsymbol\theta)\right)
\end{aligned}</script><p>其中，$\boldsymbol\theta$为指数族分布的参数，视具体的分布而定，既可以是向量也可以是标量，此处暂用向量的形式表示，$\eta(\boldsymbol\theta)$是关于$\boldsymbol\theta$的函数，称作自然参数 (natural parameter，也称canonical parameter)，$T(x)$为充分统计量（sufficient statistic），$Z(\boldsymbol\theta)=\exp(-A(\boldsymbol\theta))$为配分函数（partition function），是用来保证分布律的累加和$\sum\limits_x p(x|\boldsymbol\theta)=1$或者概率密度的积分值$\int_{-\infty}^{+\infty}p(x|\boldsymbol\theta)=1$，$b(x)$为一个关于$x$的函数，常见的伯努利分布和正态分布均属于指数族分布，所有指数族分布以及每个分布的各项参数值参见<a href="#ref2">[2]</a>里的表格。指数族分布有个很重要的性质：在给定的约束条件下，指数族分布是信息熵（微分熵）最大的分布。例如：在已知$X\in\{0,1\}$且期望$E[X]=\mu$时，伯努利分布是熵最大的分布；在已知$X$的均值为$\mu$，方差为$\sigma^2$时，正态分布是熵最大的分布，其他最大熵分布参见<a href="#ref3">[3]</a>里的表格。</p>
<h5 id="指数族分布的最大熵推导："><a href="#指数族分布的最大熵推导：" class="headerlink" title="指数族分布的最大熵推导："></a>指数族分布的最大熵推导：</h5><p><strong>当$X$为离散型时</strong><sup><a href="#ref4">[4]</a></sup>：<br>若已知$X$满足如下约束条件：</p>
<script type="math/tex; mode=display">\sum_{k=1}^{n}\sum_{i=1}^{\vert X \vert} f_k(x_i)p(x_i) = F_k \qquad (A.1)</script><p>其中，$\vert X \vert$为$X$的可能取值个数，$n$为约束个数，$f_k(x_i)$为任意函数，$F_k$为已知常数，此时求$X$的最大熵分布等价于求解如下优化问题：</p>
<script type="math/tex; mode=display">\begin{aligned}    
\max\limits_{p}\quad&-\sum_{i=1}^{\vert X \vert} p(x_i)\ln p(x_i) \\
s.t.\quad &p(x_i)  \geq0 \\
&\sum_{i=1}^{\vert X \vert} p(x_i) = 1 \\
&\sum_{k=1}^{n}\sum_{i=1}^{\vert X \vert}  f_k(x_i)p(x_i) = F_k
\end{aligned}</script><p>其中信息熵的单位为nat，也即取$b=e$，对该优化问题用拉格朗日乘子法可得：</p>
<script type="math/tex; mode=display">\begin{aligned}    
L(p,\boldsymbol\lambda) &=-\sum_{i=1}^{\vert X \vert}p(x_i)\ln p(x_i)+\lambda_0(1-\sum_{i=1}^{\vert X \vert}p(x_i))+\sum_{k=1}^{n}\lambda_k\left(F_k-\sum_{i=1}^{\vert X \vert} f_k(x_i)p(x_i) \right) \\
&=\sum_{i=1}^{\vert X \vert} -p(x_i)\ln p(x_i)-\sum_{i=1}^{\vert X \vert} \lambda_0 p(x_i)-\sum_{i=1}^{\vert X \vert}\sum_{k=1}^{n}\lambda_kf_k(x_i)p(x_i)+\lambda_0+\sum_{k=1}^{n}\lambda_kF_k \\
&=\sum_{i=1}^{\vert X \vert}\left(-p(x_i)\ln p(x_i)-\lambda_0 p(x_i)-\sum_{k=1}^{n}\lambda_kf_k(x_i)p(x_i)\right)+\lambda_0+\sum_{k=1}^{n}\lambda_kF_k
\end{aligned}</script><p>其中，$p$可以看作一个分布律向量，也即$p=[p(x_1),p(x_2),…,p(x_{\vert X \vert})]$，$\boldsymbol\lambda=[\lambda_0,\lambda_1,…,\lambda_n]^T$为拉格朗日乘子向量，对$L(p,\boldsymbol\lambda)$关于$p$求偏导等价于分别对所有的$p(x_i)$求偏导：</p>
<script type="math/tex; mode=display">\begin{aligned}
\cfrac{\partial L(p,\boldsymbol\lambda)}{\partial p(x_1)}&=-\ln p(x_1)-1-\lambda_0-\sum_{k=1}^{n}\lambda_kf_k(x_1) \\
\cfrac{\partial L(p,\boldsymbol\lambda)}{\partial p(x_2)}&=-\ln p(x_2)-1-\lambda_0-\sum_{k=1}^{n}\lambda_kf_k(x_2) \\
\vdots \\
\cfrac{\partial L(p,\boldsymbol\lambda)}{\partial p(x_{\vert X \vert})}&=-\ln p(x_{\vert X \vert})-1-\lambda_0-\sum_{k=1}^{n}\lambda_kf_k(x_{\vert X \vert}) 
\end{aligned}</script><p>则</p>
<script type="math/tex; mode=display">\cfrac{\partial L(p,\boldsymbol\lambda)}{\partial p(x_i)}=-\ln p(x_i)-1-\lambda_0-\sum_{k=1}^{n}\lambda_kf_k(x_i)</script><p>令上式等于0解得：</p>
<script type="math/tex; mode=display">p(x_i) =\exp(-1-\lambda_0-\sum\limits_{k=1}^{n}\lambda_kf_k(x_i))</script><p>又由约束条件$\sum\limits_{i=1}^{\vert X \vert} p(x_i) = 1$可得：</p>
<script type="math/tex; mode=display">\begin{aligned}    
\sum_{i=1}^{\vert X \vert} \exp(-1-\lambda_0-\sum\limits_{k=1}^{n}\lambda_kf_k(x_i))= 1 \\
\sum_{i=1}^{\vert X \vert} \cfrac{\exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(x_i))}{e^{(1+\lambda_0)}}= 1 \\
e^{(1+\lambda_0)}=\sum_{i=1}^{\vert X \vert} \exp(-\sum_{k=1}^{n}\lambda_kf_k(x_i))
\end{aligned}</script><p>将其代入$p(x_i)$可得：</p>
<script type="math/tex; mode=display">p(x_i) =\cfrac{\exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(x_i))}{\sum\limits_{i=1}^{\vert X \vert} \exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(x_i))}</script><p>此式为$X$取到各个值$x_i$的概率，可以从中抽象出$X$的分布律为：</p>
<script type="math/tex; mode=display">\begin{aligned}    
p(x) &=\cfrac{\exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(x))}{\sum\limits_x\exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(x))} \qquad (A.2) \\
&=\cfrac{1}{Z}\exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(x))
\end{aligned}</script><p>其中$Z=\sum\limits_x\exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(x))$，此时$p(x)$的表达式显然符合指数族分布的一般形式。（注：上述推导过程是结合<a href="#ref1">[1]</a>中例6.2和<a href="#ref4">[4]</a>中9.2.6所述内容而成）<br><strong>当$X$为连续型时</strong>：<br>若已知$X$满足如下约束条件：</p>
<script type="math/tex; mode=display">\sum_{k=1}^{n}\int_{-\infty}^{+\infty}f_k(x)p(x)dx = F_k \qquad (B.1)</script><p>其中，$n$为约束个数，$f_k(x)$为任意函数，$F_k$为已知常数，此时求$X$的最大熵分布等价于求解如下优化问题：</p>
<script type="math/tex; mode=display">\begin{aligned}    
\max\limits_{p}\quad&-\int_{-\infty}^{+\infty}p(x)\ln p(x)dx \\
s.t.\quad &p(x)  \geq0 \\
&\int_{-\infty}^{+\infty}p(x)dx = 1 \\
&\int_{-\infty}^{+\infty}f_k(x)p(x)dx = F_k
\end{aligned}</script><p>其中信息熵的单位为nat，也即取$b=e$，对该优化问题用拉格朗日乘子法可得：</p>
<script type="math/tex; mode=display">\begin{aligned}    
L(p,\boldsymbol\lambda) &=-\int_{-\infty}^{+\infty}p(x)\ln p(x)dx+\lambda_0(1-\int_{-\infty}^{+\infty}p(x)dx)+\sum_{k=1}^{n}\lambda_k\left(F_k-\int_{-\infty}^{+\infty}f_k(x)p(x)dx \right) \\
&=\int_{-\infty}^{+\infty}-p(x)\ln p(x)dx-\int_{-\infty}^{+\infty}\lambda_0 p(x)dx-\int_{-\infty}^{+\infty}\sum_{k=1}^{n}\lambda_kf_k(x)p(x)dx+\lambda_0+\sum_{k=1}^{n}\lambda_kF_k \\
&=\int_{-\infty}^{+\infty}\left(-p(x)\ln p(x)-\lambda_0 p(x)-\sum_{k=1}^{n}\lambda_kf_k(x)p(x)\right)dx+\lambda_0+\sum_{k=1}^{n}\lambda_kF_k
\end{aligned}</script><p>其中，$\int_{-\infty}^{+\infty}$可以看作$\sum\limits_x$，因此可以按照$X$为离散型时的推导方法推得$X$的分布律为：</p>
<script type="math/tex; mode=display">\begin{aligned}    
p(x) &=\cfrac{\exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(x))}{\int_{-\infty}^{+\infty}\exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(x))dx} \qquad (B.2)\\
&=\cfrac{1}{Z}\exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(x))
\end{aligned}</script><p>其中$Z=\int_{-\infty}^{+\infty}\exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(x))dx$。</p>
<h5 id="伯努利分布的最大熵推导："><a href="#伯努利分布的最大熵推导：" class="headerlink" title="伯努利分布的最大熵推导："></a>伯努利分布的最大熵推导：</h5><p><strong>“已知$X\in\{0,1\}$且期望$E[X]=\mu$时，伯努利分布是熵最大的分布”</strong>，证明如下：<br>已知$X\in\{0,1\}$，所以$X$属于离散型，则根据式（A.2）知$X$的分布律的一般形式为：</p>
<script type="math/tex; mode=display">p(x) =\cfrac{\exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(x))}{\exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(0))+\exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(1))}</script><p>又已知$E[X]=\mu$，其等价于如下约束条件：</p>
<script type="math/tex; mode=display">\sum_{i=1}^{\vert X \vert} x_ip(x_i) =\mu</script><p>所以对比式（A.2）可知，此时$n=1,f_1(x_i)=x_i,F_1=\mu$，代入$p(x)$可得：</p>
<script type="math/tex; mode=display">p(x) =\cfrac{e^{-\lambda_1 x}}{1+e^{-\lambda_1}}</script><p>再由$E[X]=\mu$可得：</p>
<script type="math/tex; mode=display">E[X]=0*p(0)+1*p(1)=p(1)=\cfrac{e^{-\lambda_1}}{1+e^{-\lambda_1}}=\mu</script><p>所以$X$的分布律为：</p>
<script type="math/tex; mode=display">\begin{aligned}    
p(0)&=1-\mu \\
p(1)&=\mu
\end{aligned}</script><p>显然此即为伯努利分布，证毕。</p>
<h5 id="正态分布的最大熵推导："><a href="#正态分布的最大熵推导：" class="headerlink" title="正态分布的最大熵推导："></a>正态分布的最大熵推导：</h5><p><strong>“已知$X$的均值为$\mu$，方差为$\sigma^2$时，正态分布是熵最大的分布”</strong>，证明如下<sup><a href="#ref5">[5]</a></sup>：<br>此时没有限定$X$的取值范围，则默认为$X\in(-\infty,+\infty)$的连续型，已知$X$的均值为$\mu$，方差为$\sigma^2$，其等价于如下约束条件：</p>
<script type="math/tex; mode=display">\int_{-\infty}^{+\infty}(x-\mu)^2p(x)dx = \sigma^2</script><p>所以对比式（B.1）可知，此时$n=1,f_1(x)=(x-\mu)^2,F_1=\sigma^2$，代入式（B.1）可得此时$X$的分布律：</p>
<script type="math/tex; mode=display">p(x) =\cfrac{\exp(-\lambda_1 (x-\mu)^2)}{\int_{-\infty}^{+\infty}\exp(-\lambda_1 (x-\mu)^2)dx}</script><p>再由$\int_{-\infty}^{+\infty}(x-\mu)^2p(x)dx = \sigma^2$解得：</p>
<script type="math/tex; mode=display">\lambda_1=\cfrac{1}{2\sigma^2}</script><p>代入$p(x)$中得：</p>
<script type="math/tex; mode=display">p(x) =\cfrac{1}{\sqrt{2\pi}\sigma}\exp\left(-\cfrac{(x-\mu)^2}{2\sigma^2}\right)</script><p>显然此即为正态分布，证毕。</p>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p><span id="ref1">[1] 李航.《统计学习方法》</span><br><span id="ref2">[2] <a href="https://en.wikipedia.org/wiki/Exponential_family" target="_blank" rel="noopener">Exponential family</a></span><br><span id="ref3">[3] <a href="https://en.wikipedia.org/wiki/Maximum_entropy_probability_distribution" target="_blank" rel="noopener">Maximum entropy probability distribution</a></span><br><span id="ref4">[4] Murphy K P. 《Machine Learning: A Probabilistic Perspective》</span><br><span id="ref5">[5] 周晓飞. 《统计机器学习》课程的课件</span></p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;最大熵原理&quot;&gt;&lt;a href=&quot;#最大熵原理&quot; class=&quot;headerlink&quot; title=&quot;最大熵原理&quot;&gt;&lt;/a&gt;最大熵原理&lt;/h3&gt;&lt;p&gt;最大熵原理是概率模型学习的一个准则，最大熵原理认为：学习概率模型时，在所有可能的概率模型（分布）中，熵最大的模型是最
    
    </summary>
    
      <category term="机器学习" scheme="http://www.sm1les.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="指数族分布" scheme="http://www.sm1les.com/tags/%E6%8C%87%E6%95%B0%E6%97%8F%E5%88%86%E5%B8%83/"/>
    
      <category term="最大熵" scheme="http://www.sm1les.com/tags/%E6%9C%80%E5%A4%A7%E7%86%B5/"/>
    
  </entry>
  
  <entry>
    <title>L1正则化和L2正则化</title>
    <link href="http://www.sm1les.com/2019/01/07/l1-and-l2-regularization/"/>
    <id>http://www.sm1les.com/2019/01/07/l1-and-l2-regularization/</id>
    <published>2019-01-07T09:35:09.000Z</published>
    <updated>2019-03-10T10:04:29.768Z</updated>
    
    <content type="html"><![CDATA[<p>正则化是结构风险最小化策略的实现，是在经验风险上加一个正则化项或罚项，正则化项一般是模型复杂度的单调递增函数，模型越复杂，正则化值就越大。例如模型参数向量的范数，正则化的一般形式如下<sup><a href="#ref1">[1]</a></sup>：</p>
<script type="math/tex; mode=display">\min \limits_{f\in\mathcal{F}} \left( \cfrac{1}{N} \sum_{N}^{i=1} L(y_i,f(x_i))+\lambda J(f) \right) \qquad (A.1)</script><p>其中，第1项是经验风险，第2项是正则化项，$\lambda$为调整两者之间关系的系数。常用的正则化项是模型参数向量的$L_1$范数和$L_2$范数，分别称作L1正则化和L2正则化。以线性回归为例，其L1正则化的损失函数为：</p>
<script type="math/tex; mode=display">J(\boldsymbol w)=\cfrac{1}{N} \sum_{N}^{i=1} (f(\boldsymbol x_i;\boldsymbol w)-y_i)^2+\lambda \Vert\boldsymbol w \Vert_1</script><p>其中$\Vert\boldsymbol w \Vert_1$为$\boldsymbol w$的$L_1$范数，同理可得L2正则化的损失函数为：</p>
<script type="math/tex; mode=display">J(\boldsymbol w)=\cfrac{1}{N} \sum_{N}^{i=1} (f(\boldsymbol x_i;\boldsymbol w)-y_i)^2+\lambda \Vert\boldsymbol w \Vert_2^2</script><p>其中$\Vert\boldsymbol w \Vert_2$为$\boldsymbol w$的$L_2$范数，使用L1正则化或L2正则化的线性回归也称作<strong>LASSO回归</strong><sup><a href="#ref2">[2]</a></sup>或<strong>岭回归</strong><sup><a href="#ref3">[3]</a></sup>。<br>L1正则化和L2正则化最主要的不同之处在于前者更易得稀疏解，解释如下<sup><a href="#ref2">[2]</a></sup>：</p>
<h5 id="从优化问题的角度："><a href="#从优化问题的角度：" class="headerlink" title="从优化问题的角度："></a>从优化问题的角度：</h5><p>式(A.1)可以看作如下优化问题：</p>
<script type="math/tex; mode=display">\begin{aligned}
& \min\limits_{\boldsymbol w} \quad E_{emp}(\boldsymbol w) \\
& s.t.  \quad \lambda E_{reg}(\boldsymbol w) \leq \eta
\end{aligned}</script><p>其中$E_{emp}(\boldsymbol w)$是经验风险，$E_{reg}(\boldsymbol w)$是正则化项，$\eta$是自行设定的容忍度，此优化问题可以描述为：<strong>把$\boldsymbol w$的解限制一定范围内，同时使得经验风险尽可能小</strong>。L1正则化和L2正则化画图表示如下：</p>
<p><center>
<img src="./l1vsl2.png">
</center><br>其中，左图为L1正则化，右图为L2正则化，$\boldsymbol w^*$是$\boldsymbol w$的解，蓝色等高线为经验风险$E_{emp}(\boldsymbol w)$的取值，红色等高线为正则化项$E_{reg}(\boldsymbol w)$的取值，黄色区域是红色等高线的变化范围，也即$\boldsymbol w^*$的取值范围，默认内环等高线的值更小。从图中可以看出，红色等高线和蓝色等高线的<strong>切点</strong>即为优化问题的解$\boldsymbol w^*$，而且L1正则化相比于L2正则化更容易使得切点落在$\boldsymbol w$某个维度$w_i$的坐标轴上，从而导致另一个维度$w_j$的取值为0，从而更容易得到具有稀疏性的$\boldsymbol w^*$。</p>
<h5 id="从梯度的角度："><a href="#从梯度的角度：" class="headerlink" title="从梯度的角度："></a>从梯度的角度：</h5><p>L1正则化的损失函数一般形式为：</p>
<script type="math/tex; mode=display">J(\boldsymbol w)=L(\boldsymbol w)+\lambda \sum \vert w_i \vert \qquad (B.1)</script><p>L2正则化的损失函数一般形式为：</p>
<script type="math/tex; mode=display">J(\boldsymbol w)=L(\boldsymbol w)+\lambda \sum (w_i)^2 \qquad (B.2)</script><p>对式(B.1)关于$\boldsymbol w$某个维度$w_i$求偏导可得：</p>
<script type="math/tex; mode=display">\cfrac{\partial J(\boldsymbol w)}{\partial w_i}=\cfrac{\partial L(\boldsymbol w)}{\partial w_i}+\lambda sign (w_i)</script><p>对式(B.2)关于$\boldsymbol w$某个维度$w_i$求偏导可得：</p>
<script type="math/tex; mode=display">\cfrac{\partial J(\boldsymbol w)}{\partial w_i}=\cfrac{\partial L(\boldsymbol w)}{\partial w_i}+2\lambda w_i</script><p>当使用梯度下降法等此类根据$\boldsymbol w$的梯度来调整$\boldsymbol w$的算法时，若用L1正则化，$\boldsymbol w$的某个维度$w_i$的更新公式为：</p>
<script type="math/tex; mode=display">w_i:=w_i-\eta\cfrac{\partial J(\boldsymbol w)}{\partial w_i}=w_i-\eta\cfrac{\partial L(\boldsymbol w)}{\partial w_i}-\eta\lambda sign (w_i)</script><p>其中$\eta$为自行设定的学习率，从上式可以看出，$\eta\lambda sign (w_i)$的取值恒为$\pm\eta\lambda$，与$w_i$的大小无关，所以这就会导致即使$w_i$已经很小了但仍然以较高的梯度在变化，从而容易使得$w_i$取到0；若用L2正则化，则更新公式为：</p>
<script type="math/tex; mode=display">w_i:=w_i-\eta\cfrac{\partial J(\boldsymbol w)}{\partial w_i}=w_i-\eta\cfrac{\partial L(\boldsymbol w)}{\partial w_i}-2\eta\lambda w_i</script><p>显然此式中的$2\eta\lambda w_i$的大小与$w_i$相关，所以当$w_i$很小时变化的梯度也很小，不容易取到0，也就不容易得到稀疏解。</p>
<h5 id="从贝叶斯的角度："><a href="#从贝叶斯的角度：" class="headerlink" title="从贝叶斯的角度："></a>从贝叶斯的角度：</h5><p>贝叶斯学派常用的参数估计方法为最大后验估计（Maximum A Posteriori，MAP），最大后验估计法估计参数的公式为<sup><a href="#ref5">[5]</a></sup>：</p>
<script type="math/tex; mode=display">\begin{aligned}
\hat{\boldsymbol{w}} &= \mathop{\arg\max}_{\boldsymbol{w}}P(\boldsymbol{w} \vert \boldsymbol{y})\\
&= \mathop{\arg\max}_{\boldsymbol{w}}\log P(\boldsymbol{w} \vert \boldsymbol{y}) \\
&= \mathop{\arg\min}_{\boldsymbol{w}}-\log P(\boldsymbol{w} \vert \boldsymbol{y})
\end{aligned}</script><p>由贝叶斯公式可知$P(\boldsymbol{w} \vert \boldsymbol{y})=\cfrac{P(\boldsymbol{y} \vert \boldsymbol{w})\times P( \boldsymbol{w})}{P(\boldsymbol{y})}$，代入上式可得：</p>
<script type="math/tex; mode=display">\hat{\boldsymbol{w}} =\mathop{\arg\min}_{\boldsymbol{w}}-\log P(\boldsymbol{y} \vert \boldsymbol{w})-\log P(\boldsymbol{w})+\log P(\boldsymbol{y})</script><p>由于我们要求的是最优参数$\hat{\boldsymbol{w}}$，与$P(\boldsymbol{y})$无关，所以上式最后一项可以略去，进而得到损失函数为：</p>
<script type="math/tex; mode=display">J(\boldsymbol{w}) =-\log P(\boldsymbol{y} \vert \boldsymbol{w})-\log P(\boldsymbol{w})</script><p>其中$\log P(\boldsymbol{y} \vert \boldsymbol{w})$为对数似然函数，$P(\boldsymbol{w})$为我们对参数$\boldsymbol{w}$的先验估计，当我们先验估计参数$\boldsymbol{w}$服从均值为0方差为$\sigma^2$高斯分布时，即：</p>
<script type="math/tex; mode=display">\begin{aligned}
P(\boldsymbol{w}) &= \prod_{i=1}^{d}P(w_i)=\prod_{i=1}^{d}\cfrac{1}{\sqrt{2\pi}\sigma} \mathrm{exp}\left(-\cfrac{w_i^2}{2\sigma^2}\right) \\ 
\log P(\boldsymbol{w}) &= \sum_{i=1}^{d}\log\cfrac{1}{\sqrt{2\pi}\sigma} \mathrm{exp}\left(-\cfrac{w_i^2}{2\sigma^2}\right) \\
&= d \cdot \log\cfrac{1}{\sqrt{2\pi}\sigma} -\cfrac{1}{2\sigma^2} \cdot  \sum_{i=1}^{d}w_i^2 \\
&= d \cdot \log\cfrac{1}{\sqrt{2\pi}\sigma} -\cfrac{1}{2\sigma^2} \cdot  \Vert\boldsymbol{w}\Vert_2^2
\end{aligned}</script><p>代入损失函数$J(\boldsymbol{w})$可得：</p>
<script type="math/tex; mode=display">J(\boldsymbol{w}) = -\log P(\boldsymbol{y} \vert \boldsymbol{w})-d \cdot \log\cfrac{1}{\sqrt{2\pi}\sigma} +\cfrac{1}{2\sigma^2} \cdot  \Vert\boldsymbol{w}\Vert_2^2</script><p>同理$d \cdot \log\cfrac{1}{\sqrt{2\pi}\sigma}$与$\boldsymbol{w}$无关，可以略去，所以：</p>
<script type="math/tex; mode=display">J(\boldsymbol{w})=  -\log P(\boldsymbol{y} \vert \boldsymbol{w})+\cfrac{1}{2\sigma^2} \cdot  \Vert\boldsymbol{w}\Vert_2^2</script><p>此时可以看出<strong>采用高斯分布先验的最大后验估计=最大似然估计+L2正则项</strong>，同理可得<strong>采用拉普拉斯分布先验的最大后验估计=最大似然估计+L1正则项</strong>，观察高斯分布和拉普拉斯分布的概率密度函数图像可知，拉普拉斯分布更为稀疏，也即取到0的概率更大。</p>
<p><center>
<img src="./normalandlaplace.png" width="60%" height="60%"><br>
图中高斯分布和拉普拉斯分布的均值和方差均相同
</center><br>L1正则化和L2正则化还有如下不同之处：</p>
<ul>
<li>L1正则化自带特征选择的功能，这是由于L1正则化易得稀疏解导致的，因为稀疏解$\boldsymbol w^*$的某些维度$w_i=0$，从而达到了特征选择的功能；</li>
<li>L1正则化的解不稳定，也即可能会有多个解，这是因为L1正则化的红色等高线容易与经验风险的蓝色等高线产生多个切点，例如上图中的蓝色等高线若不为圆形曲线，而是直线时，此时极有可能与L1正则化的红色等高线重合，从而产生多个解；</li>
<li>L1正则化不易求解，这是因为绝对值函数通常都不好求解；</li>
<li>L1正则化相对于L2正则化对异常值敏感度低，这是因为当$\vert w_i \vert&gt;1$时，$\sum\vert w_i \vert &lt; \sum(w_i)^2$，从而对异常值敏感度低。</li>
</ul>
<h3 id="参考文献："><a href="#参考文献：" class="headerlink" title="参考文献："></a>参考文献：</h3><p><span id="ref1">[1] 李航.《统计学习方法》</span><br><span id="ref2">[2] <a href="https://en.wikipedia.org/wiki/Lasso_(statistics)" target="_blank" rel="noopener">Lasso (statistics)</a></span><br><span id="ref3">[3] <a href="https://en.wikipedia.org/wiki/Tikhonov_regularization" target="_blank" rel="noopener"> Ridge regression</a></span><br><span id="ref4">[4] <a href="https://www.zhihu.com/question/37096933" target="_blank" rel="noopener">l1 相比于 l2 为什么容易获得稀疏解？</a></span><br><span id="ref5">[5] <a href="https://zhuanlan.zhihu.com/p/32480810" target="_blank" rel="noopener">聊一聊机器学习的MLE和MAP：最大似然估计和最大后验估计</a></span></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;正则化是结构风险最小化策略的实现，是在经验风险上加一个正则化项或罚项，正则化项一般是模型复杂度的单调递增函数，模型越复杂，正则化值就越大。例如模型参数向量的范数，正则化的一般形式如下&lt;sup&gt;&lt;a href=&quot;#ref1&quot;&gt;[1]&lt;/a&gt;&lt;/sup&gt;：&lt;/p&gt;
&lt;scrip
    
    </summary>
    
      <category term="机器学习" scheme="http://www.sm1les.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="正则化" scheme="http://www.sm1les.com/tags/%E6%AD%A3%E5%88%99%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>Logistic回归——为什么用对数损失函数而不用平方损失函数？</title>
    <link href="http://www.sm1les.com/2019/01/02/logistic-regression-log-loss-and-quadratic-loss/"/>
    <id>http://www.sm1les.com/2019/01/02/logistic-regression-log-loss-and-quadratic-loss/</id>
    <published>2019-01-02T10:14:17.000Z</published>
    <updated>2019-01-13T10:50:14.716Z</updated>
    
    <content type="html"><![CDATA[<p>损失函数本身作为选取最优模型的准则，当然是可以任意选取的，但是不同的模型选取场景下，各个准则的评价效果是不同的，因此需要因地制宜，选择评价效果最好的准则。</p>
<h3 id="平方损失函数"><a href="#平方损失函数" class="headerlink" title="平方损失函数"></a>平方损失函数</h3><p>由最小二乘法可以推得Logistic回归的平方损失函数为<sup><a href="#ref1">[1]</a></sup>：</p>
<script type="math/tex; mode=display">J(\boldsymbol w)=\sum_{i=1}^{m} \left( y_i - \cfrac{1}{1+e^{-\boldsymbol w^T\boldsymbol x_i}} \right)^2</script><p>此函数为<strong>非凸</strong>函数，易得局部最优解，不易求得全局最优解。</p>
<h3 id="对数损失函数"><a href="#对数损失函数" class="headerlink" title="对数损失函数"></a>对数损失函数</h3><p>对数损失函数也称为对数似然损失函数，一般由最（极）大似然估计法推得，推导过程如下：<br>设$y\in\{0,1\}$，$y$取1和0的概率分别分为$p_1(\boldsymbol{x};\boldsymbol w)$和$p_0(\boldsymbol{x};\boldsymbol w)$，则：</p>
<script type="math/tex; mode=display">\begin{aligned}    
p_1(\boldsymbol{x};\boldsymbol w) &= \cfrac{e^{\boldsymbol w^T\boldsymbol x}}{1+e^{\boldsymbol w^T\boldsymbol x}} \\
p_0(\boldsymbol{x};\boldsymbol w) &= 1-p_1(\boldsymbol{x};\boldsymbol w)=\cfrac{1}{1+e^{\boldsymbol w^T\boldsymbol x}}
\end{aligned}</script><p>似然项为：</p>
<script type="math/tex; mode=display">p(y|\boldsymbol x;\boldsymbol w)=[p_1(\boldsymbol{x};\boldsymbol w)]^{y}[p_0(\boldsymbol{x};\boldsymbol w)]^{1-y}</script><p>对数似然函数为：</p>
<script type="math/tex; mode=display">\begin{aligned}    
\ln L(\boldsymbol w) &= \sum_{i=1}^{m}\left(y_i\ln(p_1(\boldsymbol{x_i};\boldsymbol w))+(1-y_i)\ln(p_0(\boldsymbol{x_i};\boldsymbol w)) \right) \\
&= \sum_{i=1}^{m}\left(y_i \boldsymbol w^T\boldsymbol x_i-\ln(1+e^{\boldsymbol w^T\boldsymbol x_i}) \right) 
\end{aligned}</script><p>似然函数的目标是最大化函数值，而损失函数的目标是最小化函数值，所以将上式添加一个负号即可得对数损失函数：</p>
<script type="math/tex; mode=display">J(\boldsymbol w) = \sum_{i=1}^{m}\left(-y_i \boldsymbol w^T\boldsymbol x_i+\ln(1+e^{\boldsymbol w^T\boldsymbol x_i}) \right)</script><p>此函数为高阶连续可导凸函数，可以用各种凸优化算法求得全局最优解，这就是为什么用对数损失函数而不用平方损失函数的原因。<br>【注】：</p>
<ul>
<li>$y\in\{0,1\}$时两种似然项构造：<script type="math/tex; mode=display">\begin{aligned}
p(y|\boldsymbol x;\boldsymbol w) &= [p_1(\boldsymbol{x};\boldsymbol w)]^{y}[p_0(\boldsymbol{x};\boldsymbol w)]^{1-y} \\
p(y|\boldsymbol x;\boldsymbol w) &= yp_1(\boldsymbol{x};\boldsymbol w)+(1-y)p_0(\boldsymbol{x};\boldsymbol w)
\end{aligned}</script></li>
<li>$y\in\{1,-1\}$时一种似然项构造：<script type="math/tex; mode=display">p(y|\boldsymbol x;\boldsymbol w)=\cfrac{1}{1+e^{-y\boldsymbol w^T\boldsymbol x}}</script>其相应的对数似然函数为：<script type="math/tex; mode=display">\ln L(\boldsymbol w)=-\sum_{i=1}^{m}\ln(1+e^{-y_i\boldsymbol w^T\boldsymbol x_i})</script></li>
</ul>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p><span id="ref1">[1] <a href="https://www.zhihu.com/question/65350200" target="_blank" rel="noopener">逻辑回归损失函数为什么使用最大似然估计而不用最小二乘法？</a></span></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;损失函数本身作为选取最优模型的准则，当然是可以任意选取的，但是不同的模型选取场景下，各个准则的评价效果是不同的，因此需要因地制宜，选择评价效果最好的准则。&lt;/p&gt;
&lt;h3 id=&quot;平方损失函数&quot;&gt;&lt;a href=&quot;#平方损失函数&quot; class=&quot;headerlink&quot; ti
    
    </summary>
    
      <category term="机器学习" scheme="http://www.sm1les.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Logistic回归" scheme="http://www.sm1les.com/tags/Logistic%E5%9B%9E%E5%BD%92/"/>
    
      <category term="损失函数" scheme="http://www.sm1les.com/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>拉格朗日对偶性</title>
    <link href="http://www.sm1les.com/2018/12/11/lagrange-duality/"/>
    <id>http://www.sm1les.com/2018/12/11/lagrange-duality/</id>
    <published>2018-12-11T07:36:48.000Z</published>
    <updated>2019-03-21T11:26:43.534Z</updated>
    
    <content type="html"><![CDATA[<p>对于带不等式约束的优化问题：</p>
<script type="math/tex; mode=display">\begin{aligned}
\min \quad f(\boldsymbol x) \\
s.t.  \quad g_i(\boldsymbol x) &\leq 0 \quad (i=1,...,n) \\
h_j(\boldsymbol x) &= 0 \quad (j=1,...,m)
\end{aligned}</script><p>令上述优化问题为<strong>“主问题”</strong>，其拉格朗日函数为：</p>
<script type="math/tex; mode=display">L(\boldsymbol x,\boldsymbol \mu,\boldsymbol \lambda)=f(\boldsymbol x)+\sum_{i=1}^{n}\mu_i g_i(\boldsymbol x)+\sum_{j=1}^{m}\lambda_j h_j(\boldsymbol x)</script><p>其中$\boldsymbol \mu=(\mu_1,\mu_2,…,\mu_n)^T,\boldsymbol \lambda=(\lambda_1,\lambda_2,…,\lambda_m)^T$<br>定义$L(\boldsymbol x,\boldsymbol \mu,\boldsymbol \lambda)$的<strong>对偶函数</strong>为：</p>
<script type="math/tex; mode=display">\Gamma (\boldsymbol \mu,\boldsymbol \lambda)=\mathop{\inf}_{\boldsymbol x∈D}L(\boldsymbol x,\boldsymbol \mu,\boldsymbol \lambda)=\mathop{\inf}_{\boldsymbol x∈D} \left ( f(\boldsymbol x)+\sum_{i=1}^{n}\mu_i g_i(\boldsymbol x)+\sum_{j=1}^{m}\lambda_j h_j(\boldsymbol x) \right)</script><p>其中$D=\boldsymbol{dom}  f \cap \bigcap\limits_{i=1}^{m}\boldsymbol{dom}  g_i \cap \bigcap\limits_{j=1}^{n}\boldsymbol{dom}  h_j $，为主问题的定义域。<br>设$\tilde{\boldsymbol x}$为可行域中的点（即$g_i(\tilde{\boldsymbol x}) \leq 0$且$h_j(\tilde{\boldsymbol x}) = 0$），当$\boldsymbol \mu \succeq 0$时：</p>
<script type="math/tex; mode=display">\sum_{i=1}^{n}\mu_i g_i(\tilde{\boldsymbol x})+\sum_{j=1}^{m}\lambda_j h_j(\tilde{\boldsymbol x}) \leq 0</script><p>则</p>
<script type="math/tex; mode=display">\Gamma (\boldsymbol \mu,\boldsymbol \lambda)=\mathop{\inf}_{\boldsymbol x∈D}L(\boldsymbol x,\boldsymbol \mu,\boldsymbol \lambda) \leq L(\tilde{\boldsymbol x},\boldsymbol \mu,\boldsymbol \lambda) \leq f(\tilde{\boldsymbol x})</script><script type="math/tex; mode=display">\Gamma (\boldsymbol \mu,\boldsymbol \lambda) \leq f(\tilde{\boldsymbol x})</script><p>这意味着当$\boldsymbol \mu \succeq 0$时，可行域中每个点$\tilde{\boldsymbol x}$均满足$\Gamma (\boldsymbol \mu,\boldsymbol \lambda)\leq f(\tilde{\boldsymbol x})$，设主问题的最优值为$p^*$（即$\min f(\tilde{\boldsymbol x})$），则当$\boldsymbol \mu \succeq 0$时，$\Gamma (\boldsymbol \mu,\boldsymbol \lambda) \leq p^*$恒成立，此时对偶函数构成了最优值$p^*$的下界。于是可以考虑求最优下界来逼近$p^*$，也就是求对偶函数<strong>在$\boldsymbol \mu \succeq 0$约束下</strong>的最大值：</p>
<script type="math/tex; mode=display">\max \Gamma (\boldsymbol \mu,\boldsymbol \lambda) \quad  s.t. \ \boldsymbol \mu \succeq 0</script><p>此时求对偶函数最大值的问题便是主问题的<strong>“对偶问题”</strong>。设对偶问题的最优值为$d^*$，显然$d^* \leq p^*$，此时称为“弱对偶性”成立，若$d^* = p^*$，则称为“强对偶性”成立，此时对偶问题的最优值便是主问题的最优值。<br>【注】：</p>
<ul>
<li>对偶问题恒为<strong>凸优化问题</strong>，因为对偶函数$\Gamma (\boldsymbol \mu,\boldsymbol \lambda)$是一族关于$(\boldsymbol \mu,\boldsymbol \lambda)$的仿射函数的逐点下确界，恒为<strong>凹函数</strong>（加个负号即可转为凸函数）（证明参见<a href="#ref1">[1]</a> § 3.2.3），约束条件$\boldsymbol \mu \succeq 0$为凸集，且与主问题的凹凸性无关。这也就是为什么不直接求解主问题转而去求解对偶问题的主要原因；</li>
<li>当主问题为<strong>凸优化问题</strong>时，若满足某些<strong>约束限制条件（constraint qualification）</strong>则强对偶性成立。常见的约束限制条件有<strong>Slater条件</strong><sup><a href="#ref2">[2]</a></sup>：“当可行域中存在一点在使得等式约束成立的同时也使得<strong>所有</strong>不等式约束<strong>严格成立</strong>（即$\exists  h_j(\tilde{\boldsymbol x}_a) = 0,g_i(\tilde{\boldsymbol x}_a) &lt; 0$）时，强对偶性成立。”（证明参见<a href="#ref1">[1]</a> § 5.3.2）Slater条件仅是众多使得凸优化问题强对偶性成立的约束限制条件之一，而且它也是<a href="/2018/12/08/karush-kuhn-tucker-conditions">KKT条件</a>中的约束限制条件之一；</li>
<li>Slater条件的“弱化”形式：“若前k个不等式约束为<strong>仿射函数</strong>，当$\exists  h_j(\tilde{\boldsymbol x}_a) = 0, g_i(\tilde{\boldsymbol x}_a) \leq 0  (i=1,…k),g_i(\tilde{\boldsymbol x}_a) &lt; 0  (i=k+1,…m)$时，凸优化问题强对偶性成立。”也就是说当不等式约束中有仿射函数时，不要求可行域中存在一点使得这些仿射不等式严格成立。<strong>特别地</strong>，若所有约束条件都是仿射等式或不等式，且$\boldsymbol{dom}  f$为开集，则凸优化问题在其可行域内强对偶性成立，例如SVM、任何可行的线性规划问题；</li>
<li>设$\boldsymbol x^*$是可行域中的最优解（即$f(\boldsymbol x^*)=p^*$），若$f(\boldsymbol x),g_i(\boldsymbol x),h_j(\boldsymbol x)$<strong>一阶可微</strong>，且强对偶性成立（不一定通过Slater条件得到），则$\boldsymbol x^*$一定满足KKT条件（证明参见<a href="#ref1">[1]</a> § 5.5.2-§ 5.5.3，其中§ 5.5.2里“$L(\boldsymbol x,\boldsymbol \mu^*,\boldsymbol \lambda^*)$关于$\boldsymbol x$求极小时在$\boldsymbol x^*$处取得最小值”的原因是主问题的最小值点必是拉格朗日函数的极值点之一）；</li>
<li>若主问题为<strong>凸优化问题</strong>，且$f(\boldsymbol x),g_i(\boldsymbol x),h_j(\boldsymbol x)$<strong>一阶可微</strong>，存在$\boldsymbol x^*,\boldsymbol \mu^*,\boldsymbol \lambda^*$满足KKT条件（即$\boldsymbol x^*$满足约束限制条件），那么$\boldsymbol x^*$和$(\boldsymbol \mu^*,\boldsymbol \lambda^*)$即为主问题和对偶问题的最优解，强对偶性成立（即$p^*=f(\boldsymbol x^*)=\Gamma (\boldsymbol \mu^*,\boldsymbol \lambda^*)=d^*$）（证明参见<a href="#ref1">[1]</a> § 5.5.3），显然此时KKT条件为最优解的充要条件，完全可以通过直接求满足KKT条件的点来求解最优解；</li>
<li>KKT条件成立和强对偶性成立没有必然的联系，也就是说当KKT条件成立时<strong>不一定</strong>能推出强对偶性成立，通常强对偶性成立的条件更为苛刻。</li>
<li>若拉格朗日函数$L(\boldsymbol x,\boldsymbol \mu,\boldsymbol \lambda)$是<strong>关于$\boldsymbol x$的一阶可微凸函数</strong>，则其对偶函数的表达式求解过程如下：先对$L(\boldsymbol x,\boldsymbol \mu,\boldsymbol \lambda)$关于$\boldsymbol x$求导并令导数等于0，得到一个$\boldsymbol x$关于$\boldsymbol \mu$和$\boldsymbol \lambda$的表达式$\boldsymbol x=\Phi (\boldsymbol \mu,\boldsymbol \lambda)$，然后将其带回到$L(\boldsymbol x,\boldsymbol \mu,\boldsymbol \lambda)$中即可得仅含$\boldsymbol \mu$和$\boldsymbol \lambda$的对偶函数$L \left ( \Phi (\boldsymbol \mu,\boldsymbol \lambda),\boldsymbol \mu,\boldsymbol \lambda \right ) =\Gamma (\boldsymbol \mu,\boldsymbol \lambda)$，例<a href="#ref1">[1]</a> § 5.2.4和SVM的对偶函数求解。</li>
</ul>
<h3 id="参考文献："><a href="#参考文献：" class="headerlink" title="参考文献："></a>参考文献：</h3><p><span id="ref1">[1] 王书宁 译.《凸优化》</span><br><span id="ref2">[2] <a href="https://en.wikipedia.org/wiki/Slater%27s_condition" target="_blank" rel="noopener">Slater’s condition</a></span></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;对于带不等式约束的优化问题：&lt;/p&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
\min \quad f(\boldsymbol x) \\
s.t.  \quad g_i(\boldsymbol x) &amp;\
    
    </summary>
    
      <category term="最优化" scheme="http://www.sm1les.com/categories/%E6%9C%80%E4%BC%98%E5%8C%96/"/>
    
    
      <category term="对偶" scheme="http://www.sm1les.com/tags/%E5%AF%B9%E5%81%B6/"/>
    
      <category term="Slater条件" scheme="http://www.sm1les.com/tags/Slater%E6%9D%A1%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title>Karush–Kuhn–Tucker（简称KKT）条件</title>
    <link href="http://www.sm1les.com/2018/12/08/karush-kuhn-tucker-conditions/"/>
    <id>http://www.sm1les.com/2018/12/08/karush-kuhn-tucker-conditions/</id>
    <published>2018-12-08T09:03:27.000Z</published>
    <updated>2019-01-05T10:44:02.046Z</updated>
    
    <content type="html"><![CDATA[<p>对于带不等式约束的优化问题：</p>
<script type="math/tex; mode=display">\begin{aligned}
\min \quad f(\boldsymbol x) \\
s.t.  \quad g_i(\boldsymbol x) &\leq 0 \quad (i=1,...,n) \\
h_j(\boldsymbol x) &= 0 \quad (j=1,...,m)
\end{aligned}</script><p>若$f(\boldsymbol x),g_i(\boldsymbol x),h_j(\boldsymbol x)$在$\boldsymbol x^*$处<strong>一阶可微</strong>，$\boldsymbol x^*$是优化问题的局部可行解（此时为极小值解），并且在$\boldsymbol x^*$处<strong>约束限制条件（constraint qualifications）</strong><sup><a href="#ref1">[1]</a></sup><sup><a href="#ref2">[2]</a></sup>成立，则存在$\boldsymbol \mu^*=(\mu_1^*,\mu_2^*,…,\mu_n^*)^T,\boldsymbol \lambda^*=(\lambda_1^*,\lambda_2^*,…,\lambda_m^*)^T,$使得：</p>
<script type="math/tex; mode=display">\left\{
\begin{aligned}
& \nabla L(\boldsymbol x^* ,\boldsymbol \mu^* ,\boldsymbol \lambda^* )=\nabla f(\boldsymbol  x^* )+\sum_{i=1}^{n}\mu_i^* \nabla g_i(\boldsymbol x^* )+\sum_{j=1}^{m}\lambda_j^* \nabla h_j(\boldsymbol x^*) &(1) \\
& h_j(\boldsymbol x^*)=0 &(2) \\
& g_i(\boldsymbol x^*) \leq 0 &(3) \\
& \mu_i^* \geq 0 &(4)\\
& \mu_i^* g_i(\boldsymbol x^*)=0 &(5)
\end{aligned}
\right.</script><p>其中$L(\boldsymbol x,\boldsymbol \mu,\boldsymbol \lambda)$为拉格朗日函数：</p>
<script type="math/tex; mode=display">L(\boldsymbol x,\boldsymbol \mu,\boldsymbol \lambda)=f(\boldsymbol x)+\sum_{i=1}^{n}\mu_i g_i(\boldsymbol x)+\sum_{j=1}^{m}\lambda_j h_j(\boldsymbol x)</script><p>以上即5条为KKT条件，其中条件(2)和(3)为约束条件显然成立，条件(1)、(4)、(5)成立的<strong>简单证明</strong>如下：</p>
<p><center>
<img src="./Inequality_constraint_diagram.png" width="60%" height="60%">
</center><br>由约束条件：$g_i(\boldsymbol x) \leq 0$可知，$\boldsymbol x^*$一定满足$g_i(\boldsymbol x^*) \lt 0$或者$g_i(\boldsymbol x^*) = 0$（也即条件(3)），对这两种情形进行讨论：</p>
<ul>
<li><strong>当$g_i(\boldsymbol x^*) \lt 0$时（如上左图）：</strong><br>此时极小值点在$g_i(\boldsymbol x) \lt 0$这个区域内，等价于<strong>无不等式约束条件</strong>的最优化问题，所以$\mu_i^* = 0$。</li>
<li><strong>当$g_i(\boldsymbol x^*) = 0$时（如上右图）：</strong><br>此时极小值点在$g_i(\boldsymbol x) = 0$这个边界上，等价于<strong>仅含等式约束条件</strong>的最优化问题，所以根据拉格朗日乘子法的原理可知，此时$f(\boldsymbol  x)$和$ g_i(\boldsymbol  x)=0$在极小值点处相切，梯度（正梯度）平行，即$\nabla f(\boldsymbol  x^*)+\mu_i^* \nabla g_i(\boldsymbol  x^*)=0 \quad (\mu_i^*∈\boldsymbol R)$。易知$g_i(\boldsymbol x)=0$这个边界上的梯度都是向外的，所以$\nabla f(\boldsymbol x^*)$必然和$\nabla g_i(\boldsymbol x^*)$的方向相反（如果不相反的话极小值点就不会在边界上取到而是在$g_i(\boldsymbol x) \lt 0$内取），所以$\nabla f(\boldsymbol  x^*)$和$\nabla g_i(\boldsymbol  x^*)$异号，也即$\mu_i^* \gt 0$。</li>
</ul>
<p>综上，条件(4)：$\mu_i^* \geq 0$恒成立；当$g_i(\boldsymbol x^*) \lt 0$时$\mu_i^* = 0$， $g_i(\boldsymbol x^*) = 0$时$\mu_i^* \gt 0$，所以条件(5)：$\mu_i^* g_i(\boldsymbol x^*)=0$恒成立；$\lambda_j$为拉格朗日乘子，由拉格朗日乘子法的原理可知，$\lambda_j$取值无要求，所以总存在$\lambda_j^*$使得条件(1)恒成立。<br>【注】：</p>
<ul>
<li>若局部可行解$\boldsymbol x^*$不满足<strong>约束限制条件（constraint qualifications）</strong><sup><a href="#ref1">[1]</a></sup><sup><a href="#ref2">[2]</a></sup>，则<strong>不一定</strong>满足KKT条件，也就是说约束限制条件仅是充分条件，而不是充要条件，例如上述优化问题强对偶性成立时（不一定通过Slater条件得到），$\boldsymbol x^*$也满足KKT条件；</li>
<li>KKT条件是局部可行解$\boldsymbol x^*$的一个<strong>必要条件</strong>；</li>
<li>对于上述优化问题，若目标函数$f(\boldsymbol x)$是凸函数，不等式约束$g_i(\boldsymbol x)$是凸函数，等式约束$h_j(\boldsymbol x)$是仿射函数，则称该优化问题为<strong>凸优化</strong>，此时KKT条件升级为<strong>充要条件</strong>，$\boldsymbol x^*$升级为<strong>全局可行解</strong>；</li>
<li>以上部分论述的严格数学证明参见<a href="#ref1">[1]</a> § 4.2</li>
</ul>
<h3 id="参考文献："><a href="#参考文献：" class="headerlink" title="参考文献："></a>参考文献：</h3><p><span id="ref1">[1] 王燕军. 《最优化基础理论与方法》</span><br><span id="ref2">[2] <a href="https://en.wikipedia.org/wiki/Karush%E2%80%93Kuhn%E2%80%93Tucker_conditions#Regularity_conditions_(or_constraint_qualifications)" target="_blank" rel="noopener">Karush–Kuhn–Tucker conditions</a></span></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;对于带不等式约束的优化问题：&lt;/p&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
\min \quad f(\boldsymbol x) \\
s.t.  \quad g_i(\boldsymbol x) &amp;\
    
    </summary>
    
      <category term="最优化" scheme="http://www.sm1les.com/categories/%E6%9C%80%E4%BC%98%E5%8C%96/"/>
    
    
      <category term="KKT条件" scheme="http://www.sm1les.com/tags/KKT%E6%9D%A1%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title>线性回归——最（极）大似然估计和最小二乘法推导</title>
    <link href="http://www.sm1les.com/2018/11/27/linear-regression-maximum-likelihood/"/>
    <id>http://www.sm1les.com/2018/11/27/linear-regression-maximum-likelihood/</id>
    <published>2018-11-27T07:20:01.000Z</published>
    <updated>2019-01-09T07:28:50.727Z</updated>
    
    <content type="html"><![CDATA[<h3 id="最（极）大似然估计推导："><a href="#最（极）大似然估计推导：" class="headerlink" title="最（极）大似然估计推导："></a>最（极）大似然估计推导：</h3><p>对于线性回归模型：</p>
<script type="math/tex; mode=display">y=\boldsymbol{w}^T\boldsymbol{x}+b+\epsilon</script><p>随机误差$\epsilon$可以看成是由许多观察不到的、可加的微小误差叠加而成的<sup><a href="#ref1">[1]</a></sup>，则根据<strong>中心极限定理</strong>，随机误差$\epsilon$服从正态分布，其分布为：$\epsilon \sim N(\mu,\sigma^2)$，为了方便后续计算可以将其去均值，令$\epsilon:=\epsilon-\mu$，则此时的分布为：$\epsilon \sim N(0,\sigma^2)$，分布律为：</p>
<script type="math/tex; mode=display">p(\epsilon)=\cfrac{1}{\sqrt{2\pi}\sigma} \mathrm{exp}\left(-\cfrac{\epsilon^2}{2\sigma^2}\right)</script><p>若将其中的$\epsilon$用$\epsilon=y-\boldsymbol{w}^T\boldsymbol{x}-b$等价替换可得：</p>
<script type="math/tex; mode=display">p(y)=\cfrac{1}{\sqrt{2\pi}\sigma} \mathrm{exp}\left(-\cfrac{(y-\boldsymbol{w}^T\boldsymbol{x}-b)^2}{2\sigma^2}\right)</script><p>上式显然可以看做$y \sim N(\boldsymbol{w}^T\boldsymbol{x}+b,\sigma^2)$的分布律，接下来便可以用最（极）大似然估计法来估计$\boldsymbol{w}$和b的值。似然函数为：</p>
<script type="math/tex; mode=display">L(\boldsymbol{w},b)=\prod_{i=1}^{m}p(y_i)=\prod_{i=1}^{m}\cfrac{1}{\sqrt{2\pi}\sigma} \mathrm{exp}\left(-\cfrac{(y_i-\boldsymbol{w}^T\boldsymbol{x_i}-b)^2}{2\sigma^2}\right)</script><p>两边同时取对数得对数似然函数：</p>
<script type="math/tex; mode=display">
\begin{aligned}     
\ln L(\boldsymbol{w},b) & = \sum_{i=1}^{m}\ln \cfrac{1}{\sqrt{2\pi}\sigma} \mathrm{exp}\left(-\cfrac{(y_i-\boldsymbol{w}^T\boldsymbol{x_i}-b)^2}{2\sigma^2}\right) \\
& = \sum_{i=1}^{m}\ln \cfrac{1}{\sqrt{2\pi}\sigma}+\sum_{i=1}^{m}\ln \mathrm{exp}\left(-\cfrac{(y_i-\boldsymbol{w}^T\boldsymbol{x_i}-b)^2}{2\sigma^2}\right) \\
& = m\ln \cfrac{1}{\sqrt{2\pi}\sigma}-\cfrac{1}{2\sigma^2}\sum_{i=1}^{m}(y_i-\boldsymbol{w}^T\boldsymbol{x_i}-b)^2
\end{aligned}</script><p>其中$m$，$\sigma$均为常数，所以最大化$\ln L(\boldsymbol{w},b)$等价于最小化$\sum_{i=1}^{m}(y_i-\boldsymbol{w}^T\boldsymbol{x_i}-b)^2$，也即：</p>
<script type="math/tex; mode=display">(\boldsymbol{w}',b')=\mathop{\arg\max}_{(\boldsymbol{w},b)} \ln L(\boldsymbol{w},b)=\mathop{\arg\min}_{(\boldsymbol{w},b)} \sum_{i=1}^{m}(y_i-\boldsymbol{w}^T\boldsymbol{x_i}-b)^2</script><p>其中$\boldsymbol{w}’$和$b’$为$\boldsymbol{w}$和$b$的解.</p>
<h3 id="最小二乘法推导："><a href="#最小二乘法推导：" class="headerlink" title="最小二乘法推导："></a>最小二乘法推导：</h3><p>最小二乘法是基于均方误差最小化来对模型进行参数估计的，用公式表示为：</p>
<script type="math/tex; mode=display">
\begin{aligned}    
    (\boldsymbol{w}',b') & = \mathop{\arg\min}_{(\boldsymbol{w},b)} \sum_{i=1}^{m}(y_i-(\boldsymbol{w}^T\boldsymbol{x_i}+b))^2 \\
    & = \mathop{\arg\min}_{(\boldsymbol{w},b)} \sum_{i=1}^{m}(y_i-\boldsymbol{w}^T\boldsymbol{x_i}-b)^2
\end{aligned}</script><p>显然与最（极）大似然估计的推导结果一致。</p>
<h3 id="参考文献："><a href="#参考文献：" class="headerlink" title="参考文献："></a>参考文献：</h3><p><span id="ref1">[1] 盛骤.《概率论与数理统计（第四版）》</span></p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;最（极）大似然估计推导：&quot;&gt;&lt;a href=&quot;#最（极）大似然估计推导：&quot; class=&quot;headerlink&quot; title=&quot;最（极）大似然估计推导：&quot;&gt;&lt;/a&gt;最（极）大似然估计推导：&lt;/h3&gt;&lt;p&gt;对于线性回归模型：&lt;/p&gt;
&lt;script type=&quot;ma
    
    </summary>
    
      <category term="机器学习" scheme="http://www.sm1les.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="线性回归" scheme="http://www.sm1les.com/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    
  </entry>
  
</feed>

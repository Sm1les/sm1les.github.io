<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Sm1les&#39;s blog</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://sm1les.com/"/>
  <updated>2019-10-22T05:12:04.141Z</updated>
  <id>http://sm1les.com/</id>
  
  <author>
    <name>Sm1les</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>条件随机场（CRF）及其三个基本问题</title>
    <link href="http://sm1les.com/2019/08/27/conditional-random-fields/"/>
    <id>http://sm1les.com/2019/08/27/conditional-random-fields/</id>
    <published>2019-08-27T11:41:56.000Z</published>
    <updated>2019-10-22T05:12:04.141Z</updated>
    
    <content type="html"><![CDATA[<h3 id="条件随机场的定义-1"><a href="#条件随机场的定义-1" class="headerlink" title="条件随机场的定义[1]"></a>条件随机场的定义<sup><a href="#ref1">[1]</a></sup></h3><p>由于最大熵马尔可夫模型（MEMM）存在<a href="/2019/07/26/maximum-entropy-markov-model">标注偏置问题</a><sup><a href="#ref2">[2]</a></sup>，为此，Lafferty J, Mccallum A和Pereira F C N三人在2001年提出了一种线性链条件随机场（Conditional Random Fields，CRF）<sup><a href="#ref2">[2]</a></sup>模型，该模型拥有MEMM的所有优点，同时还不存在标注偏置问题。条件随机场的一般定义如下：<br>设$X$与$Y$是随机变量，$P(Y|X)$是在给定$X$的条件下$Y$的条件概率分布。若随机变量$Y$构成一个由无向图$G＝(V,E)$表示的马尔可夫随机场，即</p>
<script type="math/tex; mode=display">P(Y_v|X,Y_w,w\neq v)=P(Y_v|X,Y_w,w\sim v)</script><p>对任意结点$v$成立，则称条件概率分布$P(Y|X)$为条件随机场。式中$w\sim v$表示在图$G＝(V,E)$中与结点$v$有边连接的所有结点$w$，$w\neq v$表示结点$v$以外的所有结点，$Y_v,Y_w$为结点$v,w$对应的随机变量。<br>在条件随机场的一般定义中并没有要求$X$和$Y$具有相同的图结构，但是现实中一般假设$X$和$Y$有相同的图结构，Lafferty J, Mccallum A和Pereira F C N三人提出的线性链条件随机场就作了此种假设。线性链条件随机场的定义如下：</p>
<p><center>
<img src="./crf.svg">
</center><br>设$X=(x_1,x_2,…,x_n),Y=(y_1,y_2,…,y_n)$均为线性链表示的随机变量序列，若在给定随机量序列$X$的条件下，随机变量序列$Y$的条件概率分布$P(Y|X)$构成条件随机场，即满足马尔可夫性（在$i=1$和$n$时只考虑单边）</p>
<script type="math/tex; mode=display">P(y_{i} | X, y_{1}, \cdots, y_{i-1},y_{i+1}, \cdots, y_{n})=P(y_{i} | X, y_{i-1}, y_{i+1}) \quad i=1,2,...,n</script><p>则称$P(Y|X)$为线性链条件随机场。线性链条件随机场通常用来对序列标注问题进行建模，在序列标注问题中，$X$可以看作观测序列，$Y$可以看做对应的状态序列。<br>根据线性链条件随机场的定义可知，此时由$Y$构成的马尔可夫随机场的最大团为相邻两个结点的集合，那么由Hammersley-Clifford定理可知，线性链条件随机场$P(Y|X)$的表达式可以写为如下形式</p>
<script type="math/tex; mode=display">P(Y|X)=\frac{1}{Z(X)} \exp \left(\sum_{i, k} \lambda_{k} t_{k}\left(y_{i-1}, y_{i}, X, i\right)+\sum_{i, l} \mu_{i} s_{l}\left(y_{i}, X, i\right)\right)</script><p>其中，$Z(X)=\sum\limits_{Y} \exp \left(\sum\limits_{i, k} \lambda_{k} t_{k}\left(y_{i-1}, y_{i}, X, i\right)+\sum\limits_{i, l} \mu_{l} s_{l}\left(y_{i}, X, i\right)\right)$是规范化因子，求和是在所有可能的输出序列上进行的，$t_k$是定义在边上的特征函数，称为转移特征，依赖于当前和前一个位置，$s_l$是定义在结点上的特征函数，称为状态特征，依赖于当前位置。$t_k$和$s_l$都依赖于位置，是局部特征函数。线性链条件随机场完全由特征函数$t_k,s_l$和对应的权值$\lambda_{k},\mu_{i}$确定，通常特征函数$t_k,s_l$是事先人为设定好的，而$\lambda_{k},\mu_{i}$则是通过训练数据习得。观察上式易知，线性链条件随机场为判别式模型，同时也实现了用特征对观测序列参数化，而且状态转移概率采用的是全局归一化来计算，所以线性链条件随机场拥有MEMM的所有优点，而且还不存在标注偏置问题。</p>
<h3 id="线性链条件随机场的向量化形式"><a href="#线性链条件随机场的向量化形式" class="headerlink" title="线性链条件随机场的向量化形式"></a>线性链条件随机场的向量化形式</h3><p>根据特征函数的性质可知，状态特征函数$s_l$可以看做是只提取当前位置特征的转移特征函数，也即$s_{l}\left(y_{i}, X, i\right)=s_{l}\left(y_{i-1},y_{i}, X, i\right)$。因此，$P(Y|X)$表达式中的转移特征和状态特征及其权值可以用统一的符号表示。设有$K_1$个转移特征，$K_2$个状态特征，$K=K_1+K_2$，序列长度为$n$，则$P(Y|X)$可以简写为</p>
<script type="math/tex; mode=display">\begin{aligned}
P(Y|X)&=\frac{1}{Z(X)} \exp \left(\sum_{i, k} \lambda_{k} t_{k}\left(y_{i-1}, y_{i}, X, i\right)+\sum_{i, l} \mu_{i} s_{l}\left(y_{i}, X, i\right)\right) \\
&=\frac{1}{Z(X)} \exp \left(\sum_{i}\sum_{k=1}^{K_1} \lambda_{k} t_{k}\left(y_{i-1}, y_{i}, X, i\right)+\sum_{i}\sum_{l=1}^{K_2} \mu_{i} s_{l}\left(y_{i}, X, i\right)\right) \\
&=\frac{1}{Z(X)} \exp \left(\sum_{i}\sum_{k=1}^{K_1} \lambda_{k} t_{k}\left(y_{i-1}, y_{i}, X, i\right)+\sum_{i}\sum_{l=1}^{K_2} \mu_{i} s_{l}\left(y_{i-1},y_{i}, X, i\right)\right) \\
&=\frac{1}{Z(X)} \exp \left(\sum_{i}\sum_{k=1}^{K_1+K_2} w_{k} f_{k}\left(y_{i-1}, y_{i}, X, i\right)\right) \\
&=\frac{1}{Z(X)} \exp \left(\sum_{i}\sum_{k=1}^{K} w_{k} f_{k}\left(y_{i-1}, y_{i}, X, i\right)\right) \\
\end{aligned}</script><p>若令</p>
<script type="math/tex; mode=display">f_k(Y,X)=\sum_{i} f_{k}\left(y_{i-1}, y_{i}, X, i\right) \quad k=1,2,...,K</script><script type="math/tex; mode=display">F(Y,X)=\left(f_1(Y,X),f_2(Y,X),...,f_K(Y,X)\right)\in \mathbb{R}^{K\times1}</script><script type="math/tex; mode=display">\boldsymbol w=\left(w_1,w_2,...,w_k\right)\in \mathbb{R}^{K\times1}</script><p>那么$P(Y|X)$可以进一步简写为如下向量化形式</p>
<script type="math/tex; mode=display">\begin{aligned}
P(Y|X)&=\frac{1}{Z(X)} \exp \left(\sum_{i}\sum_{k=1}^{K} w_{k} f_{k}\left(y_{i-1}, y_{i}, X, i\right)\right) \\
&=\frac{1}{Z(X)} \exp \left(\sum_{k=1}^{K} w_{k} \sum_{i}f_{k}\left(y_{i-1}, y_{i}, X, i\right)\right) \\
&=\cfrac{\exp \left(\boldsymbol w^TF(Y,X)\right)}{Z(X)}  \\
\end{aligned}</script><p>其中$Z(X)=\sum\limits_{Y} \exp \left(\boldsymbol w^TF(Y,X)\right)$</p>
<h3 id="线性链条件随机场的三个基本问题"><a href="#线性链条件随机场的三个基本问题" class="headerlink" title="线性链条件随机场的三个基本问题"></a>线性链条件随机场的三个基本问题</h3><ol>
<li>概率计算问题：在给定模型参数$w_k(k=1,2,…,K)$、观测序列$X=(x_1,x_2,…,x_n)$和状态序列$Y=(y_1,y_2,…,y_n)$的条件下，计算条件概率$P(Y|X),P(y_i|X),P(y_{i-1},y_i|X)$以及一些数学期望；</li>
<li>学习问题：在给定观测序列$X=(x_1,x_2,…,x_n)$和状态序列$Y=(y_1,y_2,…,y_n)$的条件下，估计模型参数$w_k(k=1,2,…,K)$，使得条件概率$P(Y|X)$达到最大；</li>
<li>预测问题：也称为解码问题，已知模型参数$w_k(k=1,2,…,K)$和观测序列$X=(x_1,x_2,…,x_n)$，求条件概率$P(Y|X)$达到最大的状态序列$Y=(y_1,y_2,…,y_n)$，即给定观测序列，求最有可能的对应状态序列。</li>
</ol>
<h3 id="概率计算问题"><a href="#概率计算问题" class="headerlink" title="概率计算问题"></a>概率计算问题</h3><h4 id="计算条件概率-P-Y-X"><a href="#计算条件概率-P-Y-X" class="headerlink" title="计算条件概率$P(Y|X)$"></a>计算条件概率$P(Y|X)$</h4><p>由$P(Y|X)$的表达式可知，要想计算出条件概率$P(Y|X)$则需要计算出给定状态序列$Y$的非规范化概率$\exp \left(\boldsymbol w^TF(Y,X)\right)$和规范化因子$Z(X)$，由于在已知观测序列$X$和模型参数$w_k(k=1,2,…,K)$的条件下，只要知道状态的取值范围，无论对应状态序列$Y$是否已知，均能求出规范化因子$Z(X)$，所以下面考虑对$\exp \left(\boldsymbol w^TF(Y,X)\right)$和$Z(X)$分别进行求解。首先考虑求解$Z(X)$：<br>设状态的取值范围为$Q=\{q_1,q_2,…,q_m\}$，将所有状态序列前后都各填充一个$y_0=start$和$y_{n+1}=stop$，由于对观测序列$X$的每一个位置$i=1,2,…,n+1$来说，$y_{i-1}$和$y_i$都有$m$种可能的取值，因此，对于每一个位置来说都可以定义一个$m\times m$的矩阵</p>
<script type="math/tex; mode=display">\mathbf{M}_i(X)=[M_i(y_{i-1},y_i|X)]=\left[ \begin{array}{cc}
     M_1(q_1,q_1|X) & M_1(q_1,q_2|X) & ... & M_1(q_1,q_m|X) \\
     M_1(q_2,q_1|X) & M_1(q_2,q_2|X) & ... & M_1(q_2,q_m|X) \\  
     \vdots & \vdots & \ddots & \vdots \\
     M_1(q_m,q_1|X) & M_1(q_m,q_2|X) & ... & M_1(q_m,q_m|X) \\  
\end{array} \right]</script><p>其中$M_i(y_{i-1},y_i|X)=\exp\left(\sum\limits_{k=1}^{K} w_{k}f_{k}\left(y_{i-1}, y_{i}, X, i\right)\right)$。特别地，对于起始位置$i=1$和结束位置$i=n+1$的矩阵定义为</p>
<script type="math/tex; mode=display">\mathbf{M}_1(X)=[M_1(y_{0},y_1|X)]=\left[ \begin{array}{cc}
     M_1(start,q_1|X) & M_1(start,q_2|X) & ... & M_1(start,q_m|X) \\
     0 & 0 & ... & 0 \\  
     \vdots & \vdots & \ddots & \vdots \\
     0 & 0 & ... & 0 \\  
\end{array} \right]</script><script type="math/tex; mode=display">\mathbf{M}_{n+1}(X)=[M_{n+1}(y_{n},y_{n+1}|X)]=\left[ \begin{array}{cc}
     M_{n+1}(q_1,stop|X)=1 & 0 & ... & 0 \\
     M_{n+1}(q_2,stop|X)=1 & 0 & ... & 0 \\  
     \vdots & \vdots & \ddots & \vdots \\
     M_{n+1}(q_m,stop|X)=1 & 0 & ... & 0 \\  
\end{array} \right]</script><p>此时，$Z(X)$即为$\mathbf{M}_i(X)(i=1,2,…,n+1)$这$n+1$个矩阵的乘积的第1行第1列元素（具体例子参见<a href="#ref1">[1]</a>中例11.2），即</p>
<script type="math/tex; mode=display">Z(X)=\left[\prod_{i=1}^{n+1}\mathbf{M}_i(X)\right]_{(1,1)}</script><p>对于$\exp \left(\boldsymbol w^TF(Y,X)\right)$，在对应状态序列$Y$也已知的条件下，则可以通过$\mathbf{M}_i(X)(i=1,2,…,n+1)$这$n+1$个矩阵的适当元素的乘积来表示，即</p>
<script type="math/tex; mode=display">\begin{aligned}
\exp \left(\boldsymbol w^TF(Y,X)\right)&=\exp \left(\sum_{k=1}^{K} w_{k} \sum_{i=1}^{n+1}f_{k}\left(y_{i-1}, y_{i}, X, i\right)\right) \\
&=\exp \left(\sum_{i=1}^{n+1}\sum_{k=1}^{K} w_{k} f_{k}\left(y_{i-1}, y_{i}, X, i\right)\right) \\
&=\prod_{i=1}^{n+1}\exp \left(\sum_{k=1}^{K} w_{k} f_{k}\left(y_{i-1}, y_{i}, X, i\right)\right) \\
&=\prod_{i=1}^{n+1}M_i(y_{i-1},y_i|X)\\
\end{aligned}</script><h4 id="计算条件概率-P-y-i-X-P-y-i-1-y-i-X"><a href="#计算条件概率-P-y-i-X-P-y-i-1-y-i-X" class="headerlink" title="计算条件概率$P(y_i|X),P(y_{i-1},y_i|X)$"></a>计算条件概率$P(y_i|X),P(y_{i-1},y_i|X)$</h4><p>对每个位置$i=1,2,…,n+1$定义前向向量$\boldsymbol{\alpha}_i(X)\in\mathbb{R}^{m\times 1}$：</p>
<script type="math/tex; mode=display">\boldsymbol{\alpha}_0(X)=\left[ \begin{array}{cc}
     1 \\
     0 \\  
     \vdots \\
     0 \\  
\end{array} \right],
\boldsymbol{\alpha}_i(X)=\left[ \begin{array}{cc}
     \alpha_i(y_i=q_1|X) \\
     \alpha_i(y_i=q_2|X) \\  
     \vdots \\
     \alpha_i(y_i=q_m|X) \\  
\end{array} \right]</script><p>其中，$\alpha_i(y_i=q_j|X)(j=1,2,..,m)$表示在位置$i$的状态是$q_j$并且从1到$i$的状态序列的非规范化概率。根据前向向量的定义易得递推公式</p>
<script type="math/tex; mode=display">\boldsymbol{\alpha}_i(X)^T=\boldsymbol{\alpha}_{i-1}(X)^T[M_i(y_{i-1},y_i|X)]=\boldsymbol{\alpha}_{i-1}(X)^T\mathbf{M}_i(X)</script><p>同理，对每个位置$i=0,1,2,…,n$定义后向向量$\boldsymbol{\beta}_i(X)\in\mathbb{R}^{m\times 1}$：</p>
<script type="math/tex; mode=display">\boldsymbol{\beta}_i(X)=\left[ \begin{array}{cc}
     \beta_i(y_i=q_1|X) \\
     \beta_i(y_i=q_2|X) \\  
     \vdots \\
     \beta_i(y_i=q_m|X) \\  
\end{array} \right],
\boldsymbol{\beta}_{n+1}(X)=\left[ \begin{array}{cc}
     1 \\
     0 \\  
     \vdots \\
     0 \\  
\end{array} \right]</script><p>其中，$\beta_i(y_i=q_j|X)(j=1,2,..,m)$表示在位置$i$的状态是$q_j$并且从$i+1$到最后的状态序列的非规范化概率。根据后向向量的定义易得递推公式</p>
<script type="math/tex; mode=display">\boldsymbol{\beta}_i(X)=[M_{i+1}(y_i,y_{i+1}|X)]\boldsymbol{\beta}_{i-1}(X)=\mathbf{M}_i(X)\boldsymbol{\beta}_{i-1}(X)</script><p>定义完前向向量和后向向量，接下来便可以很容易地计算出在位置$i$的状态是$q_j$的条件概率和在位置$i-1$是状态$q_j$在位置$i$是状态$q_k$的条件概率：</p>
<script type="math/tex; mode=display">\begin{aligned}
P(y_i|X)&=P(y_i=q_j|X)\\
&=\cfrac{\alpha_i(y_i=q_j|X)\beta_i(y_i=q_j|X)}{Z(X)}
\end{aligned}</script><script type="math/tex; mode=display">\begin{aligned}
P(y_{i-1},y_{i}|X)&=P(y_{i-1}=q_j,y_{i}=q_k|X)\\
&=\cfrac{\alpha_{i-1}(y_{i-1}=q_j|X)M_{i}(q_j,q_k|X)\beta_i(y_i=q_k|X)}{Z(X)}
\end{aligned}</script><p>其中</p>
<script type="math/tex; mode=display">Z(X)=\boldsymbol{\alpha}_n(X)^T\boldsymbol I=\boldsymbol{\alpha}_{n+1}(X)^T\boldsymbol I=\boldsymbol I^T\boldsymbol{\beta}_0(X) \quad \boldsymbol I=(1,...,1)\in\mathbb{R}^{m\times 1}</script><h4 id="计算期望值"><a href="#计算期望值" class="headerlink" title="计算期望值"></a>计算期望值</h4><p>利用前向向量和后向向量，可以计算特征函数关于联合分布$P(X,Y)$和条件分布$P(Y|X)$的数学期望。特征函数$f_k(Y,X)=\sum_{i=1}^n f_{k}\left(y_{i-1}, y_{i}, X, i\right)$关于条件分布$P(Y|X)$的数学期望是</p>
<script type="math/tex; mode=display">\begin{aligned}
E_{P(Y|X)}[f_k(Y,X)]&=\sum_Y \left[P(Y|X)f_k(Y,X)\right] \\
&=\sum_Y \left[P(Y|X)\sum_{i=1}^{n+1} f_{k}\left(y_{i-1}, y_{i}, X, i\right)\right] \\
&=\sum_Y \left[P(Y|X)f_{k}\left(y_{0}, y_{1}, X, i\right)+...+P(Y|X)f_{k}\left(y_{n}, y_{n+1}, X, i\right)\right] \\
&=\sum_Y P(Y|X)f_{k}\left(y_{0}, y_{1}, X, i\right)+...+\sum_Y P(Y|X)f_{k}\left(y_{n}, y_{n+1}, X, i\right) \\
&=\sum_{y_2,...,y_{n+1}}\sum_{y_0,y_1} P(Y|X)f_{k}\left(y_{0}, y_{1}, X, i\right)+...+\sum_{y_0,...,y_{n-1}}\sum_{y_n,y_{n+1}} P(Y|X)f_{k}\left(y_{n}, y_{n+1}, X, i\right) \\
&=\sum_{y_0,y_1}f_{k}\left(y_{0}, y_{1}, X, i\right)\sum_{y_2,...,y_{n+1}} P(Y|X)+...+\sum_{y_n,y_{n+1}}f_{k}\left(y_{n}, y_{n+1}, X, i\right)\sum_{y_0,...,y_{n-1}}P(Y|X) \\
&=\sum_{y_0,y_1}f_{k}\left(y_{0}, y_{1}, X, i\right)P\left(y_{0},y_{1}|X\right)+...+\sum_{y_n,y_{n+1}}f_{k}\left(y_{n}, y_{n+1}, X, i\right)P\left(y_{n},y_{n+1}|X\right) \\
&=\sum_{i=1}^{n+1}\sum_{j=1,k=1}^m \left[f_{k}\left(y_{i-1}=q_j, y_{i}=q_k, X, i\right)P\left(y_{i-1}=q_j,y_{i}=q_k|X\right) \right] \\
&=\sum_{i=1}^{n+1}\sum_{j=1,k=1}^m \left[f_{k}\left(y_{i-1}=q_j, y_{i}=q_k, X, i\right)\cfrac{\alpha_{i-1}(y_{i-1}=q_j|X)M_{i}(q_j,q_k|X)\beta_i(y_i=q_k|X)}{Z(X)} \right] \\
\end{aligned}</script><p>其中</p>
<script type="math/tex; mode=display">Z(X)=\boldsymbol{\alpha}_n(X)^T\boldsymbol I=\boldsymbol{\alpha}_{n+1}(X)^T\boldsymbol I=\boldsymbol I^T\boldsymbol{\beta}_0(X) \quad \boldsymbol I=(1,...,1)\in\mathbb{R}^{m\times 1}</script><p>假设经验分布为$\tilde{P}(X)$，则特征函数$f_k(Y,X)=\sum_{i=1}^n f_{k}\left(y_{i-1}, y_{i}, X, i\right)$关于联合分布$P(X,Y)$的数学期望是</p>
<script type="math/tex; mode=display">\begin{aligned}
E_{P(X,Y)}[f_k(Y,X)]&=\sum_{X,Y} \left[P(X,Y)f_k(Y,X)\right] \\
&=\sum_{X,Y} \left[\tilde{P}(X)P(Y|X)f_k(Y,X)\right] \\
&=\sum_{X}\tilde{P}(X)\sum_{Y} \left[P(Y|X)f_k(Y,X)\right] \\
&=\sum_{X}\tilde{P}(X)E_{P(Y|X)}[f_k(Y,X)] \\
\end{aligned}</script><p>综上，对于在给定模型参数$w_k(k=1,2,…,K)$、观测序列$X=(x_1,x_2,…,x_n)$和状态序列$Y=(y_1,y_2,…,y_n)$的条件下，只需前向扫描计算和后向扫描计算一次$\boldsymbol{\alpha}_i(X)$和$\boldsymbol{\alpha}_i(X)$，规范化因子$Z(X)$和条件概率$P(y_i|X),P(y_{i-1},y_i|X)$以及一些数学期望都可以被计算出来。</p>
<h3 id="学习问题"><a href="#学习问题" class="headerlink" title="学习问题"></a>学习问题</h3><p>在给定观测序列$X=(x_1,x_2,…,x_n)$和对应状态序列$Y=(y_1,y_2,…,y_n)$的条件下，可以通过极大似然估计法来估计模型的参数。由于线性链条件随机场类似于最大熵模型，所以用于求解最大熵模型参数的GIS、IIS、梯度下降、牛顿法和拟牛顿法均可用于线性链条件随机场。</p>
<h3 id="预测问题"><a href="#预测问题" class="headerlink" title="预测问题"></a>预测问题</h3><p>线性链条件随机场的预测问题是在给定模型参数$w_k(k=1,2,…,K)$、观测序列$X=(x_1,x_2,…,x_n)$的条件下，求条件概率最大的状态序列$Y^*=(y_1^*,y_2^*,…,y_n^*)$，即对观测序列进行标注。线性链条件随机场解决预测问题所采用的算法和HMM和MEMM一样，采用的都是经典的维特比（Viterbi）算法。具体算法如下：</p>
<script type="math/tex; mode=display">\begin{aligned}
Y^*&=\underset{Y}{\arg \max }P(Y|X)\\
&=\underset{Y}{\arg \max }\cfrac{\exp \left(\boldsymbol w^TF(Y,X)\right)}{Z(X)} \\
&=\underset{Y}{\arg \max }\exp \left(\boldsymbol w^TF(Y,X)\right) \\
&=\underset{Y}{\arg \max }\left(\boldsymbol w^TF(Y,X)\right) \\
\end{aligned}</script><p>于是，线性链条件随机场的预测问题转化为了求非规范化概率最大的最优路径问题，其中路径表示的是状态序列。为了求解最优路径，将上式作如下恒等变形</p>
<script type="math/tex; mode=display">\begin{aligned}
Y^*&=\underset{Y}{\arg \max }\left(\boldsymbol w^TF(Y,X)\right) \\
&=\underset{Y}{\arg \max }\left(\sum_{k=1}^{K} w_{k} \sum_{i}f_{k}\left(y_{i-1}, y_{i}, X, i\right)\right) \\
&=\underset{Y}{\arg \max }\left(\sum_{i}\sum_{k=1}^{K} w_{k} f_{k}\left(y_{i-1}, y_{i}, X, i\right)\right) \\
&=\underset{Y}{\arg \max }\left(\sum_{i}\boldsymbol w^TF_i(y_{i-1},y_i,X)\right) \\
\end{aligned}</script><p>其中</p>
<script type="math/tex; mode=display">F_i(y_{i-1},y_i,X)=\left(f_1(y_{i-1},y_i,X,i),f_2(y_{i-1},y_i,X,i),..,f_K(y_{i-1},y_i,X,i)\right)\in \mathbb{R}^{K\times1}</script><p>首先求出位置1的各个标记$y_1=q_1,q_2,…,q_m$的非规范化概率</p>
<script type="math/tex; mode=display">\delta_1(j)=\boldsymbol w^TF_1(y_{0}=start,y_1=q_j,X)\quad j=1,2,...,m</script><p>接着由递推公式，求出到位置$i$的各个标记$l=1,2,…,m$的非规范化概率的最大值，同时记录非规范化概率最大值的路径</p>
<script type="math/tex; mode=display">\delta_i(l)=\underset{1\leq j\leq m}{\max }\{\delta_{i-1}(j)+\boldsymbol w^TF_i(y_{i-1}=q_j,y_i=q_l,X)\}\quad l=1,2,...,m</script><script type="math/tex; mode=display">\psi_i(l)=\underset{1\leq j\leq m}{\arg\max }\{\delta_{i-1}(j)+\boldsymbol w^TF_i(y_{i-1}=q_j,y_i=q_l,X)\}\quad l=1,2,...,m</script><p>直到$i=n$时终止。这时求得的非规范化概率的最大值为</p>
<script type="math/tex; mode=display">\underset{Y}{\max }\left(\boldsymbol w^TF(Y,X)\right)=\underset{1\leq j\leq m}{\max }\delta_{n}(j)</script><p>最优路径的终点为</p>
<script type="math/tex; mode=display">y_n^*=\underset{1\leq j\leq m}{\arg\max }\delta_{n}(j)</script><p>接着由最优路径的终点往回回溯</p>
<script type="math/tex; mode=display">y_i^*=\psi_{i+1}(y_{i+1}^*) \quad i=n-1,n-2,...,1</script><p>最终即可求得最优路径$Y^*=(y_1^*,y_2^*,…,y_n^*)$（具体例子参见<a href="#ref1">[1]</a>中例11.3）。</p>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p><span id="ref1">[1] 李航.《统计学习方法》</span><br><span id="ref2">[2] Lafferty J, Mccallum A, Pereira F C N. Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data[J]. Proceedings of Icml, 2001.</span></p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;条件随机场的定义-1&quot;&gt;&lt;a href=&quot;#条件随机场的定义-1&quot; class=&quot;headerlink&quot; title=&quot;条件随机场的定义[1]&quot;&gt;&lt;/a&gt;条件随机场的定义&lt;sup&gt;&lt;a href=&quot;#ref1&quot;&gt;[1]&lt;/a&gt;&lt;/sup&gt;&lt;/h3&gt;&lt;p&gt;由于最大熵
    
    </summary>
    
      <category term="机器学习" scheme="http://sm1les.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="条件随机场" scheme="http://sm1les.com/tags/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/"/>
    
      <category term="CRF" scheme="http://sm1les.com/tags/CRF/"/>
    
  </entry>
  
  <entry>
    <title>最大熵马尔可夫模型（MEMM）及其三个基本问题</title>
    <link href="http://sm1les.com/2019/07/26/maximum-entropy-markov-model/"/>
    <id>http://sm1les.com/2019/07/26/maximum-entropy-markov-model/</id>
    <published>2019-07-26T13:42:34.000Z</published>
    <updated>2019-10-21T15:20:37.313Z</updated>
    
    <content type="html"><![CDATA[<h3 id="最大熵马尔可夫模型的定义"><a href="#最大熵马尔可夫模型的定义" class="headerlink" title="最大熵马尔可夫模型的定义"></a>最大熵马尔可夫模型的定义</h3><p>最大熵马尔可夫模型（Maximum-entropy Markov model，MEMM）由Andrew McCallum，Dayne Freitag和Fernando Pereira三人于2000年提出<sup><a href="#ref1">[1]</a></sup>。它结合了隐马尔可夫模型（HMM）和最大熵模型（MEM），被广泛应用于处理序列标注问题。文献<a href="#ref1">[1]</a>认为在HMM中主要存在以下两个问题：</p>
<ul>
<li>无法用特征对观测序列参数化：在很多序列标注任务中，尤其当不能枚举所有观测序列时，通常需要用大量的特征来刻画观测序列。比如在文本中识别一个未见过的公司名字时，通常需要用到很多特征信息，如大写字母、结尾词、词性、格式、在文本中的位置等；</li>
<li>判别式模型比生成式模型更适合处理序列标注问题：HMM多被用在处理序列标注问题，序列标注问题的目标是求出状态相对于观测的条件概率$P(state|observation)$，而HMM是对状态和观测的联合概率$P(state,observation)$进行建模的生成式模型，相对于直接对$P(state|observation)$进行建模的判别式模型来说，显然判别式模型更适合处理序列标注问题。</li>
</ul>
<p>为了解决以上两个问题，MEMM在HMM的基础上做了如下改进：</p>
<ul>
<li>采用判别式模型：不对状态和观测的联合概率$P(state,observation)$进行建模，而是直接对状态相对于观测的条件概率$P(state|observation)$进行建模；</li>
<li>采用最大熵模型进行建模：对当前时刻的状态取值的概率用最大熵模型进行建模，因此能够实现用特征对观测序列参数化；</li>
</ul>
<p>MEMM的具体定义如下：</p>
<p><center>
<img src="./memm.svg">
</center><br>设$V$是所有可能的观测的集合，$Q$是所有可能的状态的集合：</p>
<script type="math/tex; mode=display">V=\{v_1,v_2,...,v_M\},Q=\{q_1,q_2,...,q_N\}</script><p>其中，$N$是可能的状态数，$M$是可能的观测数。<br>$O$是长度为$T$的观测序列，$I$是对应的状态序列：</p>
<script type="math/tex; mode=display">O=(o_1,o_2,...,o_T),I=(i_1,i_2,...,i_T)</script><p>在已知观测序列$O$的条件下，状态序列为$I$的概率为</p>
<script type="math/tex; mode=display">\begin{aligned}
P(I|O)&=P(i_1,i_2,...,i_T|O)\\
&=P(i_1|O)\prod_{t=2}^TP(i_t|i_{t-1},O)\\
&=P(i_1|O)\prod_{t=2}^T\cfrac{\exp\left(\sum_{k=1}^K w_kf_k(i_t,i_{t-1},O)\right)}{\sum\limits_{i_t}\exp\left(\sum_{k=1}^K w_kf_k(i_t,i_{t-1},O)\right)}\\
&=P(i_1|O)\prod_{t=2}^T\cfrac{1}{Z(i_{t-1},O)}\exp\left(\sum_{k=1}^K w_kf_k(i_t,i_{t-1},O)\right)\\
\end{aligned}</script><p>其中，$Z(i_{t-1},O)=\sum\limits_{i_t}\exp\left(\sum_{k=1}^K w_kf_k(i_t,i_{t-1},O)\right),f_k(i_t,i_{t-1},O),w_k$分别对应于最大熵模型中的归一化因子，特征函数和特征函数的权重。若在$i_1$前添加一个恒为常量0的状态$i_0=0$，则上式可化简为</p>
<script type="math/tex; mode=display">\begin{aligned}
P(I|O)&=P(i_0=0,i_1,i_2,...,i_T|O)\\
&=\prod_{t=1}^TP(i_t|i_{t-1},O)\\
&=\prod_{t=1}^T\cfrac{1}{Z(i_{t-1},O)}\exp\left(\sum_{k=1}^K w_kf_k(i_t,i_{t-1},O)\right)\\
\end{aligned}</script><h3 id="最大熵马尔可夫模型的三个基本问题"><a href="#最大熵马尔可夫模型的三个基本问题" class="headerlink" title="最大熵马尔可夫模型的三个基本问题"></a>最大熵马尔可夫模型的三个基本问题</h3><ol>
<li>概率计算问题：在给定模型参数$w_k(k=1,2,…,K)$、观测序列$O=(o_1,o_2,…,o_T)$和状态序列$I=(i_1,i_2,…,i_T)$的条件下，计算条件概率$P(I|O)$；</li>
<li>学习问题：在给定观测序列$O=(o_1,o_2,…,o_T)$和状态序列$I=(i_1,i_2,…,i_T)$的条件下，估计模型参数$w_k(k=1,2,…,K)$，使得条件概率$P(I|O)$达到最大；</li>
<li>预测问题：也称为解码问题，已知模型参数$w_k(k=1,2,…,K)$和观测序列$O=(o_1,o_2,…,o_T)$，求条件概率$P(I\vert O)$达到最大的状态序列$I=(i_1,i_2,…,i_T)$，即给定观测序列，求最有可能的对应状态序列。</li>
</ol>
<h3 id="概率计算问题"><a href="#概率计算问题" class="headerlink" title="概率计算问题"></a>概率计算问题</h3><p>由于MEMM属于判别式模型，而对于判别式模型来说，给定了模型参数$w_k(k=1,2,…,K)$和观测序列$O=(o_1,o_2,…,o_T)$，直接套用模型的定义即可计算出条件概率$P(I|O)$。</p>
<h3 id="学习问题"><a href="#学习问题" class="headerlink" title="学习问题"></a>学习问题</h3><ul>
<li>既有观测序列$O=(o_1,o_2,…,o_T)$也有状态序列$I=(i_1,i_2,…,i_T)$时：此时MEMM类似于最大熵模型，所以能用于估计最大熵模型参数的策略和算法均可用于MEMM；</li>
<li>只有观测序列$O=(o_1,o_2,…,o_T)$而没有状态序列$I=(i_1,i_2,…,i_T)$时：此时MEMM是一个含有隐变量的模型，对于含有隐变量的模型，则可以使用EM算法对其进行参数估计。</li>
</ul>
<h3 id="预测问题"><a href="#预测问题" class="headerlink" title="预测问题"></a>预测问题</h3><p>HMM中用于解决预测问题的维特比（Viterbi）算法在MEMM中同样适用，具体算法如下：<br>定义在时刻$t$状态为$q_i$的所有单个路径$(i_1,i_2,…,i_t)$中概率最大值为</p>
<script type="math/tex; mode=display">\delta_t(i)=\max\limits_{i_1,i_2,..,i_{t-1}}P(i_1,...,i_{t-1},i_t=q_i|O),\quad i=1,2,...,N</script><p>由此定义可推得</p>
<script type="math/tex; mode=display">\begin{aligned}
\delta_1(i)&=P(i_1=q_i|i_0=0,O) \\
\delta_2(i)&=\max\limits_{1\leq j\leq N}[\delta_1(j)\cdot P(i_2=q_i|i_1=q_j,O)] \\
\delta_3(i)&=\max\limits_{1\leq j\leq N}[\delta_2(j)\cdot P(i_3=q_i|i_2=q_j,O)] \\
\end{aligned}</script><p>依次此类推可得如下递推公式</p>
<script type="math/tex; mode=display">\delta_{t}(i)=\max\limits_{1\leq j\leq N}[\delta_{t-1}(j)\cdot P(i_t=q_i|i_{t-1}=q_j,O)]</script><p>同样再定义在时刻$t$状态为$q_i$的所有单个路径$(i_1,i_2,…,i_t)$中概率最大的路径的第$t-1$个结点为</p>
<script type="math/tex; mode=display">\psi_t(i)=\arg\max\limits_{1\leq j\leq N}[\delta_{t-1}(j)\cdot P(i_t=q_i|i_{t-1}=q_j,O)]</script><p>因此，取$i_T^*=\arg\max\limits_{i}[\delta_T(i)]$，则$i_{T-1}^*=\psi_T(i_T^*),i_{T-2}^*=\psi_{T-1}(i_{T-1}^*),…,i_1^*=\psi_2(i_2^*)$。由于MEMM模型本身的问题，用维特比算法求出来的最优序列$I^*=(i_1^*,i_2^*,…,i_T^*)$<strong>并不是真正意义上的最优状态序列</strong>，下面举例说明：<br>假设已知的观测序列为$O=(o_1,o_2,o_3,o_4)$，所有可能的状态的集合为$Q=\{1,2,3,4,5\}$，各个时刻之间的状态转移概率如下图所示</p>
<p><center>
<img src="./labelbias.svg">
</center><br>由维特比算法易算得最优状态序列$I^*=(1,1,1,1)$，但是结合解码问题的实际情形可知，显然状态序列$\tilde{I}=(1,2,2,2)$相对来说比$I^*$更加合理，因为$\tilde{I}$每个时刻之间的状态转移都比$I^*$更加<strong>自信</strong>，例如从时刻1到时刻2，$I^*$是选择转移到自己最不自信的下一个状态（0.4 &lt; 0.6），而$\tilde{I}$则是选择转移到自己最自信的那个状态（0.6 &gt; 0.4），同理可知，在时刻2到时刻3和时刻3到时刻4时都是同样的情形。因此，$I^*$一定不是真正意义上的最优状态序列，此即为MEMM的<strong>标注偏置问题（The Label Bias Problem）</strong><sup><a href="#ref2">[2]</a></sup>。导致标注偏置的主要原因是MEMM对各个时刻的状态取值的概率$P(i_t|i_{t-1},o_t)$进行了局部归一化，也即</p>
<script type="math/tex; mode=display">\begin{aligned}
\sum_{i_t}P(i_t|i_{t-1},O)&=\sum_{i_t}\cfrac{1}{Z(i_{t-1},O)}\exp\left(\sum_{k=1}^K w_kf_k(i_t,i_{t-1},O)\right) \\
&=\sum_{i_t}\cfrac{1}{\sum\limits_{i_t}\exp\left(\sum_{k=1}^K w_kf_k(i_t,i_{t-1},O)\right)}\exp\left(\sum_{k=1}^K w_kf_k(i_t,i_{t-1},O)\right) \\
&=1
\end{aligned}</script><p>所以对于那些可转移状态少的状态来说，它转移到下一个状态的概率通常都会比那些可转移状态多的状态转到下一个状态的概率要高。比如上图中的状态1可以转移到状态1/2，状态2可以转移到状态1/2/3/4/5，那么状态1可转移的状态就比状态2可转移的状态要少，所以从状态1转移到状态1/2的单个概率通常都会比从状态2转移到状态1/2/3/4/5的单个概率要高。显然这是不符合实际情形的，因为我们并不要求每个状态的可转移状态个数相等，所以对于每个状态来说，只要它们是以同等自信程度转移到下一个状态，那么它们的转移概率就应该相等。比如上图中的时刻3到时刻4时，状态1转移到状态1/2的自信程度相等（0.5=0.5），同样状态2转移到状态1/2/3/4/5的自信程度也相等（0.2=0.2=0.2=0.2=0.2），那么它们的转移概率理应都是相等的，显然进行局部归一化后它们的转移概率是不相等的，所以只需取消局部归一化或者换成全局归一化即可解决标注偏置问题。</p>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p><span id="ref1">[1] Mccallum A, Freitag D, Pereira F. Maximum Entropy Markov Models for Information Extraction and Segmentation[J]. Icml, 2000.</span><br><span id="ref2">[2] Lafferty J, Mccallum A, Pereira F C N. Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data[J]. Proceedings of Icml, 2001.</span></p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;最大熵马尔可夫模型的定义&quot;&gt;&lt;a href=&quot;#最大熵马尔可夫模型的定义&quot; class=&quot;headerlink&quot; title=&quot;最大熵马尔可夫模型的定义&quot;&gt;&lt;/a&gt;最大熵马尔可夫模型的定义&lt;/h3&gt;&lt;p&gt;最大熵马尔可夫模型（Maximum-entropy Mark
    
    </summary>
    
      <category term="机器学习" scheme="http://sm1les.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="最大熵马尔可夫模型" scheme="http://sm1les.com/tags/%E6%9C%80%E5%A4%A7%E7%86%B5%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B/"/>
    
      <category term="MEMM" scheme="http://sm1les.com/tags/MEMM/"/>
    
  </entry>
  
  <entry>
    <title>隐马尔可夫模型（HMM）及其三个基本问题</title>
    <link href="http://sm1les.com/2019/04/10/hidden-markov-model/"/>
    <id>http://sm1les.com/2019/04/10/hidden-markov-model/</id>
    <published>2019-04-10T12:03:50.000Z</published>
    <updated>2019-09-03T11:35:48.343Z</updated>
    
    <content type="html"><![CDATA[<h3 id="隐马尔可夫模型的定义-1"><a href="#隐马尔可夫模型的定义-1" class="headerlink" title="隐马尔可夫模型的定义[1]"></a>隐马尔可夫模型的定义<sup><a href="#ref1">[1]</a></sup></h3><p>隐马尔可夫模型（Hidden Markov Model，HMM）是关于时序的概率模型，描述由一个隐藏的马尔可夫链随机生成不可观测的状态随机序列，再由各个状态生成一个观测而产生观测随机序列的过程。隐藏的马尔可夫链随机生成的状态的序列，称为<strong>状态序列</strong>；每个状态生成一个观测，而由此产生的观测的随机序列，称为<strong>观测序列</strong>，序列的每一个位置又可以看作是一个时刻。其形式定义如下：</p>
<p><center>
<img src="./hmm.svg">
</center><br>$Q$是所有可能的状态的集合，$V$是所有可能的观测的集合：</p>
<script type="math/tex; mode=display">Q=\{q_1,q_2,...,q_N\},V=\{v_1,v_2,...,v_M\}</script><p>其中，$N$是可能的状态数，$M$是可能的观测数。<br>$I$是长度为$T$的状态序列，$O$是对应的观测序列：</p>
<script type="math/tex; mode=display">I=(i_1,i_2,...,i_T),O=(o_1,o_2,...,o_T)</script><p>$A$是<strong>状态转移概率矩阵</strong>：</p>
<script type="math/tex; mode=display">A=[a_{ij}]_{N\times N}</script><p>其中，$a_{ij}=P(i_{t+1}=q_j\vert i_t=q_i),\quad i=1,2,…,N;j=1,2,…,N$，表示在时刻$t$处于状态$q_i$的条件下在时刻$t+1$转移到状态$q_j$的概率。<br>$B$是<strong>观测概率矩阵</strong>：</p>
<script type="math/tex; mode=display">B=[b_{jk}]_{N\times M}</script><p>其中，$b_{jk}=P(o_t=v_k\vert i_t=q_j),\quad j=1,2,…N;k=1,2,…,M$，表示在时刻$t$处于状态$q_j$的条件下生成观测$v_k$的概率。<br>$\pi$是<strong>初始状态概率向量</strong>：</p>
<script type="math/tex; mode=display">\pi=(\pi_1,\pi_2,...,\pi_N)</script><p>其中，$\pi_i=P(i_1=q_i),\quad i=1,2,…,N$，表示时刻$t=1$时处于状态$q_i$的概率。<br>隐马尔可夫模型由初始状态概率向量$\pi$、状态转移概率矩阵$A$和观测概率矩阵$B$决定。$\pi$和$A$决定状态序列，$B$决定观测序列。因此，隐马尔可夫模型$\lambda$可以用三元符号表示，即：</p>
<script type="math/tex; mode=display">\lambda=(A,B,\pi)</script><p>$A,B,\pi$称为隐马尔可夫模型的<strong>三要素</strong>。<br>从定义可知，隐马尔可夫模型作了<strong>两个基本假设</strong>：</p>
<ol>
<li>齐次马尔可夫性假设，即假设隐藏的马尔可夫链在任意时刻$t$的状态只依赖于其前一时刻的状态，与其他时刻的状态及观测无关，也与时刻$t$无关：<script type="math/tex; mode=display">P(i_t\vert i_{t-1},o_{t-1},...,i_1,o_1)=P(i_t\vert i_{t-1})</script></li>
<li>观测独立性假设，即假设任意时刻的观测只依赖于该时刻的马尔可夫链的状态，与其他观测及状态无关：<script type="math/tex; mode=display">P(o_t\vert i_T,o_T,i_{T-1},o_{T-1},...,i_t,i_{t-1},o_{t-1},...,i_1,o_1)=P(o_t\vert i_t)</script></li>
</ol>
<h3 id="隐马尔可夫模型的三个基本问题"><a href="#隐马尔可夫模型的三个基本问题" class="headerlink" title="隐马尔可夫模型的三个基本问题"></a>隐马尔可夫模型的三个基本问题</h3><ol>
<li>概率计算问题：给定模型$\lambda=(A,B,\pi)$和观测序列$O=(o_1,o_2,…,o_T)$，计算在模型$\lambda$下观测序列$O$出现的概率$P(O\vert \lambda)$；</li>
<li>学习问题：已知观测序列$O=(o_1,o_2,…,o_T)$，估计模型$\lambda=(A,B,\pi)$参数，使得在该模型下观测序列概率$P(O\vert \lambda)$最大，即用极大似然估计的方法估计参数；</li>
<li>预测问题：也称为解码问题，已知模型$\lambda=(A,B,\pi)$和观测序列$O=(o_1,o_2,…,o_T)$，求对给定观测序列条件概率$P(I\vert O)$最大的状态序列$I=(i_1,i_2,…,i_T)$，即给定观测序列，求最有可能的对应状态序列。</li>
</ol>
<h3 id="概率计算问题"><a href="#概率计算问题" class="headerlink" title="概率计算问题"></a>概率计算问题</h3><h5 id="直接计算法"><a href="#直接计算法" class="headerlink" title="直接计算法"></a>直接计算法</h5><p>对于求$P(O\vert \lambda)$最直接的方法就是按照概率公式直接计算，即：</p>
<script type="math/tex; mode=display">\begin{aligned}
P(O\vert\lambda)&=\sum_{I}P(O,I\vert\lambda) \\
&=\sum_{I}P(O\vert I,\lambda)P(I\vert\lambda) 
\end{aligned}</script><p>其中，$P(I\vert \lambda)$表示给定模型参数时，产生状态序列$I=(i_1,i_2,…,i_T)$的概率：</p>
<script type="math/tex; mode=display">P(I\vert \lambda)=\pi_{i_1}a_{i_1i_2}a_{i_2i_3}\cdots a_{i_{T-1}i_T}</script><p>$P(O\vert I,\lambda)$表示给定模型参数且状态序列为$I=(i_1,i_2,…,i_T)$时，产生观测序列$O=(o_1,o_2,…,o_T)$的概率：</p>
<script type="math/tex; mode=display">P(O\vert I,\lambda)=b_{i_1o_1}b_{i_2o_2}...b_{i_To_T}</script><p>所以</p>
<script type="math/tex; mode=display">\begin{aligned}
P(O\vert\lambda)&=\sum_{I}P(O\vert I,\lambda)P(I\vert\lambda) \\
&=\sum_{i_1,i_2,...,i_T}\pi_{i_1}b_{i_1o_1}a_{i_1i_2}b_{i_2o_2}\cdots a_{i_{T-1}i_T}b_{i_To_T}
\end{aligned}</script><p>其中，$\sum_{i_1,i_2,…,i_T}$共有$N^T$种可能，计算$\pi_{i_1}b_{i_1o_1}a_{i_1i_2}b_{i_2o_2}\cdots a_{i_{T-1}i_T}b_{i_To_T}$的时间复杂度为$O(T)$，所以上式整体的时间复杂度为$O(TN^T)$，显然这种算法是不可行的。</p>
<h5 id="前向算法"><a href="#前向算法" class="headerlink" title="前向算法"></a>前向算法</h5><p>首先定义<strong>前向概率</strong>：给定隐马尔可夫模型$\lambda$，定义到时刻$t$部分观测序列为$o_1,o_2,…,o_t$且状态为$q_i$的概率为前向概率，记作：</p>
<script type="math/tex; mode=display">\alpha_t(i)=P(o_1,o_2,...,o_t,i_t=q_i\vert \lambda)</script><p><center>
<img src="./hmm-forward.svg">
</center><br>根据前向概率的定义可推得：</p>
<script type="math/tex; mode=display">P(O\vert \lambda)=\sum_{i=1}^{N}P(o_1,o_2,...,o_T,i_T=q_i\vert \lambda)=\sum_{i=1}^{N}\alpha_T(i)</script><p>于是求解$P(O\vert \lambda)$的问题被转化为了求解前向概率$\alpha_T(i)$的问题。由前向概率的定义可知：</p>
<script type="math/tex; mode=display">\begin{aligned}
\alpha_1(i)&=\pi_ib_{io_1}  \\
\alpha_2(i)&=[\sum_{j=1}^{N}\alpha_1(j)a_{ji}]\times b_{io_2} \\
\alpha_3(i)&=[\sum_{j=1}^{N}\alpha_2(j)a_{ji}]\times b_{io_3} \\
\end{aligned}</script><p>依次此类推可得如下递推公式：</p>
<script type="math/tex; mode=display">\alpha_{t+1}(i)=[\sum_{j=1}^{N}\alpha_t(j)a_{ji}]\times b_{io_{t+1}}</script><p>因此可以递推求得：</p>
<script type="math/tex; mode=display">\alpha_{T}(i)=[\sum_{j=1}^{N}\alpha_{T-1}(j)a_{ji}]\times b_{io_{T}}</script><h5 id="后向算法"><a href="#后向算法" class="headerlink" title="后向算法"></a>后向算法</h5><p>同前向算法一样，首先定义<strong>后向概率</strong>：给定隐马尔可夫模型$\lambda$，定义在时刻$t$状态为$q_i$的条件下，从$t+1$到$T$的部分观测序列为$o_{t+1},o_{t+2},…,o_T$的概率为后向概率，记作：</p>
<script type="math/tex; mode=display">\beta_t(i)=P(o_{t+1},o_{t+2},...,o_T\vert i_t=q_i,\lambda)</script><p><center>
<img src="./hmm-backward.svg">
</center><br>由后向概率的定义可知：</p>
<script type="math/tex; mode=display">\begin{aligned}
\beta_T(i)&=1  \\
\beta_{T-1}(i)&=\sum_{j=1}^{N}a_{ij}b_{jo_T}\beta_T(j) \\
\beta_{T-2}(i)&=\sum_{j=1}^{N}a_{ij}b_{jo_{T-1}}\beta_{T-1}(j) \\
\end{aligned}</script><p>依次类推可得递推公式：</p>
<script type="math/tex; mode=display">\beta_t(i)=\sum_{j=1}^{N}a_{ij}b_{jo_{t+1}}\beta_{t+1}(j)</script><p>根据递推公式可求得$\beta_1(i)$，又</p>
<script type="math/tex; mode=display">P(O\vert \lambda)=\sum_{i=1}^{N}\pi_ib_{io_1}\beta_1(i)</script><p>所以也可求得$P(O\vert \lambda)$。<br></p>
<p>综上可以看出前向算法和后向算法都是先计算局部概率，然后递推到全局，每一时刻的概率计算都会用上前一时刻计算出的结果，整体的时间复杂度大约为$O(TN^2)$，明显小于直接计算法的$O(TN^T)$。<br></p>
<p><strong>利用前向概率和后向概率，可以得到关于单个状态和两个状态概率的一些计算公式</strong>：</p>
<ol>
<li>给定模型参数$\lambda$和观测$O$，在时刻$t$处于状态$q_i$的概率，记<script type="math/tex; mode=display">\gamma_t(i)=P(i_t=q_i\vert O,\lambda)</script>可以通过前向概率和后向概率进行计算，推导如下：<script type="math/tex; mode=display">\gamma_t(i)=P(i_t=q_i\vert O,\lambda)=\cfrac{P(i_t=q_i,O\vert \lambda)}{P(O\vert\lambda)}</script>又由前向概率和后向概率的定义可知：<script type="math/tex; mode=display">\alpha_t(i)\beta_t(i)=P(i_t=q_i,O\vert\lambda)</script>所以<script type="math/tex; mode=display">\gamma_t(i)=\cfrac{P(i_t=q_i,O\vert \lambda)}{P(O\vert\lambda)}=\cfrac{P(i_t=q_i,O\vert \lambda)}{\sum_{j=1}^NP(i_t=q_j,O\vert \lambda)}=\cfrac{\alpha_t(i)\beta_t(i)}{\sum_{j=1}^N\alpha_t(j)\beta_t(j)} \tag{A.1}</script></li>
<li>给定模型参数$\lambda$和观测$O$，在时刻$t$处于状态$q_i$且在时刻$t+1$处于状态$q_j$的概率，记<script type="math/tex; mode=display">\xi_t(i,j)=P(i_t=q_i,i_{t+1}=q_j\vert O,\lambda)</script>可以通过前向后向概率进行计算，推导如下：<script type="math/tex; mode=display">\xi_t(i,j)=\cfrac{P(i_t=q_i,i_{t+1}=q_j,O\vert\lambda)}{P(O\vert\lambda)}=\cfrac{P(i_t=q_i,i_{t+1}=q_j,O\vert\lambda)}{\sum_{i=1}^N\sum_{j=1}^NP(i_t=q_i,i_{t+1}=q_j,O\vert\lambda)}</script>而<script type="math/tex; mode=display">P(i_t=q_i,i_{t+1}=q_j,O\vert\lambda)=\alpha_t(i)a_{ij}b_{jo_{t+1}}\beta_{t+1}(j)</script>所以<script type="math/tex; mode=display">\xi_t(i,j)=\cfrac{\alpha_t(i)a_{ij}b_{jo_{t+1}}\beta_{t+1}(j)}{\sum_{i=1}^N\sum_{j=1}^N\alpha_t(i)a_{ij}b_{jo_{t+1}}\beta_{t+1}(j)}\tag{A.2}</script></li>
</ol>
<h3 id="学习问题"><a href="#学习问题" class="headerlink" title="学习问题"></a>学习问题</h3><h5 id="监督学习方法"><a href="#监督学习方法" class="headerlink" title="监督学习方法"></a>监督学习方法</h5><p>假设已给出训练数据包含$S$个长度相同的观测序列和对应的状态序列$\{(O_1,I_1),(O_2,I_2),…,(O_S,I_S)\}$，那么可以利用极大似然估计法来估计隐马尔可夫模型的参数，具体方法如下：</p>
<ul>
<li>转移概率$a_{ij}$的估计：<script type="math/tex; mode=display">a_{ij}=\cfrac{A_{ij}}{\sum_{j=1}^NA_{ij}}</script>其中，$A_{ij}$为样本中时刻$t$处于状态$q_i$而到时刻$t+1$转移到状态$q_j$的频数；</li>
<li>观测概率$b_{jk}$的估计：<script type="math/tex; mode=display">b_{jk}=\cfrac{B_{jk}}{\sum_{k=1}^MB_{jk}}</script>其中，$B_{jk}$为样本中状态为$q_j$，其对应观测为$v_k$的频数；</li>
<li>初始状态概率$\pi_i$的估计为$S$个样本中初始状态为$q_i$的<strong>频率</strong>。</li>
</ul>
<p>显然此训练数据中的状态序列数据通常是需要人工标注出来的，因此代价较高，所以非监督学习的方法更为实用，例如Baum-Welch算法。</p>
<h5 id="Baum-Welch算法"><a href="#Baum-Welch算法" class="headerlink" title="Baum-Welch算法"></a>Baum-Welch算法</h5><p>如果只有观测序列数据$O=(o_1,o_2,…,o_T)$，而没有状态序列数据$I=(i_1,i_2,…,i_T)$，那么隐马尔可夫模型就是一个含有隐变量的概率模型：</p>
<script type="math/tex; mode=display">P(O|\lambda)=\sum_I P(O\vert I,\lambda)P(I\vert \lambda)</script><p>如果要对它进行参数估计，则可以采用<strong>EM算法</strong>来实现，具体步骤如下：</p>
<h6 id="1-确定完全数据的对数似然函数"><a href="#1-确定完全数据的对数似然函数" class="headerlink" title="1.确定完全数据的对数似然函数"></a>1.确定完全数据的对数似然函数</h6><p>此时观测数据为$O=(o_1,o_2,…,o_T)$，未观测数据为$I=(i_1,i_2,…,i_T)$，则完全数据为$(O,I)=(o_1,o_2,…,o_T,i_1,i_2,…,i_T)$，完全数据的对数似然函数为：</p>
<script type="math/tex; mode=display">\ln P(O,I\vert \lambda)</script><p>其中，$P(O,I\vert \lambda)=\pi_{i_1}b_{i_1o_1}a_{i_1i_2}b_{i_2o_2}\cdots a_{i_{T-1}i_T}b_{i_To_T}$，所以可以进一步推得：</p>
<script type="math/tex; mode=display">\begin{aligned}
\ln P(O,I\vert \lambda)&=\ln (\pi_{i_1}b_{i_1o_1}a_{i_1i_2}b_{i_2o_2}\cdots a_{i_{T-1}i_T}b_{i_To_T}) \\
&=\ln \pi_{i_1} + \sum_{t=1}^{T-1}\ln a_{i_t i_{t+1}} + \sum_{t=1}^{T}\ln b_{i_t o_t} \\
\end{aligned}</script><h6 id="2-EM算法E步：求-Q-函数-Q-lambda-bar-lambda"><a href="#2-EM算法E步：求-Q-函数-Q-lambda-bar-lambda" class="headerlink" title="2.EM算法E步：求$Q$函数$Q(\lambda,\bar{\lambda})$"></a>2.EM算法E步：求$Q$函数$Q(\lambda,\bar{\lambda})$</h6><script type="math/tex; mode=display">Q(\lambda,\bar{\lambda})=\sum_I P(I\vert O,\bar{\lambda})\ln P(O,I\vert \lambda)</script><p>其中，$\bar{\lambda}$是隐马尔可夫模型参数的当前估计值，$\lambda$是要极大化的隐马尔可夫模型参数。为了便于后续计算，$Q$函数还可以作如下恒等变形：</p>
<script type="math/tex; mode=display">\begin{aligned}
Q(\lambda,\bar{\lambda})&=\sum_I P(I\vert O,\bar{\lambda})\ln P(O,I\vert \lambda) \\
&=\sum_I \cfrac{P(I\vert O,\bar{\lambda})P(O\vert\bar{\lambda})}{P(O\vert\bar{\lambda})}\ln P(O,I\vert \lambda) \\
&=\sum_I \cfrac{P(O,I\vert\bar{\lambda})}{P(O\vert\bar{\lambda})}\ln P(O,I\vert \lambda)
\end{aligned}</script><p>由于接下来仅极大化$\lambda$，所以$P(O\vert\bar{\lambda})$可以看做常数项进行略去，所以$Q$函数可以进一步化简为：</p>
<script type="math/tex; mode=display">\begin{aligned}
Q(\lambda,\bar{\lambda})&=\sum_I P(O,I\vert\bar{\lambda})\ln P(O,I\vert \lambda) \\
&=\sum_I P(O,I\vert\bar{\lambda})\left(\ln \pi_{i_1} + \sum_{t=1}^{T-1}\ln a_{i_t i_{t+1}} + \sum_{t=1}^{T}\ln b_{i_t o_t}\right) \\
&=\sum_I P(O,I\vert\bar{\lambda})\ln \pi_{i_1} + \sum_I P(O,I\vert\bar{\lambda})\left(\sum_{t=1}^{T-1}\ln a_{i_t i_{t+1}}\right)+ \sum_I P(O,I\vert\bar{\lambda})\left(\sum_{t=1}^{T}\ln b_{i_t o_t}\right)
\end{aligned}</script><h6 id="3-EM算法M步：极大化-Q-函数"><a href="#3-EM算法M步：极大化-Q-函数" class="headerlink" title="3.EM算法M步：极大化$Q$函数"></a>3.EM算法M步：极大化$Q$函数</h6><p>由于要极大化的参数在上式中单独地出现在3个项中，所以只需对各项分别极大化。</p>
<ol>
<li>上述$Q$函数中的第1项可以写成：<script type="math/tex; mode=display">\begin{aligned}
\sum_I P(O,I\vert\bar{\lambda})\ln \pi_{i_1} &=\sum_{i=1}^N \left\{\ln\pi_{i}\cdot\left(\sum_{i_2,i_3,...,i_T} P(O,i_1=q_i,i_2,i_3,...,i_T\vert\bar{\lambda})\right)\right\} \\
&=\sum_{i=1}^N \left\{\ln\pi_{i}\cdot P(O,i_1=q_i\vert\bar{\lambda})\right\} \\
&=\sum_{i=1}^N\ln\pi_{i}P(O,i_1=q_i\vert\bar{\lambda})
\end{aligned}</script>由于$\pi_i$需要满足约束$\sum_{i=1}^N\pi_i=1$，利用拉格朗日乘子法，写出拉格朗日函数：<script type="math/tex; mode=display">\sum_{i=1}^N\ln\pi_{i}P(O,i_1=q_i\vert\bar{\lambda})+\eta\left(\sum_{i=1}^N\pi_i-1\right)</script>对其关于$\pi_i$求偏导并令结果为0：<script type="math/tex; mode=display">\cfrac{\partial}{\partial\pi_i}\left[\sum_{i=1}^N\ln\pi_{i}P(O,i_1=q_i\vert\bar{\lambda})+\eta\left(\sum_{i=1}^N\pi_i-1\right)\right]=0</script>得<script type="math/tex; mode=display">P(O,i_1=q_i\vert\bar{\lambda})+\eta\pi_i=0\tag{B.1}</script>对上式关于$i$求和可得：<script type="math/tex; mode=display">\begin{aligned}
\sum_{i=1}^N\left[P(O,i_1=q_i\vert\bar{\lambda})+\eta\pi_i\right]&=0 \\
\sum_{i=1}^NP(O,i_1=q_i\vert\bar{\lambda})+\sum_{i=1}^N\eta\pi_i&=0 \\
P(O\vert\bar{\lambda})+\eta\cdot 1&=0 \\
\end{aligned}</script>解得<script type="math/tex; mode=display">\eta=-P(O\vert\bar{\lambda})</script>将其代回式（B.1）可得：<script type="math/tex; mode=display">P(O,i_1=q_i\vert\bar{\lambda})-P(O\vert\bar{\lambda})\cdot\pi_i=0</script><script type="math/tex; mode=display">\pi_i = \cfrac{P(O,i_1=q_i\vert\bar{\lambda})}{P(O\vert\bar{\lambda})}</script><script type="math/tex; mode=display">\pi_i=\gamma_1(i)</script>其中，$\gamma_1(i)$由式（A.1）给出。</li>
<li>上述$Q$函数中的第2项可以写成：<script type="math/tex; mode=display">\begin{aligned} 
\sum_I P(O,I\vert\bar{\lambda})\left(\sum_{t=1}^{T-1}\ln a_{i_t i_{t+1}}\right)&=\sum_{t=1}^{T-1}\left\{\sum_{i=1}^N\sum_{j=1}^N\left[\ln a_{ij}\cdot\left(\sum_{i_1,...,i_{t-1},i_{t+2},...,i_T}P(O,i_1,...,i_t=q_i,i_{t+1}=q_j,...,i_T\vert\bar{\lambda})\right)\right]\right\} \\
&=\sum_{t=1}^{T-1}\left\{\sum_{i=1}^N\sum_{j=1}^N\left[\ln a_{ij}\cdot P(O,i_t=q_i,i_{t+1}=q_j\vert\bar{\lambda})\right]\right\} \\
&=\sum_{t=1}^{T-1}\sum_{i=1}^N\sum_{j=1}^N\ln a_{ij}P(O,i_t=q_i,i_{t+1}=q_j\vert\bar{\lambda})
\end{aligned}</script>由于$a_{ij}$满足约束$\sum_{j=1}^Na_{ij}=1$，同样利用拉格朗日乘子法，写出拉格朗日函数：<script type="math/tex; mode=display">\sum_{t=1}^{T-1}\sum_{i=1}^N\sum_{j=1}^N\ln a_{ij}P(O,i_t=q_i,i_{t+1}=q_j\vert\bar{\lambda})+\eta\left(\sum_{j=1}^Na_{ij}-1\right)</script>对其关于$a_{ij}$求偏导并令结果为0：<script type="math/tex; mode=display">\cfrac{\partial}{\partial a_{ij}}\left[\sum_{t=1}^{T-1}\sum_{i=1}^N\sum_{j=1}^N\ln a_{ij}P(O,i_t=q_i,i_{t+1}=q_j\vert\bar{\lambda})+\eta\left(\sum_{j=1}^Na_{ij}-1\right)\right]=0</script>得<script type="math/tex; mode=display">\sum_{t=1}^{T-1}P(O,i_t=q_i,i_{t+1}=q_j\vert\bar{\lambda})+\eta a_{ij}=0\tag{B.2}</script>对上式关于$j$求和可得：<script type="math/tex; mode=display">\begin{aligned} 
\sum_{j=1}^N\sum_{t=1}^{T-1}P(O,i_t=q_i,i_{t+1}=q_j\vert\bar{\lambda})+\sum_{j=1}^N\eta a_{ij}&=0 \\
\sum_{t=1}^{T-1}P(O,i_t=q_i\vert\bar{\lambda})+\eta\cdot 1&=0 \\
\end{aligned}</script>解得：<script type="math/tex; mode=display">\eta=-\sum_{t=1}^{T-1}P(O,i_t=q_i\vert\bar{\lambda})</script>将其代回式（B.2）可得：<script type="math/tex; mode=display">\sum_{t=1}^{T-1}P(O,i_t=q_i,i_{t+1}=q_j\vert\bar{\lambda})-\sum_{t=1}^{T-1}P(O,i_t=q_i\vert\bar{\lambda}) \cdot a_{ij}=0</script><script type="math/tex; mode=display">a_{ij}=\cfrac{\sum_{t=1}^{T-1}P(O,i_t=q_i,i_{t+1}=q_j\vert\bar{\lambda})}{\sum_{t=1}^{T-1}P(O,i_t=q_i\vert\bar{\lambda})}</script>分子分母同时除以$P(O|\bar{\lambda})$，所以<script type="math/tex; mode=display">a_{ij}=\cfrac{\cfrac{\sum_{t=1}^{T-1}P(O,i_t=q_i,i_{t+1}=q_j\vert\bar{\lambda})}{P(O|\bar{\lambda})}}{\cfrac{\sum_{t=1}^{T-1}P(O,i_t=q_i\vert\bar{\lambda})}{P(O|\bar{\lambda})}}=\cfrac{\sum_{t=1}^{T-1}P(i_t=q_i,i_{t+1}=q_j\vert O,\bar{\lambda})}{\sum_{t=1}^{T-1}P(i_t=q_i\vert O,\bar{\lambda})}=\cfrac{\sum_{t=1}^{T-1}\xi_t(i,j)}{\sum_{t=1}^{T-1}\gamma_t(i)}</script>其中，$\xi_t(i,j)$由式（A.2）给出，$\gamma_t(i)$由式（A.1）给出。</li>
<li>上述$Q$函数中的第3项可以写成：<script type="math/tex; mode=display">\begin{aligned}
\sum_I P(O,I\vert\bar{\lambda})\left(\sum_{t=1}^{T}\ln b_{i_t o_t}\right)&=\sum_{t=1}^{T}\left\{\sum_{j=1}^N\left[\ln b_{jo_t}\cdot\left(\sum_{i_1,...,i_{t-1},i_{t+1},...,i_T}P(O,i_1,...,i_t=q_j,...,i_T\vert\bar{\lambda})\right)\right]\right\} \\
&=\sum_{t=1}^{T}\left\{\sum_{j=1}^N\left[\ln b_{jo_t}\cdot P(O,i_t=q_j\vert\bar{\lambda})\right]\right\} \\
&=\sum_{t=1}^{T}\sum_{j=1}^N\ln b_{jo_t}P(O,i_t=q_j\vert\bar{\lambda}) \\
\end{aligned}</script>由于$b_{jk}$满足约束$\sum_{k=1}^M b_{jk}=1$，同样利用拉格朗日乘子法，写出拉格朗日函数：<script type="math/tex; mode=display">\sum_{t=1}^{T}\sum_{j=1}^N\ln b_{jo_t}P(O,i_t=q_j\vert\bar{\lambda})+\eta\left(\sum_{k=1}^M b_{jk}-1\right)</script>对其关于$b_{jk}$求偏导并令结果为0：<script type="math/tex; mode=display">\cfrac{\partial}{\partial b_{jk}}\left[\sum_{t=1}^{T}\sum_{j=1}^N\ln b_{jo_t}P(O,i_t=q_j\vert\bar{\lambda})+\eta\left(\sum_{k=1}^M b_{jk}-1\right)\right]=0</script>得<script type="math/tex; mode=display">\sum_{t=1}^{T}P(O,i_t=q_j\vert\bar{\lambda})\mathbb{I}(o_t=v_k)+\eta b_{jk}=0 \tag{B.3}</script>其中，$\mathbb{I}(o_t=v_k)$为指示函数。对上式关于$k$求和可得：<script type="math/tex; mode=display">\begin{aligned}
\sum_{k=1}^M\sum_{t=1}^{T}P(O,i_t=q_j\vert\bar{\lambda})\mathbb{I}(o_t=v_k)+\sum_{k=1}^M\eta b_{jk}&=0 \\
\sum_{t=1}^{T}P(O,i_t=q_j\vert\bar{\lambda})+\eta\cdot 1&=0 
\end{aligned}</script>解得：<script type="math/tex; mode=display">\eta=-\sum_{t=1}^{T}P(O,i_t=q_j\vert\bar{\lambda})</script>将其代回式（B.3）可得：<script type="math/tex; mode=display">\sum_{t=1}^{T}P(O,i_t=q_j\vert\bar{\lambda})\mathbb{I}(o_t=v_k)-\sum_{t=1}^{T}P(O,i_t=q_j\vert\bar{\lambda})\cdot b_{jk}=0</script><script type="math/tex; mode=display">b_{jk}=\cfrac{\sum_{t=1}^{T}P(O,i_t=q_j\vert\bar{\lambda})\mathbb{I}(o_t=v_k)}{\sum_{t=1}^{T}P(O,i_t=q_j\vert\bar{\lambda})}</script>分子分母同时除以$P(O|\bar{\lambda})$，所以<script type="math/tex; mode=display">b_{jk}=\cfrac{\cfrac{\sum_{t=1}^{T}P(O,i_t=q_j\vert\bar{\lambda})\mathbb{I}(o_t=v_k)}{P(O|\bar{\lambda})}}{\cfrac{\sum_{t=1}^{T}P(O,i_t=q_j\vert\bar{\lambda})}{P(O|\bar{\lambda})}}=\cfrac{\sum_{t=1}^{T}P(i_t=q_j\vert O,\bar{\lambda})\mathbb{I}(o_t=v_k)}{\sum_{t=1}^{T}P(i_t=q_j\vert O,\bar{\lambda})}=\cfrac{\sum_{t=1,o_t=v_k}^T\gamma_t(j)}{\sum_{t=1}^{T}\gamma_t(j)}</script>其中，$\gamma_t(j)$由式（A.1）给出。</li>
</ol>
<h3 id="预测问题"><a href="#预测问题" class="headerlink" title="预测问题"></a>预测问题</h3><h5 id="近似算法"><a href="#近似算法" class="headerlink" title="近似算法"></a>近似算法</h5><p>近似算法思想：在每个时刻$t$选择在该时刻最有可能出现的状态$i_t^*$，从而得到一个状态序列$I^*=(i_1^*,i_2^*,…,i_T^*)$，将它作为预测的结果。具体算法如下：<br><br>给定隐马尔可夫模型$\lambda$和观测序列$O$，在时刻$t$处于状态$q_i$的概率$\gamma_t(i)$是</p>
<script type="math/tex; mode=display">\gamma_t(i)=\cfrac{\alpha_t(i)\beta_t(i)}{\sum_{j=1}^N\alpha_t(j)\beta_t(j)}</script><p>在每一时刻$t$最有可能的状态$i_t^*$是</p>
<script type="math/tex; mode=display">i_t^*=\arg\max\limits_{1\leq i \leq N}[\gamma_t(i)],\quad t=1,2,...,T</script><p>从而得到状态序列$I^*=(i_1^*,i_2^*,…,i_T^*)$。<br><br>近似算法的优点是计算简单，其缺点是不能保证预测的状态序列整体是最有可能的状态序列，因为预测的序列可能有实际不发生的部分，也即可能存在状态转移概率$a_{i^*j^*}=0$的相邻状态$i^*$和$j^*$出现。<strong>尽管如此，近似算法仍然是有用的。</strong></p>
<h5 id="维特比算法"><a href="#维特比算法" class="headerlink" title="维特比算法"></a>维特比算法</h5><p>维特比（Viterbi）算法实际是用<strong>动态规划</strong>解隐马尔可夫模型预测问题，即用动态规划求概率最大路径，这时一条路径对应着一个状态序列。具体算法如下：<br><br>定义在时刻$t$状态为$q_i$的所有单个路径$(i_1,i_2,…,i_t)$中概率最大值为</p>
<script type="math/tex; mode=display">\delta_t(i)=\max\limits_{i_1,i_2,..,i_{t-1}}P(o_1,...,o_t,i_1,...,i_{t-1},i_t=q_i),\quad i=1,2,...,N</script><p>由此定义可推得</p>
<script type="math/tex; mode=display">\begin{aligned}
\delta_1(i)&=\pi_ib_{io_1} \\
\delta_2(i)&=\max\limits_{1\leq j\leq N}[\delta_1(j)a_{ji}]b_{io_2} \\
\delta_3(i)&=\max\limits_{1\leq j\leq N}[\delta_2(j)a_{ji}]b_{io_3} \\
\end{aligned}</script><p>依次此类推可得如下递推公式：</p>
<script type="math/tex; mode=display">\delta_{t}(i)=\max\limits_{1\leq j\leq N}[\delta_{t-1}(j)a_{ji}]b_{io_t}</script><p>同时再定义在时刻$t$状态为$q_i$的所有单个路径$(i_1,i_2,…,i_t)$中概率最大的路径的第$t-1$个结点为</p>
<script type="math/tex; mode=display">\psi_t(i)=\arg\max\limits_{1\leq j\leq N}[\delta_{t-1}(j)a_{ji}]</script><p>因此，取$i_T^*=\arg\max\limits_{1\leq i\leq N}[\delta_T(i)]$，则$i_{T-1}^*=\psi_T(i_T^*),i_{T-2}^*=\psi_{T-1}(i_{T-1}^*),…,i_1^*=\psi_2(i_2^*)$，具体例子参见<a href="#ref1">[1]</a>第10章例10.3。</p>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p><span id="ref1">[1] 李航.《统计学习方法》</span></p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;隐马尔可夫模型的定义-1&quot;&gt;&lt;a href=&quot;#隐马尔可夫模型的定义-1&quot; class=&quot;headerlink&quot; title=&quot;隐马尔可夫模型的定义[1]&quot;&gt;&lt;/a&gt;隐马尔可夫模型的定义&lt;sup&gt;&lt;a href=&quot;#ref1&quot;&gt;[1]&lt;/a&gt;&lt;/sup&gt;&lt;/h3&gt;
    
    </summary>
    
      <category term="机器学习" scheme="http://sm1les.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="隐马尔可夫模型" scheme="http://sm1les.com/tags/%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B/"/>
    
      <category term="HMM" scheme="http://sm1les.com/tags/HMM/"/>
    
  </entry>
  
  <entry>
    <title>EM算法的两种推导方式</title>
    <link href="http://sm1les.com/2019/03/13/expectation-maximization/"/>
    <id>http://sm1les.com/2019/03/13/expectation-maximization/</id>
    <published>2019-03-13T07:51:10.000Z</published>
    <updated>2019-10-16T05:25:56.919Z</updated>
    
    <content type="html"><![CDATA[<p>EM算法有两种常见的推导方式，一种是李航老师在《统计学习方法》里面给出的，另一种是吴恩达老师在CS229课上讲到的，两种推导方式各有千秋，但都殊途同归，下面对这两种推导方式进行一个总结。由于两种推导方式里都用到了一个经典的不等式——Jensen不等式<sup><a href="#ref1">[1]</a></sup>，所以下面先铺垫一下Jensen不等式。Jensen不等式的定义如下：<br>若$f$是<strong>凸函数</strong>，则</p>
<script type="math/tex; mode=display">f\left(t x_1 + (1-t)x_2\right)\leq tf(x_1)+(1-t)f(x_2)</script><p>其中$t\in [0,1]$，若将$x$推广到$n$个时同样成立，即</p>
<script type="math/tex; mode=display">f(t_1 x_1 + t_2x_2+...+t_nx_n)\leq t_1f(x_1)+t_2f(x_2)+...+t_nf(t_n)</script><p>其中$t_1,t_2,…,t_n\in[0,1],t_1+t_2+…+t_n=1$。此不等式在概率论中通常以如下形式出现</p>
<script type="math/tex; mode=display">\varphi(E[X])\leq E[\varphi(X)]</script><p>其中$X$是一个随机变量，$\varphi$为凸函数，$E[X]$为随机变量$X$的期望。同理，若$f$和$\varphi$是<strong>凹函数</strong>，则只需将不等式中的$\leq$换成$\geq$即可。</p>
<h3 id="EM算法的由来"><a href="#EM算法的由来" class="headerlink" title="EM算法的由来"></a>EM算法的由来</h3><p>假设现有一批独立同分布的样本数据$\{x_1,x_2,…,x_m\}$，它们是由某个含有隐变量的模型$p(x,z;\theta)$生成，现尝试用极大似然估计法估计此模型的参数。由对数似然函数的定义可知此时的对数似然函数为（假设$z$为离散型）</p>
<script type="math/tex; mode=display">\begin{aligned} 
LL(\theta) &=\sum_{i=1}^{m} \ln p(x_i; \theta) \\ 
&=\sum_{i=1}^{m} \ln \sum_{z_i} p(x_i, z_i; \theta) 
\end{aligned}</script><p>显然，此时$LL(\theta)$里含有未知的隐变量$z$以及和（$z$为离散型时）或者积分（$z$为连续型时）的对数，因此无法按照传统方法直接求出使得$LL(\theta)$达到最大值的模型参数$\theta$，而EM算法则给出了一种迭代的方法来完成对$LL(\theta)$的极大化。下面给出EM算法的两种推导方式：</p>
<h3 id="《统计学习方法》版-2"><a href="#《统计学习方法》版-2" class="headerlink" title="《统计学习方法》版[2]"></a>《统计学习方法》版<sup><a href="#ref2">[2]</a></sup></h3><p>设$X=\{x_1,x_2,…,x_m\},Z=\{z_1,z_2,…,z_m\}$，则对数似然函数可以改写为</p>
<script type="math/tex; mode=display">\begin{aligned} 
LL(\theta)&=\ln P(X\vert \theta)\\
&=\ln \sum_Z P(X,Z\vert\theta)\\
&=\ln \left(\sum_Z P(X\vert Z,\theta)P(Z\vert \theta)\right)
\end{aligned}</script><p>EM算法采用的是通过迭代逐步近似极大化$L(\theta)$：假设第$t$次迭代时$\theta$的估计值是$\theta^{(t)}$，我们希望第$t+1$次迭代时的$\theta$能使$LL(\theta)$增大，也即$LL(\theta)&gt;LL(\theta^{(t)})$。为此，考虑两者的差</p>
<script type="math/tex; mode=display">\begin{aligned}
LL(\theta)-LL(\theta^{(t)})&=\ln \left(\sum_Z P(X\vert Z,\theta)P(Z\vert \theta)\right)-\ln P(X\vert\theta^{(t)}) \\
&=\ln \left(\sum_Z P(Z\vert X,\theta^{(t)}) \cfrac{P(X\vert Z,\theta)P(Z\vert \theta)}{P(Z\vert X,\theta^{(t)})}\right)-\ln P(X\vert\theta^{(t)})
\end{aligned}</script><p>由上述Jensen不等式可得</p>
<script type="math/tex; mode=display">\begin{aligned}
LL(\theta)-LL(\theta^{(t)})
&\geq \sum_Z P(Z\vert X,\theta^{(t)})\ln \cfrac{P(X\vert Z,\theta)P(Z\vert \theta)}{P(Z\vert X,\theta^{(t)})}-\ln P(X\vert\theta^{(t)}) \\
&= \sum_Z P(Z\vert X,\theta^{(t)})\ln \cfrac{P(X\vert Z,\theta)P(Z\vert \theta)}{P(Z\vert X,\theta^{(t)})}-1\cdot \ln P(X\vert\theta^{(t)}) \\
&= \sum_Z P(Z\vert X,\theta^{(t)})\ln \cfrac{P(X\vert Z,\theta)P(Z\vert \theta)}{P(Z\vert X,\theta^{(t)})}-\sum_Z P(Z\vert X,\theta^{(t)})\cdot \ln P(X\vert\theta^{(t)}) \\
&=\sum_Z P(Z\vert X,\theta^{(t)}) \left( \ln \cfrac{P(X\vert Z,\theta)P(Z\vert \theta)}{P(Z\vert X,\theta^{(t)})} - \ln P(X\vert\theta^{(t)}) \right)\\
&= \sum_Z P(Z\vert X,\theta^{(t)})\ln \cfrac{P(X\vert Z,\theta)P(Z\vert \theta)}{P(Z\vert X,\theta^{(t)})P(X\vert\theta^{(t)})}
\end{aligned}</script><p>令</p>
<script type="math/tex; mode=display">B(\theta,\theta^{(t)})=LL(\theta^{(t)})+\sum_Z P(Z\vert X,\theta^{(t)})\ln \cfrac{P(X\vert Z,\theta)P(Z\vert \theta)}{P(Z\vert X,\theta^{(t)})P(X\vert\theta^{(t)})}</script><p>则</p>
<script type="math/tex; mode=display">LL(\theta)\geq B(\theta,\theta^{(t)})</script><p>即$B(\theta,\theta^{(t)})$是$LL(\theta)$的下界，此时若设$\theta^{(t+1)}$能使得$B(\theta,\theta^{(t)})$达到极大，也即</p>
<script type="math/tex; mode=display">B(\theta^{(t+1)},\theta^{(t)}) \geq B(\theta,\theta^{(t)})</script><p>由于$LL(\theta^{(t)})=B(\theta^{(t)},\theta^{(t)})$，那么可以进一步推得</p>
<script type="math/tex; mode=display">LL(\theta^{(t+1)})\geq B(\theta^{(t+1)},\theta^{(t)})\geq B(\theta^{(t)},\theta^{(t)})=LL(\theta^{(t)})</script><script type="math/tex; mode=display">LL(\theta^{(t+1)})\geq LL(\theta^{(t)})</script><p>因此，任何能使得$B(\theta,\theta^{(t)})$增大的$\theta$，也可以使得$LL(\theta)$增大，于是问题就转化为了求解能使得$B(\theta,\theta^{(t)})$达到极大的$\theta^{(t+1)}$，即</p>
<script type="math/tex; mode=display">\begin{aligned}
\theta^{(t+1)}&=\mathop{\arg\max}_{\theta}B(\theta,\theta^{(t)}) \\
&=\mathop{\arg\max}_{\theta}\left( LL(\theta^{(t)})+\sum_Z P(Z\vert X,\theta^{(t)})\ln \cfrac{P(X\vert Z,\theta)P(Z\vert \theta)}{P(Z\vert X,\theta^{(t)})P(X\vert\theta^{(t)})}\right)
\end{aligned}</script><p>略去对$\theta$极大化而言是常数的项：</p>
<script type="math/tex; mode=display">\begin{aligned}
\theta^{(t+1)}&=\mathop{\arg\max}_{\theta}\left(\sum_Z P(Z\vert X,\theta^{(t)})\ln\left( P(X\vert Z,\theta)P(Z\vert \theta)\right)\right) \\
&=\mathop{\arg\max}_{\theta}\left(\sum_Z P(Z\vert X,\theta^{(t)})\ln P(X,Z\vert \theta)\right) \\
&=\mathop{\arg\max}_{\theta}Q(\theta,\theta^{(t)})
\end{aligned}</script><p>到此即完成了EM算法的一次迭代，求出的$\theta^{(t+1)}$作为下一次迭代的初始$\theta^{(t)}$。综上所述即可总结出EM算法的“E步”和“M步”分别为：</p>
<p><strong>E步：</strong>计算完全数据的对数似然函数$\ln P(X,Z\vert \theta)$关于在给定观测数据$X$和当前参数$\theta^{(t)}$下对未观测数据$Z$的条件概率分布$ P(Z\vert X,\theta^{(t)})$的期望，也即$Q(\theta,\theta^{(t)})$：</p>
<script type="math/tex; mode=display">Q(\theta,\theta^{(t)})=E_Z[\ln P(X,Z\vert \theta)\vert X,\theta^{(t)}]=\sum_Z P(Z\vert X,\theta^{(t)})\ln P(X,Z\vert \theta)</script><p><strong>M步：</strong>求使得$Q(\theta,\theta^{(t)})$达到极大的$\theta^{(t+1)}$。</p>
<h3 id="CS229版-3"><a href="#CS229版-3" class="headerlink" title="CS229版[3]"></a>CS229版<sup><a href="#ref3">[3]</a></sup></h3><p>设$z_i$的概率质量函数为$Q_i(z_i)$，则$LL(\theta)$可以作如下恒等变形</p>
<script type="math/tex; mode=display">\begin{aligned} 
LL(\theta) &=\sum_{i=1}^{m} \ln p(x_i; \theta) \\ 
&=\sum_{i=1}^{m} \ln \sum_{z_i} p(x_i, z_i; \theta) \\
&=\sum_{i=1}^{m} \ln \sum_{z_i} Q_i(z_i)\cfrac{p(x_i, z_i; \theta)}{Q_i(z_i)} \\
\end{aligned}</script><p>其中$\sum_{z_i} Q_i(z_i)\cfrac{p(x_i, z_i; \theta)}{Q_i(z_i)}$可以看做是对$\cfrac{p(x_i, z_i; \theta)}{Q_i(z_i)}$关于$z_i$求期望，也即</p>
<script type="math/tex; mode=display">\sum_{z_i} Q_i(z_i)\cfrac{p(x_i, z_i; \theta)}{Q_i(z_i)}=E_{z_i}\left[\cfrac{p(x_i, z_i; \theta)}{Q_i(z_i)}\right]</script><p>那么由Jensen不等式可得</p>
<script type="math/tex; mode=display">\ln\left(E_{z_i}\left[\cfrac{p(x_i, z_i; \theta)}{Q_i(z_i)}\right]\right)\geq E_{z_i}\left[\ln\left(\cfrac{p(x_i, z_i; \theta)}{Q_i(z_i)}\right)\right]</script><script type="math/tex; mode=display">\ln\sum_{z_i} Q_i(z_i)\cfrac{p(x_i, z_i; \theta)}{Q_i(z_i)}\geq \sum_{z_i} Q_i(z_i)\ln\cfrac{p(x_i, z_i; \theta)}{Q_i(z_i)}</script><p>将此式代入$LL(\theta)$可得</p>
<script type="math/tex; mode=display">\begin{aligned} 
LL(\theta) &=\sum_{i=1}^{m} \ln \sum_{z_i} Q_i(z_i)\cfrac{p(x_i, z_i; \theta)}{Q_i(z_i)} \qquad(A.1)\\
&\geq \sum_{i=1}^{m}\sum_{z_i} Q_i(z_i)\ln\cfrac{p(x_i, z_i; \theta)}{Q_i(z_i)}
\end{aligned}</script><p>若令$B(\theta)=\sum\limits_{i=1}^{m}\sum\limits_{z_i} Q_i(z_i)\ln\cfrac{p(x_i, z_i; \theta)}{Q_i(z_i)}$，则此时$B(\theta)$为$LL(\theta)$的下界函数，那么这个下界函数所能构成的最优下界是多少？也即$B(\theta)$的最大值是多少？显然，$B(\theta)$是$LL(\theta)$的下界函数，那么$LL(\theta)$就是其上界函数，所以如果能使得$B(\theta)=LL(\theta)$，那么此时的$B(\theta)$就取到了最大值。根据Jensen不等式的性质可知，如果能使得$\cfrac{p(x_i, z_i; \theta)}{Q_i(z_i)}$恒等于某个<strong>常量</strong>$c$，大于等于号便可以取到等号。因此，只需任意选取满足$\cfrac{p(x_i, z_i; \theta)}{Q_i(z_i)}=c$的$Q_i(z_i)$就能使得$B(\theta)$达到最大值。由于$Q_i(z_i)$是$z_i$的概率质量函数，所以$Q_i(z_i)$同时也满足约束$0\leq Q_i(z_i)\leq 1,\sum\limits_{z_i} Q_i(z_i)=1$，那么结合$Q_i(z_i)$的所有约束可以推得</p>
<script type="math/tex; mode=display">\cfrac{p(x_i, z_i; \theta)}{Q_i(z_i)}=c</script><script type="math/tex; mode=display">p(x_i, z_i; \theta)=c\cdot Q_i(z_i)</script><script type="math/tex; mode=display">\sum_{z_i}p(x_i, z_i; \theta)=c\cdot \sum_{z_i}Q_i(z_i)</script><script type="math/tex; mode=display">\sum_{z_i}p(x_i, z_i; \theta)=c</script><script type="math/tex; mode=display">\cfrac{p(x_i, z_i; \theta)}{Q_i(z_i)}=\sum_{z_i}p(x_i, z_i; \theta)</script><script type="math/tex; mode=display">Q_i(z_i)=\cfrac{p(x_i, z_i; \theta)}{\sum\limits_{z_i}p(x_i, z_i; \theta)}=\cfrac{p(x_i, z_i; \theta)}{p(x_i; \theta)}=p(z_i|x_i; \theta)</script><p>所以，当且仅当$Q_i(z_i)=p(z_i|x_i; \theta)$时$B(\theta)$取到最大值，将$Q_i(z_i)=p(z_i|x_i; \theta)$代回$LL(\theta)$和$B(\theta)$可以推得</p>
<script type="math/tex; mode=display">\begin{aligned} 
LL(\theta) &=\sum_{i=1}^{m} \ln \sum_{z_i} Q_i(z_i)\cfrac{p(x_i, z_i; \theta)}{Q_i(z_i)} &\qquad(A.2.1)\\
&=\sum_{i=1}^{m} \ln \sum_{z_i}p(z_i|x_i; \theta)\cfrac{p(x_i, z_i; \theta)}{p(z_i|x_i; \theta)} &\qquad(A.2.2)\\
&=\sum_{i=1}^{m}\sum_{z_i} p(z_i|x_i; \theta)\ln\cfrac{p(x_i, z_i; \theta)}{p(z_i|x_i; \theta)}&\qquad(A.2.3)\\
&=\max\{B(\theta)\} &\qquad(A.2.4)\\
\end{aligned}</script><p>其中，（A.2.3）是（A.1）中不等号取等号时的情形。由以上推导可知，对数似然函数$LL(\theta)$等价于其下界函数的最大值$\max\{B(\theta)\}$，所以要想极大化$LL(\theta)$可以通过极大化$\max\{B(\theta)\}$来间接极大化$LL(\theta)$，因此，下面考虑如何极大化$\max\{B(\theta)\}$。假设<strong>已知</strong>第$t$次迭代的参数为$\theta^{(t)}$，而第$t+1$次迭代的参数$\theta^{(t+1)}$通过如下方式求得</p>
<script type="math/tex; mode=display">\begin{aligned} 
\theta^{(t+1)}&=\arg\max_{\theta}\max\{B(\theta)\} \qquad\qquad\qquad\qquad\qquad(A.3) \\
&=\arg\max_{\theta}\sum_{i=1}^{m}\sum_{z_i} p(z_i|x_i;\theta^{(t)})\ln\cfrac{p(x_i, z_i; \theta)}{p(z_i|x_i; \theta^{(t)})} \\
&=\arg\max_{\theta}\sum_{i=1}^{m}\sum_{z_i} p(z_i|x_i;\theta^{(t)})\ln p(x_i, z_i; \theta)
\end{aligned}</script><p>将$\theta^{(t+1)}$代入$LL(\theta^{(t+1)})$则可以进一步推得</p>
<script type="math/tex; mode=display">\begin{aligned} 
LL(\theta^{(t+1)}) &=\max\{B(\theta^{(t+1)})\} &\qquad(A.4.1) \\
&=\sum_{i=1}^{m}\sum_{z_i} p(z_i|x_i; \theta^{(t+1)})\ln\cfrac{p(x_i, z_i; \theta^{(t+1)})}{p(z_i|x_i; \theta^{(t+1)})} &\qquad(A.4.2)\\
&\geq \sum_{i=1}^{m}\sum_{z_i} p(z_i|x_i; \theta^{(t)})\ln\cfrac{p(x_i, z_i; \theta^{(t+1)})}{p(z_i|x_i; \theta^{(t)})} &\qquad(A.4.3)\\
&\geq \sum_{i=1}^{m}\sum_{z_i} p(z_i|x_i; \theta^{(t)})\ln\cfrac{p(x_i, z_i; \theta^{(t)})}{p(z_i|x_i; \theta^{(t)})} &\qquad(A.4.4)\\
&=\max\{B(\theta^{(t)})\} &\qquad(A.4.5) \\
&=LL(\theta^{(t)})&\qquad(A.4.6)
\end{aligned}</script><p>其中，（A.4.1）和（A.4.2）由（A.2）推得；（A.4.3）由（A.1）推得；（A.4.4）由（A.3）推得；（A.4.5）和（A.4.6）由（A.2）推得。显然，若令</p>
<script type="math/tex; mode=display">Q(\theta,\theta^{(t)})=\sum_{i=1}^{m}\sum_{z_i} p(z_i|x_i; \theta^{(t)})\ln p(x_i, z_i; \theta)</script><p>那么由（A.4）可知，凡是能使得$Q(\theta,\theta^{(t)})$达到极大的$\theta^{(t+1)}$一定能使得$LL(\theta^{(t+1)})\geq LL(\theta^{(t)})$。综上所述即可总结出EM算法的“E步”和“M步”分别为：</p>
<p><strong>E步：</strong>令$Q_i(z_i)=p(z_i|x_i; \theta)$并写出$Q(\theta,\theta^{(t)})$；</p>
<p><strong>M步：</strong>求使得$Q(\theta,\theta^{(t)})$到达极大的$\theta^{(t+1)}$。</p>
<h3 id="证明两种推导方式中的Q函数相等"><a href="#证明两种推导方式中的Q函数相等" class="headerlink" title="证明两种推导方式中的Q函数相等"></a>证明两种推导方式中的Q函数相等</h3><script type="math/tex; mode=display">
\begin{aligned} Q(\theta|\theta^{(t)})&=\sum_Z P(Z|X,\theta^{(t)})\ln P(X,Z|\theta) \\
&=\sum_{z_1,z_2,...,z_m}\left\{\prod_{i=1}^mP(z_i|x_i,\theta^{(t)})\ln\left[ \prod_{i=1}^m P(x_i,z_i|\theta) \right] \right\} \\
&=\sum_{z_1,z_2,...,z_m}\left\{\prod_{i=1}^mP(z_i|x_i,\theta^{(t)})\left[ \sum_{i=1}^m\ln P(x_i,z_i|\theta) \right] \right\} \\
&=\sum_{z_1,z_2,...,z_m}\left\{\prod_{i=1}^mP(z_i|x_i,\theta^{(t)})\left[\ln P(x_1,z_1|\theta) + \ln P(x_2,z_2|\theta) +...+ \ln P(x_m,z_m|\theta)\right] \right\} \\
&=\sum_{z_1,z_2,...,z_m}\left[\prod_{i=1}^mP(z_i|x_i,\theta^{(t)})\cdot\ln P(x_1,z_1|\theta) \right]+...+\sum_{z_1,z_2,...,z_m}\left[\prod_{i=1}^mP(z_i|x_i,\theta^{(t)})\cdot\ln P(x_m,z_m|\theta) \right]  \\
\end{aligned}</script><p>其中$\sum\limits_{z_1,z_2,…,z_m}\left[\prod\limits_{i=1}^mP(z_i|x_i,\theta^{(t)})\cdot\ln P(x_1,z_1|\theta) \right] $可作如下恒等变形：</p>
<script type="math/tex; mode=display">\begin{aligned} 
&=\sum\limits_{z_1,z_2,...,z_m}\left[\prod_{i=2}^mP(z_i|x_i,\theta^{(t)})\cdot P(z_1|x_1,\theta^{(t)})\cdot\ln P(x_1,z_1|\theta) \right] \\
&=\sum_{z_1}\sum\limits_{z_2,...,z_m}\left[\prod_{i=2}^mP(z_i|x_i,\theta^{(t)})\cdot P(z_1|x_1,\theta^{(t)})\cdot\ln P(x_1,z_1|\theta) \right] \\
&=\sum_{z_1}P(z_1|x_1,\theta^{(t)})\ln P(x_1,z_1|\theta) \sum\limits_{z_2,...,z_m}\left[\prod_{i=2}^mP(z_i|x_i,\theta^{(t)}) \right] \\
&=\sum_{z_1}P(z_1|x_1,\theta^{(t)})\ln P(x_1,z_1|\theta)\sum\limits_{z_2,...,z_m}\left[\prod_{i=3}^mP(z_i|x_i,\theta^{(t)})\cdot P(z_2|x_2,\theta^{(t)}) \right] \\
&=\sum_{z_1}P(z_1|x_1,\theta^{(t)})\ln P(x_1,z_1|\theta) \left\{\sum\limits_{z_2}\sum\limits_{z_3,...,z_m}\left[\prod_{i=3}^mP(z_i|x_i,\theta^{(t)})\cdot P(z_2|x_2,\theta^{(t)}) \right]\right\} \\
&=\sum_{z_1}P(z_1|x_1,\theta^{(t)})\ln P(x_1,z_1|\theta) \left\{\sum_{z_2}P(z_2|x_2,\theta^{(t)}) \sum\limits_{z_3,...,z_m}\left[\prod_{i=3}^mP(z_i|x_i,\theta^{(t)})\right]\right\} \\
&=\sum_{z_1}P(z_1|x_1,\theta^{(t)})\ln P(x_1,z_1|\theta) \left\{\sum_{z_2}P(z_2|x_2,\theta^{(t)})\times\sum_{z_3}P(z_3|x_3,\theta^{(t)})\times...\times\sum_{z_m}P(z_m|x_m,\theta^{(t)})\right\} \\
&=\sum_{z_1}P(z_1|x_1,\theta^{(t)})\ln P(x_1,z_1|\theta)\times \left\{1\times1\times...\times1\right\} \\
&=\sum_{z_1}P(z_1|x_1,\theta^{(t)})\ln P(x_1,z_1|\theta)  \\
\end{aligned}</script><p>所以</p>
<script type="math/tex; mode=display">\sum\limits_{z_1,z_2,...,z_m}\left[\prod_{i=1}^mP(z_i|x_i,\theta^{(t)})\cdot\ln P(x_1,z_1|\theta) \right]=\sum_{z_1}P(z_1|x_1,\theta^{(t)})\ln P(x_1,z_1|\theta)</script><p>同理可得</p>
<script type="math/tex; mode=display">\begin{aligned} 
\sum\limits_{z_1,z_2,...,z_m}\left[\prod_{i=1}^mP(z_i|x_i,\theta^{(t)})\cdot\ln P(x_2,z_2|\theta) \right] &=\sum_{z_2}P(z_2|x_2,\theta^{(t)})\ln P(x_2,z_2|\theta) \\
&\vdots\\
\sum\limits_{z_1,z_2,...,z_m}\left[\prod_{i=1}^mP(z_i|x_i,\theta^{(t)})\cdot\ln P(x_m,z_m|\theta) \right] &=\sum_{z_m}P(z_m|x_m,\theta^{(t)})\ln P(x_m,z_m|\theta)
\end{aligned}</script><p>将上式代入$Q(\theta|\theta^{(t)})$可得</p>
<script type="math/tex; mode=display">\begin{aligned} 
Q(\theta|\theta^{(t)})&=\sum_{z_1,z_2,...,z_m}\left[\prod_{i=1}^mP(z_i|x_i,\theta^{(t)})\cdot\ln P(x_1,z_1|\theta) \right]+...+\sum_{z_1,z_2,...,z_m}\left[\prod_{i=1}^mP(z_i|x_i,\theta^{(t)})\cdot\ln P(x_m,z_m|\theta) \right]  \\
&=\sum_{z_1}P(z_1|x_1,\theta^{(t)})\ln P(x_1,z_1|\theta) +...+\sum_{z_m}P(z_m|x_m,\theta^{(t)})\ln P(x_m,z_m|\theta) \\
&=\sum_{i=1}^m\sum_{z_i}P(z_i|x_i,\theta^{(t)})\ln P(x_i,z_i|\theta)\\
\end{aligned}</script><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p><span id="ref1">[1] <a href="https://en.wikipedia.org/wiki/Jensen%27s_inequality" target="_blank" rel="noopener">Jensen’s inequality</a></span><br><span id="ref2">[2] 李航.《统计学习方法》第9章</span><br><span id="ref3">[3] Andrew Ng.CS229-notes8&lt;/a&gt;</span></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;EM算法有两种常见的推导方式，一种是李航老师在《统计学习方法》里面给出的，另一种是吴恩达老师在CS229课上讲到的，两种推导方式各有千秋，但都殊途同归，下面对这两种推导方式进行一个总结。由于两种推导方式里都用到了一个经典的不等式——Jensen不等式&lt;sup&gt;&lt;a href
    
    </summary>
    
      <category term="机器学习" scheme="http://sm1les.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="EM算法" scheme="http://sm1les.com/tags/EM%E7%AE%97%E6%B3%95/"/>
    
      <category term="Jensen不等式" scheme="http://sm1les.com/tags/Jensen%E4%B8%8D%E7%AD%89%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>泰勒公式视角下的梯度下降法和牛顿法</title>
    <link href="http://sm1les.com/2019/03/01/gradient-descent-and-newton-method/"/>
    <id>http://sm1les.com/2019/03/01/gradient-descent-and-newton-method/</id>
    <published>2019-03-01T03:21:35.000Z</published>
    <updated>2019-07-24T01:39:31.716Z</updated>
    
    <content type="html"><![CDATA[<h3 id="泰勒公式视角下的梯度下降法-1-："><a href="#泰勒公式视角下的梯度下降法-1-：" class="headerlink" title="泰勒公式视角下的梯度下降法[1]："></a>泰勒公式视角下的梯度下降法<sup><a href="#ref1">[1]</a></sup>：</h3><p>梯度下降法的目标是使得$f(x_t+\Delta x )&lt;f(x_t)$，由泰勒公式可知，$f(x)$在$x_t$点的一阶泰勒展开为：</p>
<script type="math/tex; mode=display">f(x) = f(x_t)+f’(x_t)(x-x_t)</script><p>则</p>
<script type="math/tex; mode=display">f(x_{t+1}) = f(x_t)+f’(x_t)(x_{t+1}-x_t)</script><p>又$x_{t+1}$可等价写作$x_t + \Delta x$，则上式可化为：</p>
<script type="math/tex; mode=display">f(x_t + \Delta x) = f(x_t)+f’(x_t) \cdot \Delta x</script><p>所以要想使得$f(x_t+\Delta x)$&lt;$f(x_t)$，$f’(x_t)\cdot\Delta x$必须小于0，此时$f’(x_t)$为定值，$\Delta x$为可变部分，于是可以令$\Delta x = -\eta \cdot f’(x_t)$，其中$\eta&gt;0$，则</p>
<script type="math/tex; mode=display">f’(x_t) \cdot \Delta x= -\eta(f’(x_t))^2<0</script><p>由此可以推得当$\Delta x = -\eta \cdot f’(x_t)$时，$f(x_t+\Delta x )&lt;f(x_t)$恒成立。</p>
<h3 id="泰勒公式视角下的牛顿法-2-："><a href="#泰勒公式视角下的牛顿法-2-：" class="headerlink" title="泰勒公式视角下的牛顿法[2]："></a>泰勒公式视角下的牛顿法<sup><a href="#ref2">[2]</a></sup>：</h3><p>对于无约束的<strong>凸优化</strong>问题</p>
<script type="math/tex; mode=display">\min\limits_{\boldsymbol{x} \in \mathbb{R}^n}f(\boldsymbol{x})</script><p>其中$\boldsymbol{x}^*$为目标函数的最小值点，也是极小值点，牛顿法利用极小值点的必要条件</p>
<script type="math/tex; mode=display">\nabla f(\boldsymbol{x}^*)=\boldsymbol{0}</script><p>从点$\boldsymbol{x}^t$开始，求$ f(\boldsymbol{x})$在$\boldsymbol{x}^t$点的二阶泰勒展开式的极小值点（仅当$\boldsymbol{x}^{t}$点的Hessian矩阵为正定矩阵时），作为下一次（第$t+1$次）的迭代值$\boldsymbol{x}^{t+1}$，直到某次迭代值$\boldsymbol{x}^{t+1}$使得$\parallel\nabla f(\boldsymbol{x}^{t+1})\parallel&lt;\epsilon$时停止迭代，其中$\epsilon$为自定义的精度要求，具体迭代步骤如下，由多元函数的泰勒展开式<sup><a href="#ref3">[3]</a></sup>可得$f(\boldsymbol{x})$在$\boldsymbol{x}^{t}$点的二阶泰勒展开式为：</p>
<script type="math/tex; mode=display">f(\boldsymbol{x})=f(\boldsymbol{x}^t)+g_t^T \cdot (\boldsymbol{x}-\boldsymbol{x}^t)+\cfrac{1}{2}(\boldsymbol{x}-\boldsymbol{x}^t)^T \cdot H_t \cdot (\boldsymbol{x}-\boldsymbol{x}^t)</script><p>其中$g_t$为$f(\boldsymbol{x})$在$\boldsymbol{x}^{t}$点的梯度值，$H_t$为$f(\boldsymbol{x})$在$\boldsymbol{x}^{t}$点的Hessian矩阵。对上式求导并令其等于$\boldsymbol{0}$可得：</p>
<script type="math/tex; mode=display">g_t + H_t \cdot (\boldsymbol{x}-\boldsymbol{x}^t)=\boldsymbol{0}</script><p>解得$\boldsymbol{x}=\boldsymbol{x}^t-H_t^{-1}g_t$，令其为下一次的迭代值，即$\boldsymbol{x}^{t+1}=\boldsymbol{x}^t-H_t^{-1}g_t$。<br>【注】：</p>
<ul>
<li>牛顿法也是经典的求根算法，在求根时是一阶算法，在求最优化问题时是二阶算法，具体参见<sup><a href="#ref4">[4]</a></sup>；</li>
<li>关于牛顿法和梯度下降法的效率对比：从本质上去看，牛顿法是二阶收敛，梯度下降是一阶收敛，所以牛顿法就更快。如果更通俗地说的话，比如你想找一条最短的路径走到一个盆地的最底部，梯度下降法每次只从你当前所处位置选一个坡度最大的方向走一步，牛顿法在选择方向时，不仅会考虑坡度是否够大，还会考虑你走了一步之后，坡度是否会变得更大。所以，可以说牛顿法比梯度下降法看得更远一点，能更快地走到最底部。（牛顿法目光更加长远，所以少走弯路；相对而言，梯度下降法只考虑了局部的最优，没有全局思想。）根据wiki上的解释，从几何上说，牛顿法就是用一个二次曲面去拟合你当前所处位置的局部曲面，而梯度下降法是用一个平面去拟合当前的局部曲面，通常情况下，二次曲面的拟合会比平面更好，所以牛顿法选择的下降路径会更符合真实的最优下降路径<sup><a href="#ref5">[5]</a></sup>。<center>
<img src="./gdandnewton.jpg"><br>
红色为牛顿法的迭代路径，绿色为梯度下降法的迭代路径
</center>

</li>
</ul>
<h3 id="参考文献："><a href="#参考文献：" class="headerlink" title="参考文献："></a>参考文献：</h3><p><span id="ref1">[1] <a href="https://zhuanlan.zhihu.com/p/36564434" target="_blank" rel="noopener">梯度下降法 —— 经典的优化方法</a></span><br><span id="ref2">[2]  李航.《统计学习方法》</span><br><span id="ref3">[3] <a href="https://blog.csdn.net/red_stone1/article/details/70260070" target="_blank" rel="noopener">多元函数的泰勒(Taylor)展开式</a></span><br><span id="ref4">[4] <a href="http://sofasofa.io/forum_main_post.php?postid=1000966" target="_blank" rel="noopener">牛顿法到底是一阶优化算法还是二阶优化算法？</a></span><br><span id="ref5">[5] <a href="http://www.cnblogs.com/maybe2030/p/4751804.html" target="_blank" rel="noopener">常见的几种最优化方法</a></span></p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;泰勒公式视角下的梯度下降法-1-：&quot;&gt;&lt;a href=&quot;#泰勒公式视角下的梯度下降法-1-：&quot; class=&quot;headerlink&quot; title=&quot;泰勒公式视角下的梯度下降法[1]：&quot;&gt;&lt;/a&gt;泰勒公式视角下的梯度下降法&lt;sup&gt;&lt;a href=&quot;#ref1&quot;&gt;[
    
    </summary>
    
      <category term="最优化" scheme="http://sm1les.com/categories/%E6%9C%80%E4%BC%98%E5%8C%96/"/>
    
    
      <category term="梯度下降法" scheme="http://sm1les.com/tags/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/"/>
    
      <category term="牛顿法" scheme="http://sm1les.com/tags/%E7%89%9B%E9%A1%BF%E6%B3%95/"/>
    
      <category term="泰勒公式" scheme="http://sm1les.com/tags/%E6%B3%B0%E5%8B%92%E5%85%AC%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>Logistic回归与最大熵</title>
    <link href="http://sm1les.com/2019/01/17/logistic-regression-and-maximum-entropy/"/>
    <id>http://sm1les.com/2019/01/17/logistic-regression-and-maximum-entropy/</id>
    <published>2019-01-17T14:22:03.000Z</published>
    <updated>2019-07-23T13:44:54.738Z</updated>
    
    <content type="html"><![CDATA[<p>根据Wikipedia上的资料显示，Logistic回归的起源主要有以下几大历程：最早由Pierre François Verhulst在对人口增长情况进行研究时提出Logistic function<sup><a href="#ref1">[1]</a></sup>，后来Joseph Berkson在其基础上提出Logit function<sup><a href="#ref2">[2]</a></sup>，再后来David Cox用Logit function来做二分类的回归分析，进而提出了Logistic regression<sup><a href="#ref3">[3]</a></sup>，详细的起源历程参见<a href="#ref4">[4]</a>和<a href="#ref5">[5]</a>。Logistic回归除了按照它的起源从对数几率的角度解释以外，还有业界比较认同的从最大熵的角度来解释，下面给出Logistic回归从最大熵角度的解释。</p>
<p>对于数据集$\{(\boldsymbol x_1,y_1),(\boldsymbol x_2,y_2)…(\boldsymbol x_m,y_m)\}$，其中$\boldsymbol x_i\in \mathbb{R}^n,i=1,2…m$，Logistic回归在对随机变量$y\vert\boldsymbol x$建模的时候是假设其取值仅为0或1，即$y_i\in\{0,1\}$，且$y\vert\boldsymbol x$有固定但未知的期望$\mu$，所以根据<strong>最大熵原理</strong>，此时可以假设$y\vert\boldsymbol x$服从伯努利分布（原因参见<a href="/2019/01/13/exponential-family-and-maximum-entropy">《指数族分布与最大熵》</a>），接着我们想用线性模型来对$y\vert\boldsymbol x$的概率$p(y\vert\boldsymbol x)$进行建模，于是可以通过广义线性模型（Generalized Linear Models）<sup><a href="#ref6">[6]</a></sup>的建模方法得到我们想要的模型。广义线性模型的建模步骤如下<sup><a href="#ref7">[7]</a></sup>：</p>
<ul>
<li>在给定$\boldsymbol x$的条件下，假设随机变量$y\vert\boldsymbol x$服从某个指数族分布（Exponential family）<sup><a href="#ref8">[8]</a></sup>；</li>
<li>假设该指数族分布中的自然参数$\eta(\boldsymbol\theta)$和$\boldsymbol x$呈线性关系，即$\eta(\boldsymbol\theta) = \boldsymbol w^T \boldsymbol x$；</li>
<li>建模出的模型为$T(y\vert\boldsymbol x)$的期望$E[T(y\vert\boldsymbol x)]$的表达式。</li>
</ul>
<p>在使用上述步骤对$y$进行建模前，先证明一下伯努利分布属于指数族分布：<br>伯努利分布的分布律如下：</p>
<script type="math/tex; mode=display">p(x)=\mu^x (1-\mu)^{1-x}</script><p>其中$x\in\{0,1\}$，$\mu$为$x=1$的概率也为$x$的期望，即$p(1)=E[x]=\mu$。对其进行恒等变形可得：</p>
<script type="math/tex; mode=display">
\begin{aligned}    
p(x) &= \mu^x (1-\mu)^{1-x} \\
&= \exp(x \ln \mu+(1−x) \ln(1−\mu)) \\
&= \exp \left((\ln(\cfrac{\mu}{1-\mu}))x+\ln(1-\mu) \right)
\end{aligned}</script><p>对照<a href="/2019/01/13/exponential-family-and-maximum-entropy">《指数族分布与最大熵》</a>中指数族分布的一般形式可知，伯努利分布属于指数族分布，且对应的指数族分布参数为：</p>
<script type="math/tex; mode=display">
\begin{aligned}    
\boldsymbol\theta &=\mu &(A.1)\\
\eta(\boldsymbol\theta)&= \ln(\cfrac{\mu}{1-\mu}) &(A.2)\\
T(x) &= x &(A.3)\\
A(\boldsymbol\theta) &= -\ln(1-\mu) &(A.4)\\
h(x) &= 1 &(A.5)
\end{aligned}</script><p>现在便可以根据上述广义线性模型的建模步骤对$y$进行建模：首先$y$服从伯努利分布，属于指数族分布，接着假设伯努利分布中的自然参数$\eta(\boldsymbol\theta)=\boldsymbol w^T \boldsymbol x$，再接着计算充分统计量$T(y\vert\boldsymbol x)$的期望表达式：</p>
<script type="math/tex; mode=display">
\begin{aligned}    
E[T(y\vert\boldsymbol x)]&= E[y\vert\boldsymbol x] \\
&= \mu \\
&= \cfrac{1}{1+e^{(-\eta(\boldsymbol\theta))}} \\
&= \cfrac{1}{1+e^{(-\boldsymbol w^T \boldsymbol x)}}
\end{aligned}</script><p>其中，第1个等式由式（A.3）导出；第2个等式是因为$y\vert\boldsymbol x$服从伯努利分布，所以$E(y\vert\boldsymbol x)=1*p(1\vert\boldsymbol x)+0*(1-p(1\vert\boldsymbol x))=p(1\vert\boldsymbol x)=\mu$；第3个等式是由式(A.2)导出，所以现在建模出的模型为：</p>
<script type="math/tex; mode=display">E(y\vert\boldsymbol x)=p(1\vert\boldsymbol x)=\cfrac{1}{1+e^{(-\boldsymbol w^T \boldsymbol x)}}</script><p>显然此即为Logistic回归模型。<br>【注】：</p>
<ul>
<li>上述广义线性模型的建模步骤是一种固定的建模方法，也就是说在构建广义线性模型时，我们唯一要做的就是假设$y\vert\boldsymbol x$服从何种<strong>指数族分布</strong>，通常是以最大熵原理为准则来假设$y\vert\boldsymbol x$的分布，例如在做二分类问题时通常假设$y\vert\boldsymbol x$服从伯努利分布，在做回归问题时通常假设$y\vert\boldsymbol x$服从高斯分布，在做网站访问量预测时通常假设$y\vert\boldsymbol x$服从泊松分布。在确定$y\vert\boldsymbol x$的分布后，只需按照上述步骤即可构建出一个广义线性模型；</li>
<li>除了从伯努利分布属于最大熵分布来解释以外，还有学者直接通过最大熵原理推导出Logistic回归，详细推导过程参见<a href="#ref9">[9]</a>，文中推导思路如下：首先说明Logistic回归是多分类模型类别总数k=2时的特例，所以只要用最大熵原理推导出多分类模型也就推导出了Logistic回归。于是先证明了多分类模型的Softmax函数在取得最优参数时类似一个指示函数，接着便以此为约束条件用最大熵原理推导出Softmax函数，也即推导出多分类模型，进而也就推导出了Logistic回归。类似的直接从最大熵原理出发的推导还有<a href="#ref10">[10]</a>；</li>
<li>Logistic回归也可以从贝叶斯的角度解释，参见<a href="#ref11">[11]</a></li>
<li>本文启发自知乎上的讨论：<a href="https://www.zhihu.com/question/35322351" target="_blank" rel="noopener">为什么 LR 模型要使用 sigmoid 函数，背后的数学原理是什么？</a></li>
</ul>
<h3 id="参考文献："><a href="#参考文献：" class="headerlink" title="参考文献："></a>参考文献：</h3><p><span id="ref1">[1] <a href="https://en.wikipedia.org/wiki/Logistic_function" target="_blank" rel="noopener">Logistic function</a></span><br><span id="ref2">[2] <a href="https://en.wikipedia.org/wiki/Logit" target="_blank" rel="noopener">Logit</a></span><br><span id="ref3">[3] <a href="https://en.wikipedia.org/wiki/Logistic_regression" target="_blank" rel="noopener">Logistic regression</a></span><br><span id="ref4">[4] <a href="https://chenrudan.github.io/blog/2016/01/09/logisticregression.html" target="_blank" rel="noopener">【机器学习算法系列之二】浅析Logistic Regression</a></span><br><span id="ref5">[5] Cramer J S . The Origins of Logistic Regression</span><br><span id="ref6">[6] <a href="https://en.wikipedia.org/wiki/Generalized_linear_model" target="_blank" rel="noopener">Generalized linear model</a></span><br><span id="ref7">[7] Andrew Ng. cs229-notes1</span><br><span id="ref8">[8] <a href="https://en.wikipedia.org/wiki/Exponential_family" target="_blank" rel="noopener">Exponential family</a></span><br><span id="ref9">[9] <a href="http://www. win-vector. com/dfiles/LogisticRegressionMaxEnt. pdf" target="_blank" rel="noopener">Mount, J.The equivalence of logistic regression and maximum entropy models</a></span><br><span id="ref10">[10] <a href="https://www.zhihu.com/question/24094554/answer/108271031" target="_blank" rel="noopener">如何理解最大熵模型里面的特征？ - Semiring的回答 - 知乎</a></span><br><span id="ref11">[11] <a href="http://charleshm.github.io/2016/03/LR-and-NB/" target="_blank" rel="noopener">Logistic Regression and Naive Bayes</a></span></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;根据Wikipedia上的资料显示，Logistic回归的起源主要有以下几大历程：最早由Pierre François Verhulst在对人口增长情况进行研究时提出Logistic function&lt;sup&gt;&lt;a href=&quot;#ref1&quot;&gt;[1]&lt;/a&gt;&lt;/sup&gt;，后来
    
    </summary>
    
      <category term="机器学习" scheme="http://sm1les.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="最大熵" scheme="http://sm1les.com/tags/%E6%9C%80%E5%A4%A7%E7%86%B5/"/>
    
      <category term="Logistic回归" scheme="http://sm1les.com/tags/Logistic%E5%9B%9E%E5%BD%92/"/>
    
      <category term="广义线性模型" scheme="http://sm1les.com/tags/%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>指数族分布与最大熵</title>
    <link href="http://sm1les.com/2019/01/13/exponential-family-and-maximum-entropy/"/>
    <id>http://sm1les.com/2019/01/13/exponential-family-and-maximum-entropy/</id>
    <published>2019-01-13T07:55:30.000Z</published>
    <updated>2019-08-26T13:29:31.018Z</updated>
    
    <content type="html"><![CDATA[<h3 id="最大熵原理"><a href="#最大熵原理" class="headerlink" title="最大熵原理"></a>最大熵原理</h3><p>最大熵原理是概率模型学习的一个准则，最大熵原理认为：学习概率模型时，在所有可能的概率模型（分布）中，熵最大的模型是最好的模型。通常用约束条件来确定概率模型的集合，所以，最大熵原理也可以表述为在满足约束条件的模型集合中选取熵最大的模型<sup><a href="#ref1">[1]</a></sup>。此处所说的“熵”为信息论中的信息熵，信息熵定义如下：</p>
<ul>
<li>自信息：<script type="math/tex; mode=display">I(X) = -log_bp(X)</script>其中，$b=2$时单位为bit，$b=e$时单位为nat，$b=10$时单位为ban.</li>
<li>信息熵是自信息的期望，即：<script type="math/tex; mode=display">H(X)=E[I(X)]=E[-log_bp(X)]</script>当$X$为离散型时：<script type="math/tex; mode=display">H(X)=-\sum_x p(x)log_bp(x)</script>当$X$为连续型时：<script type="math/tex; mode=display">H(X)=-\int_{-\infty}^{+\infty}p(x)log_bp(x)dx</script>其中$p(x)=p(X=x)$，当$X$为连续型时信息熵也称为微分熵，熵只依赖于$X$的分布，而与$X$的取值无关。</li>
</ul>
<h3 id="指数族分布"><a href="#指数族分布" class="headerlink" title="指数族分布"></a>指数族分布</h3><p>指数族（Exponential family）分布<sup><a href="#ref2">[2]</a></sup>是一类分布的总称，该类分布的分布律（概率密度函数）的一般形式如下：</p>
<script type="math/tex; mode=display">\begin{aligned}    
p(x;\boldsymbol\theta) &= \cfrac{1}{Z(\boldsymbol\theta)} h(x) \exp\left(\eta(\boldsymbol\theta)^T T(x) \right) \\
&= h(x) \exp\left(\eta(\boldsymbol\theta)^T T(x) − A(\boldsymbol\theta)\right)
\end{aligned}</script><p>其中，$\boldsymbol\theta$为指数族分布的参数，视具体的分布而定，既可以是向量也可以是标量，此处暂用向量的形式表示，$\eta(\boldsymbol\theta)$是关于$\boldsymbol\theta$的函数，称作自然参数 (natural parameter，也称canonical parameter)，$T(x)$为充分统计量（sufficient statistic），$Z(\boldsymbol\theta)=\exp(A(\boldsymbol\theta))$为配分函数（partition function），是用来保证分布律的累加和$\sum\limits_x p(x|\boldsymbol\theta)=1$或者概率密度的积分值$\int_{-\infty}^{+\infty}p(x|\boldsymbol\theta)=1$，$h(x)$为一个关于$x$的函数，常见的伯努利分布和正态分布均属于指数族分布，所有指数族分布以及每个分布的各项参数值参见<a href="#ref2">[2]</a>里的表格。指数族分布有个很重要的性质：在给定的约束条件下，指数族分布是信息熵（微分熵）最大的分布。例如：在已知$X\in\{0,1\}$且期望$E[X]=\mu$时，伯努利分布是熵最大的分布；在已知$X$的均值为$\mu$，方差为$\sigma^2$时，正态分布是熵最大的分布，其他最大熵分布参见<a href="#ref3">[3]</a>里的表格。</p>
<h5 id="指数族分布的最大熵推导："><a href="#指数族分布的最大熵推导：" class="headerlink" title="指数族分布的最大熵推导："></a>指数族分布的最大熵推导：</h5><p><strong>当$X$为离散型时</strong><sup><a href="#ref4">[4]</a></sup>：<br>若已知$X$满足如下约束条件：</p>
<script type="math/tex; mode=display">\sum_{k=1}^{n}\sum_{i=1}^{\vert X \vert} f_k(x_i)p(x_i) = F_k \qquad (A.1)</script><p>其中，$\vert X \vert$为$X$的可能取值个数，$n$为约束个数，$f_k(x_i)$为任意函数，$F_k$为已知常数，此时求$X$的最大熵分布等价于求解如下优化问题：</p>
<script type="math/tex; mode=display">\begin{aligned}    
\max\limits_{p}\quad&-\sum_{i=1}^{\vert X \vert} p(x_i)\ln p(x_i) \\
s.t.\quad &p(x_i)  \geq0 \\
&\sum_{i=1}^{\vert X \vert} p(x_i) = 1 \\
&\sum_{k=1}^{n}\sum_{i=1}^{\vert X \vert}  f_k(x_i)p(x_i) = F_k
\end{aligned}</script><p>其中信息熵的单位为nat，也即取$b=e$，对该优化问题用拉格朗日乘子法可得：</p>
<script type="math/tex; mode=display">\begin{aligned}    
L(p,\boldsymbol\lambda) &=-\sum_{i=1}^{\vert X \vert}p(x_i)\ln p(x_i)+\lambda_0(1-\sum_{i=1}^{\vert X \vert}p(x_i))+\sum_{k=1}^{n}\lambda_k\left(F_k-\sum_{i=1}^{\vert X \vert} f_k(x_i)p(x_i) \right) \\
&=\sum_{i=1}^{\vert X \vert} -p(x_i)\ln p(x_i)-\sum_{i=1}^{\vert X \vert} \lambda_0 p(x_i)-\sum_{i=1}^{\vert X \vert}\sum_{k=1}^{n}\lambda_kf_k(x_i)p(x_i)+\lambda_0+\sum_{k=1}^{n}\lambda_kF_k \\
&=\sum_{i=1}^{\vert X \vert}\left(-p(x_i)\ln p(x_i)-\lambda_0 p(x_i)-\sum_{k=1}^{n}\lambda_kf_k(x_i)p(x_i)\right)+\lambda_0+\sum_{k=1}^{n}\lambda_kF_k
\end{aligned}</script><p>其中，$p$可以看作一个分布律向量，也即$p=[p(x_1),p(x_2),…,p(x_{\vert X \vert})]$，$\boldsymbol\lambda=[\lambda_0,\lambda_1,…,\lambda_n]^T$为拉格朗日乘子向量，对$L(p,\boldsymbol\lambda)$关于$p$求偏导等价于分别对所有的$p(x_i)$求偏导：</p>
<script type="math/tex; mode=display">\begin{aligned}
\cfrac{\partial L(p,\boldsymbol\lambda)}{\partial p(x_1)}&=-\ln p(x_1)-1-\lambda_0-\sum_{k=1}^{n}\lambda_kf_k(x_1) \\
\cfrac{\partial L(p,\boldsymbol\lambda)}{\partial p(x_2)}&=-\ln p(x_2)-1-\lambda_0-\sum_{k=1}^{n}\lambda_kf_k(x_2) \\
\vdots \\
\cfrac{\partial L(p,\boldsymbol\lambda)}{\partial p(x_{\vert X \vert})}&=-\ln p(x_{\vert X \vert})-1-\lambda_0-\sum_{k=1}^{n}\lambda_kf_k(x_{\vert X \vert}) 
\end{aligned}</script><p>则</p>
<script type="math/tex; mode=display">\cfrac{\partial L(p,\boldsymbol\lambda)}{\partial p(x_i)}=-\ln p(x_i)-1-\lambda_0-\sum_{k=1}^{n}\lambda_kf_k(x_i)</script><p>令上式等于0解得：</p>
<script type="math/tex; mode=display">p(x_i) =\exp(-1-\lambda_0-\sum\limits_{k=1}^{n}\lambda_kf_k(x_i))</script><p>又由约束条件$\sum\limits_{i=1}^{\vert X \vert} p(x_i) = 1$可得：</p>
<script type="math/tex; mode=display">\begin{aligned}    
\sum_{i=1}^{\vert X \vert} \exp(-1-\lambda_0-\sum\limits_{k=1}^{n}\lambda_kf_k(x_i))= 1 \\
\sum_{i=1}^{\vert X \vert} \cfrac{\exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(x_i))}{e^{(1+\lambda_0)}}= 1 \\
e^{(1+\lambda_0)}=\sum_{i=1}^{\vert X \vert} \exp(-\sum_{k=1}^{n}\lambda_kf_k(x_i))
\end{aligned}</script><p>将其代入$p(x_i)$可得：</p>
<script type="math/tex; mode=display">p(x_i) =\cfrac{\exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(x_i))}{\sum\limits_{i=1}^{\vert X \vert} \exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(x_i))}</script><p>此式为$X$取到各个值$x_i$的概率，可以从中抽象出$X$的分布律为：</p>
<script type="math/tex; mode=display">\begin{aligned}    
p(x) &=\cfrac{\exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(x))}{\sum\limits_x\exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(x))} \qquad (A.2) \\
&=\cfrac{1}{Z}\exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(x))
\end{aligned}</script><p>其中$Z=\sum\limits_x\exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(x))$，此时$p(x)$的表达式显然符合指数族分布的一般形式。（注：上述推导过程是结合<a href="#ref1">[1]</a>中例6.2和<a href="#ref4">[4]</a>中9.2.6所述内容而成）<br><strong>当$X$为连续型时</strong>：<br>若已知$X$满足如下约束条件：</p>
<script type="math/tex; mode=display">\sum_{k=1}^{n}\int_{-\infty}^{+\infty}f_k(x)p(x)dx = F_k \qquad (B.1)</script><p>其中，$n$为约束个数，$f_k(x)$为任意函数，$F_k$为已知常数，此时求$X$的最大熵分布等价于求解如下优化问题：</p>
<script type="math/tex; mode=display">\begin{aligned}    
\max\limits_{p}\quad&-\int_{-\infty}^{+\infty}p(x)\ln p(x)dx \\
s.t.\quad &p(x)  \geq0 \\
&\int_{-\infty}^{+\infty}p(x)dx = 1 \\
&\int_{-\infty}^{+\infty}f_k(x)p(x)dx = F_k
\end{aligned}</script><p>其中信息熵的单位为nat，也即取$b=e$，对该优化问题用拉格朗日乘子法可得：</p>
<script type="math/tex; mode=display">\begin{aligned}    
L(p,\boldsymbol\lambda) &=-\int_{-\infty}^{+\infty}p(x)\ln p(x)dx+\lambda_0(1-\int_{-\infty}^{+\infty}p(x)dx)+\sum_{k=1}^{n}\lambda_k\left(F_k-\int_{-\infty}^{+\infty}f_k(x)p(x)dx \right) \\
&=\int_{-\infty}^{+\infty}-p(x)\ln p(x)dx-\int_{-\infty}^{+\infty}\lambda_0 p(x)dx-\int_{-\infty}^{+\infty}\sum_{k=1}^{n}\lambda_kf_k(x)p(x)dx+\lambda_0+\sum_{k=1}^{n}\lambda_kF_k \\
&=\int_{-\infty}^{+\infty}\left(-p(x)\ln p(x)-\lambda_0 p(x)-\sum_{k=1}^{n}\lambda_kf_k(x)p(x)\right)dx+\lambda_0+\sum_{k=1}^{n}\lambda_kF_k
\end{aligned}</script><p>其中，$\int_{-\infty}^{+\infty}$可以看作$\sum\limits_x$，因此可以按照$X$为离散型时的推导方法推得$X$的分布律为：</p>
<script type="math/tex; mode=display">\begin{aligned}    
p(x) &=\cfrac{\exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(x))}{\int_{-\infty}^{+\infty}\exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(x))dx} \qquad (B.2)\\
&=\cfrac{1}{Z}\exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(x))
\end{aligned}</script><p>其中$Z=\int_{-\infty}^{+\infty}\exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(x))dx$。</p>
<h5 id="伯努利分布的最大熵推导："><a href="#伯努利分布的最大熵推导：" class="headerlink" title="伯努利分布的最大熵推导："></a>伯努利分布的最大熵推导：</h5><p><strong>“已知$X\in\{0,1\}$且期望$E[X]=\mu$时，伯努利分布是熵最大的分布”</strong>，证明如下：<br>已知$X\in\{0,1\}$，所以$X$属于离散型，则根据式（A.2）知$X$的分布律的一般形式为：</p>
<script type="math/tex; mode=display">p(x) =\cfrac{\exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(x))}{\exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(0))+\exp(-\sum\limits_{k=1}^{n}\lambda_kf_k(1))}</script><p>又已知$E[X]=\mu$，其等价于如下约束条件：</p>
<script type="math/tex; mode=display">\sum_{i=1}^{\vert X \vert} x_ip(x_i) =\mu</script><p>所以对比式（A.2）可知，此时$n=1,f_1(x_i)=x_i,F_1=\mu$，代入$p(x)$可得：</p>
<script type="math/tex; mode=display">p(x) =\cfrac{e^{-\lambda_1 x}}{1+e^{-\lambda_1}}</script><p>再由$E[X]=\mu$可得：</p>
<script type="math/tex; mode=display">E[X]=0*p(0)+1*p(1)=p(1)=\cfrac{e^{-\lambda_1}}{1+e^{-\lambda_1}}=\mu</script><p>所以$X$的分布律为：</p>
<script type="math/tex; mode=display">\begin{aligned}    
p(0)&=1-\mu \\
p(1)&=\mu
\end{aligned}</script><p>显然此即为伯努利分布，证毕。</p>
<h5 id="正态分布的最大熵推导："><a href="#正态分布的最大熵推导：" class="headerlink" title="正态分布的最大熵推导："></a>正态分布的最大熵推导：</h5><p><strong>“已知$X$的均值为$\mu$，方差为$\sigma^2$时，正态分布是熵最大的分布”</strong>，证明如下<sup><a href="#ref5">[5]</a></sup>：<br>此时没有限定$X$的取值范围，则默认为$X\in(-\infty,+\infty)$的连续型，已知$X$的均值为$\mu$，方差为$\sigma^2$，其等价于如下约束条件：</p>
<script type="math/tex; mode=display">\int_{-\infty}^{+\infty}(x-\mu)^2p(x)dx = \sigma^2</script><p>所以对比式（B.1）可知，此时$n=1,f_1(x)=(x-\mu)^2,F_1=\sigma^2$，代入式（B.1）可得此时$X$的分布律：</p>
<script type="math/tex; mode=display">p(x) =\cfrac{\exp(-\lambda_1 (x-\mu)^2)}{\int_{-\infty}^{+\infty}\exp(-\lambda_1 (x-\mu)^2)dx}</script><p>再由$\int_{-\infty}^{+\infty}(x-\mu)^2p(x)dx = \sigma^2$解得：</p>
<script type="math/tex; mode=display">\lambda_1=\cfrac{1}{2\sigma^2}</script><p>代入$p(x)$中得：</p>
<script type="math/tex; mode=display">p(x) =\cfrac{1}{\sqrt{2\pi}\sigma}\exp\left(-\cfrac{(x-\mu)^2}{2\sigma^2}\right)</script><p>显然此即为正态分布，证毕。</p>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p><span id="ref1">[1] 李航.《统计学习方法》</span><br><span id="ref2">[2] <a href="https://en.wikipedia.org/wiki/Exponential_family" target="_blank" rel="noopener">Exponential family</a></span><br><span id="ref3">[3] <a href="https://en.wikipedia.org/wiki/Maximum_entropy_probability_distribution" target="_blank" rel="noopener">Maximum entropy probability distribution</a></span><br><span id="ref4">[4] Murphy K P. 《Machine Learning: A Probabilistic Perspective》</span><br><span id="ref5">[5] 周晓飞. 《统计机器学习》课程的课件</span></p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;最大熵原理&quot;&gt;&lt;a href=&quot;#最大熵原理&quot; class=&quot;headerlink&quot; title=&quot;最大熵原理&quot;&gt;&lt;/a&gt;最大熵原理&lt;/h3&gt;&lt;p&gt;最大熵原理是概率模型学习的一个准则，最大熵原理认为：学习概率模型时，在所有可能的概率模型（分布）中，熵最大的模型是最
    
    </summary>
    
      <category term="机器学习" scheme="http://sm1les.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="指数族分布" scheme="http://sm1les.com/tags/%E6%8C%87%E6%95%B0%E6%97%8F%E5%88%86%E5%B8%83/"/>
    
      <category term="最大熵" scheme="http://sm1les.com/tags/%E6%9C%80%E5%A4%A7%E7%86%B5/"/>
    
  </entry>
  
  <entry>
    <title>L1正则化比L2正则化易得稀疏解的三种解释</title>
    <link href="http://sm1les.com/2019/01/07/l1-and-l2-regularization/"/>
    <id>http://sm1les.com/2019/01/07/l1-and-l2-regularization/</id>
    <published>2019-01-07T09:35:09.000Z</published>
    <updated>2019-10-15T10:02:49.639Z</updated>
    
    <content type="html"><![CDATA[<p>正则化是结构风险最小化策略的实现，是在经验风险上加一个正则化项或罚项，正则化项一般是模型复杂度的单调递增函数，模型越复杂，正则化值就越大。例如模型参数向量的范数，正则化的一般形式如下<sup><a href="#ref1">[1]</a></sup>：</p>
<script type="math/tex; mode=display">\min \limits_{f\in\mathcal{F}} \left( \cfrac{1}{N} \sum_{i=1}^{N} L(y_i,f(\boldsymbol x_i))+\lambda J(f) \right) \qquad (A.1)</script><p>其中，第1项是经验风险，第2项是正则化项，$\lambda$为调整正则化项权重的系数。常用的正则化项是模型参数向量的$L_1$范数和$L_2$范数，分别称作L1正则化和L2正则化。以线性回归为例，其带L1正则化项的损失函数为：</p>
<script type="math/tex; mode=display">J(\boldsymbol w)=\cfrac{1}{N} \sum_{i=1}^{N} (\boldsymbol w^T\boldsymbol x_i-y_i)^2+\lambda \Vert\boldsymbol w \Vert_1</script><p>其中$\Vert\boldsymbol w \Vert_1$为$\boldsymbol w$的$L_1$范数。同理可得带L2正则化项的损失函数为：</p>
<script type="math/tex; mode=display">J(\boldsymbol w)=\cfrac{1}{N} \sum_{i=1}^{N} (\boldsymbol w^T\boldsymbol x_i-y_i)^2+\lambda \Vert\boldsymbol w \Vert_2^2</script><p>其中$\Vert\boldsymbol w \Vert_2$为$\boldsymbol w$的$L_2$范数。使用L1正则化或L2正则化的线性回归也称作<strong>LASSO回归</strong><sup><a href="#ref2">[2]</a></sup>或<strong>岭回归</strong><sup><a href="#ref3">[3]</a></sup>。<br>L1正则化和L2正则化最主要的不同之处在于前者更易得稀疏解，解释如下<sup><a href="#ref4">[4]</a></sup>：</p>
<h5 id="从优化问题的角度："><a href="#从优化问题的角度：" class="headerlink" title="从优化问题的角度："></a>从优化问题的角度：</h5><p>式(A.1)可以看作如下优化问题：</p>
<script type="math/tex; mode=display">\begin{aligned}
& \min\limits_{\boldsymbol w} \quad L_{emp}(\boldsymbol w) \\
& s.t.  \quad \lambda L_{reg}(\boldsymbol w) \leq \eta
\end{aligned}</script><p>其中$L_{emp}(\boldsymbol w)$是经验风险，$L_{reg}(\boldsymbol w)$是正则化项，$\eta$是自行设定的容忍度，此优化问题可以描述为：<strong>把$\boldsymbol w$的解限制一定范围内，同时使得经验风险尽可能小</strong>。L1正则化和L2正则化画图表示如下：</p>
<p><center>
<img src="./l1vsl2.png">
</center><br>其中，左图为L1正则化，右图为L2正则化，$\boldsymbol w^*$是$\boldsymbol w$的解，蓝色等高线为经验风险$L_{emp}(\boldsymbol w)$的取值，红色等高线为正则化项$L_{reg}(\boldsymbol w)$的取值，黄色区域是红色等高线的变化范围，也即$\boldsymbol w^*$的取值范围，默认内环等高线的值更小。从图中可以看出，红色等高线和蓝色等高线的<strong>切点</strong>即为优化问题的解$\boldsymbol w^*$，而且L1正则化相比于L2正则化更容易使得切点落在$\boldsymbol w$某个维度$w_i$的坐标轴上，从而导致另一个维度$w_j$的取值为0，从而更容易得到具有稀疏性的$\boldsymbol w^*$。</p>
<h5 id="从梯度的角度："><a href="#从梯度的角度：" class="headerlink" title="从梯度的角度："></a>从梯度的角度：</h5><p>L1正则化的损失函数一般形式为：</p>
<script type="math/tex; mode=display">J(\boldsymbol w)=L(\boldsymbol w)+\lambda \sum \vert w_i \vert \qquad (B.1)</script><p>L2正则化的损失函数一般形式为：</p>
<script type="math/tex; mode=display">J(\boldsymbol w)=L(\boldsymbol w)+\lambda \sum (w_i)^2 \qquad (B.2)</script><p>对式(B.1)关于$\boldsymbol w$某个维度$w_i$求偏导可得：</p>
<script type="math/tex; mode=display">\cfrac{\partial J(\boldsymbol w)}{\partial w_i}=\cfrac{\partial L(\boldsymbol w)}{\partial w_i}+\lambda sign (w_i)</script><p>对式(B.2)关于$\boldsymbol w$某个维度$w_i$求偏导可得：</p>
<script type="math/tex; mode=display">\cfrac{\partial J(\boldsymbol w)}{\partial w_i}=\cfrac{\partial L(\boldsymbol w)}{\partial w_i}+2\lambda w_i</script><p>当使用梯度下降法等此类根据$\boldsymbol w$的梯度来调整$\boldsymbol w$的算法时，若用L1正则化，$\boldsymbol w$的某个维度$w_i$的更新公式为：</p>
<script type="math/tex; mode=display">w_i:=w_i-\eta\cfrac{\partial J(\boldsymbol w)}{\partial w_i}=w_i-\eta\cfrac{\partial L(\boldsymbol w)}{\partial w_i}-\eta\lambda sign (w_i)</script><p>其中$\eta$为自行设定的学习率，从上式可以看出，$\eta\lambda sign (w_i)$的取值恒为$\pm\eta\lambda$，与$w_i$的大小无关，所以这就会导致即使$w_i$已经很小了但仍然以较高的梯度在变化，从而容易使得$w_i$取到0；若用L2正则化，则更新公式为：</p>
<script type="math/tex; mode=display">w_i:=w_i-\eta\cfrac{\partial J(\boldsymbol w)}{\partial w_i}=w_i-\eta\cfrac{\partial L(\boldsymbol w)}{\partial w_i}-2\eta\lambda w_i</script><p>显然此式中的$2\eta\lambda w_i$的大小与$w_i$相关，所以当$w_i$很小时变化的梯度也很小，不容易取到0，也就不容易得到稀疏解。</p>
<h5 id="从最大后验估计的角度："><a href="#从最大后验估计的角度：" class="headerlink" title="从最大后验估计的角度："></a>从最大后验估计的角度：</h5><p>由于对概率模型来说，其模型的训练过程就是参数估计过程，而对于参数估计，统计学界的两个学派分别提供了不同的解决方案：频率主义学派认为参数虽然未知，但却是客观存在的固定值，因此，可以通过优化似然函数等准则来确定参数值，其主张使用的参数估计方法为极大似然估计（Maximum Likelihood Estimation，MLE）；而贝叶斯学派则认为参数是未观察到的随机变量，其本省也可有分布，因此，可假设参数服从一个先验分布，然后基于观察到的数据来计算参数的后验分布，其主张使用的参数估计方法为最大后验估计（Maximum A Posteriori，MAP）。下面举例对比两种参数估计方法的异同<sup><a href="#ref5">[5]</a></sup>：假设含有N个独立同分布的样本集合为$D=\{(\boldsymbol x_1,y_1),(\boldsymbol x_2,y_2),…,(\boldsymbol x_N,y_N)\}$，极大似然估计法的思路如下：</p>
<script type="math/tex; mode=display">\hat{\boldsymbol{w}} = \mathop{\arg\max}_{\boldsymbol{w}}P(D|\boldsymbol{w})</script><p>其中，$P(D|\boldsymbol{w})$表示样本集合$D$中全体样本的联合概率，通常可以用一个关于参数$\boldsymbol{w}$的函数来进行表示，并且将该函数称之为似然函数。最大后验估计法的思路如下：</p>
<script type="math/tex; mode=display">\hat{\boldsymbol{w}} = \mathop{\arg\max}_{\boldsymbol{w}}P(\boldsymbol{w}|D)</script><p>由贝叶斯公式可知$P(\boldsymbol{w}|D)=\cfrac{P(D|\boldsymbol{w})P( \boldsymbol{w})}{P(D)}$，代入上式可得：</p>
<script type="math/tex; mode=display">\begin{aligned}
\hat{\boldsymbol{w}} &= \mathop{\arg\max}_{\boldsymbol{w}}\cfrac{P(D|\boldsymbol{w})P( \boldsymbol{w})}{P(D)}\\
&= \mathop{\arg\max}_{\boldsymbol{w}}P(D|\boldsymbol{w})P( \boldsymbol{w})\\
\end{aligned}</script><p>其中，$P(\boldsymbol{w})$为对参数$\boldsymbol{w}$的先验估计。显然，如果对$\boldsymbol{w}$的先验估计为均匀分布的话</p>
<script type="math/tex; mode=display">\mathop{\arg\max}_{\boldsymbol{w}}P(D|\boldsymbol{w})P( \boldsymbol{w})=\mathop{\arg\max}_{\boldsymbol{w}}P(D|\boldsymbol{w})</script><p>最大后验估计等价于极大似然估计，但是如果假设参数$\boldsymbol{w}$的先验估计为均值为0方差为$\sigma^2$的高斯分布的话，最大后验估计等价于<strong>极大似然估计+L2正则化项</strong>，具体推导如下：</p>
<script type="math/tex; mode=display">\begin{aligned}
\hat{\boldsymbol{w}} &= \mathop{\arg\max}_{\boldsymbol{w}}P(D|\boldsymbol{w})P( \boldsymbol{w})\\
&= \mathop{\arg\max}_{\boldsymbol{w}}\ln \left( P(D|\boldsymbol{w})P( \boldsymbol{w}) \right) \\
&= \mathop{\arg\min}_{\boldsymbol{w}}-\ln \left( P(D|\boldsymbol{w})P( \boldsymbol{w}) \right) \\
&= \mathop{\arg\min}_{\boldsymbol{w}}-\ln P(D|\boldsymbol{w})-\ln P( \boldsymbol{w}) \\
&= \mathop{\arg\min}_{\boldsymbol{w}} J(\boldsymbol{w}) \\
\end{aligned}</script><p>由于</p>
<script type="math/tex; mode=display">\begin{aligned}
P(\boldsymbol{w}) &= \prod_{i=1}^{d}P(w_i)=\prod_{i=1}^{d}\cfrac{1}{\sqrt{2\pi}\sigma} \mathrm{exp}\left(-\cfrac{w_i^2}{2\sigma^2}\right) \\ 
\ln P(\boldsymbol{w}) &= \sum_{i=1}^{d}\ln\cfrac{1}{\sqrt{2\pi}\sigma} \mathrm{exp}\left(-\cfrac{w_i^2}{2\sigma^2}\right) \\
&= d \cdot \ln\cfrac{1}{\sqrt{2\pi}\sigma} -\cfrac{1}{2\sigma^2} \cdot  \sum_{i=1}^{d}w_i^2 \\
&= d \cdot \ln\cfrac{1}{\sqrt{2\pi}\sigma} -\cfrac{1}{2\sigma^2} \cdot  \Vert\boldsymbol{w}\Vert_2^2
\end{aligned}</script><p>所以</p>
<script type="math/tex; mode=display">J(\boldsymbol{w}) = -\ln P(D|\boldsymbol{w})-d \cdot \ln\cfrac{1}{\sqrt{2\pi}\sigma} +\cfrac{1}{2\sigma^2} \cdot  \Vert\boldsymbol{w}\Vert_2^2</script><p>由于$d \cdot \ln\cfrac{1}{\sqrt{2\pi}\sigma}$与$\boldsymbol{w}$无关，可以略去，所以</p>
<script type="math/tex; mode=display">J(\boldsymbol{w})=  -\ln P(D|\boldsymbol{w})+\cfrac{1}{2\sigma^2} \cdot  \Vert\boldsymbol{w}\Vert_2^2</script><p>同理可得<strong>采用拉普拉斯分布先验的最大后验估计=极大似然估计+L1正则化项</strong>。观察高斯分布和拉普拉斯分布的概率密度函数图像可知，拉普拉斯分布更为稀疏，也即取到0的概率更大，所以其生成的参数$\boldsymbol{w}$更为稀疏。</p>
<p><center>
<img src="./normalandlaplace.png" width="60%" height="60%"><br>
图中高斯分布和拉普拉斯分布的均值和方差均相同
</center><br>L1正则化和L2正则化还有如下不同之处：</p>
<ul>
<li>L1正则化自带特征选择的功能，这是由于L1正则化易得稀疏解导致的，因为稀疏解$\boldsymbol w^*$的某些维度$w_i=0$，从而达到了特征选择的功能；</li>
<li>L1正则化的解不稳定，也即可能会有多个解，这是因为L1正则化的红色等高线容易与经验风险的蓝色等高线产生多个切点，例如上图中的蓝色等高线若不为圆形曲线，而是直线时，此时极有可能与L1正则化的红色等高线重合，从而产生多个解；</li>
<li>L1正则化不易求解，这是因为绝对值函数通常都不好求解；</li>
<li>L1正则化相对于L2正则化对异常值敏感度低，这是因为当$\vert w_i \vert&gt;1$时，$\sum\vert w_i \vert &lt; \sum(w_i)^2$，从而对异常值敏感度低。</li>
</ul>
<h3 id="参考文献："><a href="#参考文献：" class="headerlink" title="参考文献："></a>参考文献：</h3><p><span id="ref1">[1] 李航.《统计学习方法》</span><br><span id="ref2">[2] <a href="https://en.wikipedia.org/wiki/Lasso_(statistics)" target="_blank" rel="noopener">Lasso (statistics)</a></span><br><span id="ref3">[3] <a href="https://en.wikipedia.org/wiki/Tikhonov_regularization" target="_blank" rel="noopener"> Ridge regression</a></span><br><span id="ref4">[4] <a href="https://www.zhihu.com/question/37096933" target="_blank" rel="noopener">l1 相比于 l2 为什么容易获得稀疏解？</a></span><br><span id="ref5">[5] <a href="http://www.cs.cmu.edu/~aarti/Class/10701_Spring14/slides/MLE_MAP_Part1.pdf" target="_blank" rel="noopener">MLE, MAP, Bayes classification</a></span></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;正则化是结构风险最小化策略的实现，是在经验风险上加一个正则化项或罚项，正则化项一般是模型复杂度的单调递增函数，模型越复杂，正则化值就越大。例如模型参数向量的范数，正则化的一般形式如下&lt;sup&gt;&lt;a href=&quot;#ref1&quot;&gt;[1]&lt;/a&gt;&lt;/sup&gt;：&lt;/p&gt;
&lt;scrip
    
    </summary>
    
      <category term="机器学习" scheme="http://sm1les.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="L1正则化" scheme="http://sm1les.com/tags/L1%E6%AD%A3%E5%88%99%E5%8C%96/"/>
    
      <category term="L2正则化" scheme="http://sm1les.com/tags/L2%E6%AD%A3%E5%88%99%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>拉格朗日对偶函数及对偶问题</title>
    <link href="http://sm1les.com/2018/12/11/lagrange-duality/"/>
    <id>http://sm1les.com/2018/12/11/lagrange-duality/</id>
    <published>2018-12-11T07:36:48.000Z</published>
    <updated>2019-10-13T08:22:56.109Z</updated>
    
    <content type="html"><![CDATA[<p>对于一般地约束优化问题：</p>
<script type="math/tex; mode=display">\begin{array}{ll}
{\min } & {f(\boldsymbol x)} \qquad\qquad\qquad\qquad\qquad\qquad (A.1)\\ 
{\text {s.t.}} & {g_{i}(\boldsymbol x) \leq 0 \quad(i=1, \ldots, m)} \\ 
{} & {h_{j}(\boldsymbol x)=0 \quad(j=1, \ldots, n)}
\end{array}</script><p>其中，自变量$\boldsymbol x\in \mathbb{R}^k$。设优化问题（A.1）的定义域为$D=\boldsymbol{dom}  f \cap \bigcap\limits_{i=1}^{m}\boldsymbol{dom}  g_i \cap \bigcap\limits_{j=1}^{n}\boldsymbol{dom}  h_j $，可行集为$\tilde{D}=\{\boldsymbol x|\boldsymbol x\in D,g_i(\boldsymbol x) \leq 0,h_j(\boldsymbol x) = 0\}$，最优值为$p^*=\min\{f(\tilde{\boldsymbol x})\}$。由拉格朗日函数的定义可知优化问题（A.1）的拉格朗日函数为</p>
<script type="math/tex; mode=display">L(\boldsymbol x,\boldsymbol \mu,\boldsymbol \lambda)=f(\boldsymbol x)+\sum_{i=1}^{m}\mu_i g_i(\boldsymbol x)+\sum_{j=1}^{n}\lambda_j h_j(\boldsymbol x)</script><p>其中$\boldsymbol \mu=(\mu_1,\mu_2,…,\mu_m)^T,\boldsymbol \lambda=(\lambda_1,\lambda_2,…,\lambda_n)^T$为拉格朗日乘子向量。</p>
<h3 id="拉格朗日对偶函数"><a href="#拉格朗日对偶函数" class="headerlink" title="拉格朗日对偶函数"></a>拉格朗日对偶函数</h3><p>定义优化问题（A.1）的拉格朗日对偶函数$\Gamma (\boldsymbol \mu,\boldsymbol \lambda)$为$L(\boldsymbol x,\boldsymbol \mu,\boldsymbol \lambda)$关于$\boldsymbol x$的下确界，也即</p>
<script type="math/tex; mode=display">\Gamma (\boldsymbol \mu,\boldsymbol \lambda)=\mathop{\inf}_{\boldsymbol x∈D}L(\boldsymbol x,\boldsymbol \mu,\boldsymbol \lambda)=\mathop{\inf}_{\boldsymbol x∈D} \left( f(\boldsymbol x)+\sum_{i=1}^{m}\mu_i g_i(\boldsymbol x)+\sum_{j=1}^{n}\lambda_j h_j(\boldsymbol x) \right)</script><p>对偶函数$\Gamma (\boldsymbol \mu,\boldsymbol \lambda)$有如下重要性质：</p>
<ul>
<li>对偶函数$\Gamma (\boldsymbol \mu,\boldsymbol \lambda)$是一族关于$(\boldsymbol \mu,\boldsymbol \lambda)$的仿射函数的逐点下确界，所以无论优化问题（A.1）是否是凸优化问题，其对偶函数$\Gamma (\boldsymbol \mu,\boldsymbol \lambda)$恒为<strong>凹函数</strong>（证明参见<a href="#ref1">[1]</a> § 3.2.3）；</li>
<li>当$\boldsymbol \mu \succeq 0$时，$\Gamma (\boldsymbol \mu,\boldsymbol \lambda)$构成了优化问题（A.1）最优值$p^*$的下界，也即<script type="math/tex; mode=display">\Gamma (\boldsymbol \mu,\boldsymbol \lambda)\leq p^*</script>【证明】：设$\tilde{\boldsymbol x}\in\tilde{D}$是优化问题（A.1）的可行点，那么当$\boldsymbol \mu \succeq 0$时<script type="math/tex; mode=display">\sum_{i=1}^{n}\mu_i g_i(\tilde{\boldsymbol x})+\sum_{j=1}^{m}\lambda_j h_j(\tilde{\boldsymbol x}) \leq 0</script>这是因为左边第一项非正而第二项恒为0。根据此不等式可以进一步推得<script type="math/tex; mode=display">\Gamma (\boldsymbol \mu,\boldsymbol \lambda)=\mathop{\inf}_{\boldsymbol x∈D}L(\boldsymbol x,\boldsymbol \mu,\boldsymbol \lambda) \leq L(\tilde{\boldsymbol x},\boldsymbol \mu,\boldsymbol \lambda) \leq f(\tilde{\boldsymbol x})</script><script type="math/tex; mode=display">\Gamma (\boldsymbol \mu,\boldsymbol \lambda) \leq \min\{f(\tilde{\boldsymbol x})\}=p^*</script>所以，当$\boldsymbol \mu \succeq 0$时，$\Gamma (\boldsymbol \mu,\boldsymbol \lambda) \leq p^*$恒成立，证毕。</li>
</ul>
<h3 id="拉格朗日对偶问题"><a href="#拉格朗日对偶问题" class="headerlink" title="拉格朗日对偶问题"></a>拉格朗日对偶问题</h3><p>由以上分析可知，当$\boldsymbol \mu \succeq 0$时，对偶函数$\Gamma (\boldsymbol \mu,\boldsymbol \lambda)$构成了优化问题（A.1）最优值$p^*$的下界，那么对偶函数所能取到的最优下界是多少？这也就引出了求对偶函数最大值的问题。定义求对偶函数最大值的优化问题为拉格朗日对偶问题，也即</p>
<script type="math/tex; mode=display">\begin{array}{ll}
{\max } & {\Gamma (\boldsymbol \mu,\boldsymbol \lambda)} \qquad\qquad\qquad\qquad\qquad\qquad (B.1)\\ 
{\text {s.t.}} & {\boldsymbol \mu \succeq 0} 
\end{array}</script><p>设优化问题（B.1）的最优值为$d^*$，显然$d^* \leq p^*$，此时称为“弱对偶性”成立，若$d^* = p^*$，则称为“强对偶性”成立。对偶问题有如下重要性质：</p>
<ul>
<li><p>对偶问题恒为<strong>凸优化问题</strong>，因为对偶函数$\Gamma (\boldsymbol \mu,\boldsymbol \lambda)$恒为<strong>凹函数</strong>（加个负号即可转为凸函数），约束条件$\boldsymbol \mu \succeq 0$恒为凸集。这也就是为什么不直接求解主问题转而去求解对偶问题的主要原因；</p>
</li>
<li><p>当主问题（A.1）满足某些<strong>充分条件（sufficient conditions）</strong><sup><a href="#ref2">[2]</a></sup>时，强对偶性成立。常见的充分条件有<strong>Slater条件</strong><sup><a href="#ref3">[3]</a></sup>：“若主问题是凸优化问题，且可行集$\tilde{D}$中存在一点能使得<strong>所有</strong>不等式约束的不等号成立，则强对偶性成立”（证明参见<a href="#ref1">[1]</a> § 5.3.2）。Slater条件也是KKT条件中的约束限制条件之一；</p>
</li>
<li><p>Slater条件的“弱化”形式（参见<a href="#ref1">[1]</a> § 5.2.3）：“若主问题是凸优化问题，前$k$个不等式约束为<strong>仿射函数</strong>，可行集$\tilde{D}$中存在一点能使得第$k+1$至第$m$个不等式约束的不等号成立，则强对偶性成立”。也就是说当不等式约束中有仿射函数时，不要求可行集$\tilde{D}$中存在一点使得这些仿射不等式的不等号成立；</p>
</li>
<li><p>设$f(\boldsymbol x),g_i(\boldsymbol x),h_j(\boldsymbol x)$一阶偏导连续，$\boldsymbol x^*,(\boldsymbol \mu^*,\boldsymbol \lambda^*)$分别为主问题（A.1）（注：此时并不要求为凸优化问题）和对偶问题（B.1）的最优解，若强对偶性成立，则$\boldsymbol x^*,\boldsymbol \mu^*,\boldsymbol \lambda^*$一定满足KKT条件，也就是说KK条件是强对偶性成立的必要条件；<br>【证明】：因为$\boldsymbol x^*,(\boldsymbol \mu^*,\boldsymbol \lambda^*)$分别为主问题（A.1）和对偶问题（B.1）的最优解，且此时强对偶性成立，那么</p>
<script type="math/tex; mode=display">\begin{aligned}
f(\boldsymbol x^*)&=\Gamma(\boldsymbol \mu^*,\boldsymbol \lambda^*) &(B.2.1)\\
&=\mathop{\inf}_{\boldsymbol x∈D} \left( f(\boldsymbol x)+\sum_{i=1}^{m}\mu_i^* g_i(\boldsymbol x)+\sum_{j=1}^{n}\lambda_j^* h_j(\boldsymbol x) \right) &(B.2.2)\\
&\leq f(\boldsymbol x^*)+\sum_{i=1}^{m}\mu_i^* g_i(\boldsymbol x^*)+\sum_{j=1}^{n}\lambda_j^* h_j(\boldsymbol x^*) &(B.2.3)\\
&\leq f(\boldsymbol x^*)&(B.2.4)
\end{aligned}</script><p>其中，（B.2.1）是由强对偶性成立推得；（B.2.2）是由$\Gamma(\boldsymbol \mu,\boldsymbol \lambda)$的定义推得；（B.2.3）是由下确界函数的性质推得；（B.2.4）是由$\boldsymbol \mu \succeq 0\Rightarrow\mu_i^*\geq0,g_i(\boldsymbol x^*)\leq0,h_j(\boldsymbol x^*)=0$推得。由于$f(\boldsymbol x^*)=f(\boldsymbol x^*)$，所以此时上式中的两个不等号均可以替换为等号。如果将（B.2.3）中的不等号替换为等号，那么可以推得$\boldsymbol x^*$为$L(\boldsymbol x,\boldsymbol \mu^*,\boldsymbol \lambda^*)$的最小值点，所以$L(\boldsymbol x,\boldsymbol \mu^*,\boldsymbol \lambda^*)$在$\boldsymbol x^*$处的梯度一定为0，也即</p>
<script type="math/tex; mode=display">\nabla_{\boldsymbol x} L(\boldsymbol x^* ,\boldsymbol \mu^* ,\boldsymbol \lambda^* )=\nabla f(\boldsymbol  x^* )+\sum_{i=1}^{m}\mu_i^* \nabla g_i(\boldsymbol x^* )+\sum_{j=1}^{n}\lambda_j^* \nabla h_j(\boldsymbol x^*)=0 \qquad (B.3)</script><p>如果将（B.2.4）中的不等号替换为等号，那么可以推得</p>
<script type="math/tex; mode=display">\left\{ \begin{array}{lcl}
\sum_{i=1}^{m}\mu_i^* g_i(\boldsymbol x^*)=0 \\ 
\mu_i^*\geq0 \\
g_i(\boldsymbol x^*)\leq0\\
\end{array}\right.
\Rightarrow 
\left\{ \begin{array}{lcl}
\mu_i^* g_i(\boldsymbol x^*)=0 \\ 
\mu_i^*\geq0 \\
g_i(\boldsymbol x^*)\leq0\\
\end{array}\right.\qquad (B.4)</script><p>此条件称作<strong>互补松弛（complementary slackness）</strong>。将$h_j(\boldsymbol x^*)=0$和（B.3）、（B.4）整合在一起即可得KKT条件，证毕。</p>
</li>
<li><p>若主问题（A.1）为<strong>凸优化问题</strong>，且$f(\boldsymbol x),g_i(\boldsymbol x),h_j(\boldsymbol x)$一阶偏导连续，如果存在$\boldsymbol x^*,\boldsymbol \mu^*,\boldsymbol \lambda^*$满足KKT条件，那么$\boldsymbol x^*$和$(\boldsymbol \mu^*,\boldsymbol \lambda^*)$一定是主问题（A.1）和对偶问题（B.1）的最优解，且强对偶性成立，也就是说当主问题（A.1）为凸优化问题时，KKT条件是强对偶性成立的充分条件。<br>【证明】：已知存在$\boldsymbol x^*,\boldsymbol \mu^*,\boldsymbol \lambda^*$满足KKT条件，也即</p>
<script type="math/tex; mode=display">\left\{
\begin{aligned}
& \nabla_{\boldsymbol x} L(\boldsymbol x^* ,\boldsymbol \mu^* ,\boldsymbol \lambda^* )=\nabla f(\boldsymbol  x^* )+\sum_{i=1}^{m}\mu_i^* \nabla g_i(\boldsymbol x^* )+\sum_{j=1}^{n}\lambda_j^* \nabla h_j(\boldsymbol x^*)=0 &(B.5.1) \\
& h_j(\boldsymbol x^*)=0 &(B.5.2) \\
& g_i(\boldsymbol x^*) \leq 0 &(B.5.3) \\
& \mu_i^* \geq 0 &(B.5.4)\\
& \mu_i^* g_i(\boldsymbol x^*)=0 &(B.5.5)
\end{aligned}
\right.</script><p>由（B.5.2）和（B.5.3）可知$\boldsymbol x^*$是可行集$\tilde{D}$中的点；由（B.5.4）可推得$L(\boldsymbol x,\boldsymbol \mu^*,\boldsymbol \lambda^*)$是关于$\boldsymbol x$的凸函数，因为</p>
<script type="math/tex; mode=display">L(\boldsymbol x ,\boldsymbol \mu^* ,\boldsymbol \lambda^* )= f(\boldsymbol  x)+\sum_{i=1}^{m}\mu_i^*  g_i(\boldsymbol x )+\sum_{j=1}^{n}\lambda_j^* h_j(\boldsymbol x)</script><p>由于此时主问题（A.1）为凸优化问题，所以上式中的$f(\boldsymbol x),g_i(\boldsymbol x)$为凸函数，$h_j(\boldsymbol x)$为仿射函数，显然，当$\mu_i^* \geq 0$时$L(\boldsymbol x ,\boldsymbol \mu^* ,\boldsymbol \lambda^* )$恒为关于$\boldsymbol x$的凸函数；由（B.5.1）可知，$\boldsymbol x^*$是$L(\boldsymbol x ,\boldsymbol \mu^* ,\boldsymbol \lambda^* )$的极值点，由凸函数的性质可知，此极值点必是最小值点，那么可以进一步推得</p>
<script type="math/tex; mode=display">\begin{aligned}
\Gamma(\boldsymbol \mu^*,\boldsymbol \lambda^*)&=\mathop{\inf}_{\boldsymbol x∈D} \left( f(\boldsymbol x)+\sum_{i=1}^{m}\mu_i^* g_i(\boldsymbol x)+\sum_{j=1}^{n}\lambda_j^* h_j(\boldsymbol x) \right) &(B.6.1)\\
&=L(\boldsymbol x^* ,\boldsymbol \mu^* ,\boldsymbol \lambda^* )&(B.6.2)\\
&=f(\boldsymbol x^*)+\sum_{i=1}^{m}\mu_i^* g_i(\boldsymbol x^*)+\sum_{j=1}^{n}\lambda_j^* h_j(\boldsymbol x^*) &(B.6.3)\\
&=f(\boldsymbol x^*)&(B.6.4)
\end{aligned}</script><p>其中，（B.6.1）是由$\Gamma(\boldsymbol \mu,\boldsymbol \lambda)$的定义推得；（B.6.2）是由</p>
<script type="math/tex; mode=display">\mathop{\inf}_{\boldsymbol x∈D} \left( f(\boldsymbol x)+\sum_{i=1}^{m}\mu_i^* g_i(\boldsymbol x^*)+\sum_{j=1}^{n}\lambda_j^* h_j(\boldsymbol x) \right)=\min\{L(\boldsymbol x ,\boldsymbol \mu^* ,\boldsymbol \lambda^* )\}=L(\boldsymbol x^* ,\boldsymbol \mu^* ,\boldsymbol \lambda^* )</script><p>推得；（B.6.3）是由$L(\boldsymbol x,\boldsymbol \mu,\boldsymbol \lambda)$的定义推得；（B.6.4）是由（B.5.2）和（B.5.5）推得。因此，根据上述对偶函数的第二条性质可知，当$\boldsymbol \mu \succeq 0$时，能找到$\boldsymbol x^*\in \tilde{D}$和$(\boldsymbol \mu^*,\boldsymbol \lambda^*)$使得$\Gamma(\boldsymbol \mu^*,\boldsymbol \lambda^*)=f(\boldsymbol x^*)$成立，那么此时强对偶性成立，且$\boldsymbol x^*$和$(\boldsymbol \mu^*,\boldsymbol \lambda^*)$是主问题（A.1）和对偶问题（B.1）的最优解，证毕。</p>
</li>
</ul>
<p>综合上述最后两条性质可知：若主问题（A.1）为非凸优化问题，KKT条件是强对偶性成立的必要条件，若主问题（A.1）为凸优化问题，那么KKT条件即为强对偶性成立的<strong>充要条件</strong>。</p>
<h3 id="参考文献："><a href="#参考文献：" class="headerlink" title="参考文献："></a>参考文献：</h3><p><span id="ref1">[1] 王书宁 译.《凸优化》</span><br><span id="ref2">[2] <a href="https://en.wikipedia.org/wiki/Strong_duality#Sufficient_conditions" target="_blank" rel="noopener">Strong duality</a></span><br><span id="ref3">[3] <a href="https://en.wikipedia.org/wiki/Slater%27s_condition" target="_blank" rel="noopener">Slater’s condition</a></span></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;对于一般地约束优化问题：&lt;/p&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{array}{ll}
{\min } &amp; {f(\boldsymbol x)} \qquad\qquad\qquad\qquad\qquad\qqua
    
    </summary>
    
      <category term="最优化" scheme="http://sm1les.com/categories/%E6%9C%80%E4%BC%98%E5%8C%96/"/>
    
    
      <category term="拉格朗日对偶" scheme="http://sm1les.com/tags/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E5%AF%B9%E5%81%B6/"/>
    
      <category term="Slater条件" scheme="http://sm1les.com/tags/Slater%E6%9D%A1%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title>KKT条件（Karush–Kuhn–Tucker conditions）</title>
    <link href="http://sm1les.com/2018/12/08/karush-kuhn-tucker-conditions/"/>
    <id>http://sm1les.com/2018/12/08/karush-kuhn-tucker-conditions/</id>
    <published>2018-12-08T09:03:27.000Z</published>
    <updated>2020-01-01T13:42:41.774Z</updated>
    
    <content type="html"><![CDATA[<p>对于一般地约束优化问题</p>
<script type="math/tex; mode=display">\begin{array}{ll}
{\min } & {f(\boldsymbol x)} \\ 
{\text {s.t.}} & {g_{i}(\boldsymbol x) \leq 0 \quad(i=1, \ldots, m)} \\ 
{} & {h_{j}(\boldsymbol x)=0 \quad(j=1, \ldots, n)}
\end{array}</script><p>其中，自变量$\boldsymbol x\in \mathbb{R}^n$。设$f(\boldsymbol x),g_i(\boldsymbol x),h_j(\boldsymbol x)$具有连续的一阶偏导数，$\boldsymbol x^*$是优化问题的局部可行解。若在$\boldsymbol x^*$处<strong>约束限制条件（constraint qualifications or regularity conditions）</strong><sup><a href="#ref1">[1]</a></sup><sup><a href="#ref2">[2]</a></sup>成立，则一定存在$\boldsymbol \mu^*=(\mu_1^*,\mu_2^*,…,\mu_m^*)^T,\boldsymbol \lambda^*=(\lambda_1^*,\lambda_2^*,…,\lambda_n^*)^T,$使得</p>
<script type="math/tex; mode=display">\left\{
\begin{aligned}
& \nabla_{\boldsymbol x} L(\boldsymbol x^* ,\boldsymbol \mu^* ,\boldsymbol \lambda^* )+\nabla f(\boldsymbol  x^* )+\sum_{i=1}^{m}\mu_i^* \nabla g_i(\boldsymbol x^* )+\sum_{j=1}^{n}\lambda_j^* \nabla h_j(\boldsymbol x^*)=0 &(1) \\
& h_j(\boldsymbol x^*)=0 &(2) \\
& g_i(\boldsymbol x^*) \leq 0 &(3) \\
& \mu_i^* \geq 0 &(4)\\
& \mu_i^* g_i(\boldsymbol x^*)=0 &(5)
\end{aligned}
\right.</script><p>其中$L(\boldsymbol x,\boldsymbol \mu,\boldsymbol \lambda)$为拉格朗日函数</p>
<script type="math/tex; mode=display">L(\boldsymbol x,\boldsymbol \mu,\boldsymbol \lambda)=f(\boldsymbol x)+\sum_{i=1}^{m}\mu_i g_i(\boldsymbol x)+\sum_{j=1}^{n}\lambda_j h_j(\boldsymbol x)</script><p>以上5条即为<strong>KKT条件</strong>，其中条件(2)和(3)为约束条件显然成立，条件(1)、(4)、(5)成立的<strong>简单证明</strong>（严格数学证明参见<a href="#ref1">[1]</a> § 4.2.1）如下：</p>
<p><center>
<img src="./Inequality_constraint_diagram.png" width="60%" height="60%">
</center><br>由约束条件：$g_i(\boldsymbol x) \leq 0$可知，$\boldsymbol x^*$一定满足$g_i(\boldsymbol x^*) \lt 0$或者$g_i(\boldsymbol x^*) = 0$，下面对这两种情形分别进行讨论：</p>
<ul>
<li><strong>当$g_i(\boldsymbol x^*) \lt 0$时：</strong><br>此时极小值点在$g_i(\boldsymbol x) \lt 0$这个区域内（如上图左部所示），所以$g_i(\boldsymbol x) \leq 0$这个约束可以忽略，那么此时的优化问题等价于<strong>仅含等式约束</strong>的优化问题，所以$\mu_i^* = 0$。</li>
<li><strong>当$g_i(\boldsymbol x^*) = 0$时：</strong><br>此时极小值点在$g_i(\boldsymbol x) = 0$这个边界上，所以约束$g_i(\boldsymbol x) \leq 0$等价于约束$g_i(\boldsymbol x) = 0$，那么此时的优化问题同样等价于<strong>仅含等式约束</strong>的最优化问题。根据拉格朗日乘子法的原理可知，此时$f(\boldsymbol  x)$和$ g_i(\boldsymbol  x)=0$在极小值点处相切（如上图右部所示），梯度（正梯度）平行，即$\nabla f(\boldsymbol  x^*)+\mu_i^* \nabla g_i(\boldsymbol  x^*)=0 \quad (\mu_i^*\in \mathbb{R})$。易知$g_i(\boldsymbol x)=0$这个边界上的梯度都是向外的，而$\nabla f(\boldsymbol x^*)$一定和$\nabla g_i(\boldsymbol x^*)$的方向相反（如果不相反的话极小值点就不会在边界上取到而是在$g_i(\boldsymbol x) \lt 0$内取），所以$\nabla f(\boldsymbol  x^*)$和$\nabla g_i(\boldsymbol  x^*)$异号，那么$\mu_i^*$一定大于0。</li>
</ul>
<p>综上，当$g_i(\boldsymbol x^*) \lt 0$时$\mu_i^* = 0$， $g_i(\boldsymbol x^*) = 0$时$\mu_i^* \gt 0$，所以条件(4)、(5)恒成立；由于对$\lambda_j$取值无要求，所以总存在$\lambda_j^*$使得条件(1)恒成立。<br>【注】：</p>
<ul>
<li>若在$\boldsymbol x^*$处约束限制条件<strong>成立</strong>，则KKT条件是局部可行解$\boldsymbol x^*$的<strong>必要条件</strong>；</li>
<li>若在$\boldsymbol x^*$处约束限制条件<strong>不成立</strong>，则局部解$\boldsymbol x^*$<strong>不一定</strong>满足KKT条件（证明参见<a href="#ref1">[1]</a> § 4.2.1）;</li>
<li>满足KKT条件的点$\boldsymbol x^*$不一定是局部可行解（证明参见<a href="#ref1">[1]</a> § 4.2.1）；</li>
<li>若上述优化问题是<strong>凸优化</strong>问题，也即目标函数$f(\boldsymbol x)$是凸函数，不等式约束$g_i(\boldsymbol x)$是凸函数，等式约束$h_j(\boldsymbol x)$是仿射函数，那么此时KKT条件为局部可行解$\boldsymbol x^*$的<strong>充分条件</strong>，同时局部可行解$\boldsymbol x^*$也为<strong>全局可行解</strong>（证明参见<a href="#ref1">[1]</a> § 4.4），特别地，此时若在$\boldsymbol x^*$处约束限制条件也成立，那么KKT条件即升级为<strong>充要条件=充分条件+必要条件</strong>；</li>
</ul>
<h3 id="参考文献："><a href="#参考文献：" class="headerlink" title="参考文献："></a>参考文献：</h3><p><span id="ref1">[1] 王燕军. 《最优化基础理论与方法》</span><br><span id="ref2">[2] <a href="https://en.wikipedia.org/wiki/Karush%E2%80%93Kuhn%E2%80%93Tucker_conditions#Regularity_conditions_(or_constraint_qualifications)" target="_blank" rel="noopener">Karush–Kuhn–Tucker conditions</a></span></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;对于一般地约束优化问题&lt;/p&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{array}{ll}
{\min } &amp; {f(\boldsymbol x)} \\ 
{\text {s.t.}} &amp; {g_{i}(\boldsym
    
    </summary>
    
      <category term="最优化" scheme="http://sm1les.com/categories/%E6%9C%80%E4%BC%98%E5%8C%96/"/>
    
    
      <category term="KKT条件" scheme="http://sm1les.com/tags/KKT%E6%9D%A1%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title>线性回归参数的极大似然估计和最小二乘估计</title>
    <link href="http://sm1les.com/2018/11/27/linear-regression-maximum-likelihood/"/>
    <id>http://sm1les.com/2018/11/27/linear-regression-maximum-likelihood/</id>
    <published>2018-11-27T07:20:01.000Z</published>
    <updated>2019-07-24T01:07:05.287Z</updated>
    
    <content type="html"><![CDATA[<h3 id="极大似然估计"><a href="#极大似然估计" class="headerlink" title="极大似然估计"></a>极大似然估计</h3><p>对于线性回归模型：</p>
<script type="math/tex; mode=display">y=\boldsymbol{w}^T\boldsymbol{x}+b+\epsilon</script><p>随机误差$\epsilon$可以看成是由许多观察不到的、可加的微小误差叠加而成的<sup><a href="#ref1">[1]</a></sup>，则根据<strong>中心极限定理</strong>，随机误差$\epsilon$服从正态分布，其分布为：$\epsilon \sim N(\mu,\sigma^2)$，为了方便后续计算可以将其去均值，令$\epsilon:=\epsilon-\mu$，则此时的分布为：$\epsilon \sim N(0,\sigma^2)$，分布律为：</p>
<script type="math/tex; mode=display">p(\epsilon)=\cfrac{1}{\sqrt{2\pi}\sigma} \mathrm{exp}\left(-\cfrac{\epsilon^2}{2\sigma^2}\right)</script><p>若将其中的$\epsilon$用$\epsilon=y-\boldsymbol{w}^T\boldsymbol{x}-b$等价替换可得：</p>
<script type="math/tex; mode=display">p(y)=\cfrac{1}{\sqrt{2\pi}\sigma} \mathrm{exp}\left(-\cfrac{(y-\boldsymbol{w}^T\boldsymbol{x}-b)^2}{2\sigma^2}\right)</script><p>上式显然可以看做$y \sim N(\boldsymbol{w}^T\boldsymbol{x}+b,\sigma^2)$的分布律，接下来便可以用最（极）大似然估计法来估计$\boldsymbol{w}$和b的值。似然函数为：</p>
<script type="math/tex; mode=display">L(\boldsymbol{w},b)=\prod_{i=1}^{m}p(y_i)=\prod_{i=1}^{m}\cfrac{1}{\sqrt{2\pi}\sigma} \mathrm{exp}\left(-\cfrac{(y_i-\boldsymbol{w}^T\boldsymbol{x_i}-b)^2}{2\sigma^2}\right)</script><p>两边同时取对数得对数似然函数：</p>
<script type="math/tex; mode=display">
\begin{aligned}     
\ln L(\boldsymbol{w},b) & = \sum_{i=1}^{m}\ln \cfrac{1}{\sqrt{2\pi}\sigma} \mathrm{exp}\left(-\cfrac{(y_i-\boldsymbol{w}^T\boldsymbol{x_i}-b)^2}{2\sigma^2}\right) \\
& = \sum_{i=1}^{m}\ln \cfrac{1}{\sqrt{2\pi}\sigma}+\sum_{i=1}^{m}\ln \mathrm{exp}\left(-\cfrac{(y_i-\boldsymbol{w}^T\boldsymbol{x_i}-b)^2}{2\sigma^2}\right) \\
& = m\ln \cfrac{1}{\sqrt{2\pi}\sigma}-\cfrac{1}{2\sigma^2}\sum_{i=1}^{m}(y_i-\boldsymbol{w}^T\boldsymbol{x_i}-b)^2
\end{aligned}</script><p>其中$m$，$\sigma$均为常数，所以最大化$\ln L(\boldsymbol{w},b)$等价于最小化$\sum_{i=1}^{m}(y_i-\boldsymbol{w}^T\boldsymbol{x_i}-b)^2$，也即：</p>
<script type="math/tex; mode=display">(\boldsymbol{w}',b')=\mathop{\arg\max}_{(\boldsymbol{w},b)} \ln L(\boldsymbol{w},b)=\mathop{\arg\min}_{(\boldsymbol{w},b)} \sum_{i=1}^{m}(y_i-\boldsymbol{w}^T\boldsymbol{x_i}-b)^2</script><p>其中$\boldsymbol{w}’$和$b’$为$\boldsymbol{w}$和$b$的解.</p>
<h3 id="最小二乘估计"><a href="#最小二乘估计" class="headerlink" title="最小二乘估计"></a>最小二乘估计</h3><p>最小二乘法是基于均方误差最小化来对模型进行参数估计的，用公式表示为：</p>
<script type="math/tex; mode=display">
\begin{aligned}    
    (\boldsymbol{w}',b') & = \mathop{\arg\min}_{(\boldsymbol{w},b)} \sum_{i=1}^{m}(y_i-(\boldsymbol{w}^T\boldsymbol{x_i}+b))^2 \\
    & = \mathop{\arg\min}_{(\boldsymbol{w},b)} \sum_{i=1}^{m}(y_i-\boldsymbol{w}^T\boldsymbol{x_i}-b)^2
\end{aligned}</script><p>显然与最（极）大似然估计的推导结果一致。</p>
<h3 id="参考文献："><a href="#参考文献：" class="headerlink" title="参考文献："></a>参考文献：</h3><p><span id="ref1">[1] 盛骤.《概率论与数理统计（第四版）》</span></p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;极大似然估计&quot;&gt;&lt;a href=&quot;#极大似然估计&quot; class=&quot;headerlink&quot; title=&quot;极大似然估计&quot;&gt;&lt;/a&gt;极大似然估计&lt;/h3&gt;&lt;p&gt;对于线性回归模型：&lt;/p&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;y=
    
    </summary>
    
      <category term="机器学习" scheme="http://sm1les.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="线性回归" scheme="http://sm1les.com/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    
  </entry>
  
</feed>
